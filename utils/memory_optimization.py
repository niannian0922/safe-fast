"""
å®‰å…¨æ•æ·é£è¡Œç³»ç»Ÿçš„å†…å­˜ä¼˜åŒ–å·¥å…·ã€‚

æ­¤æ¨¡å—æä¾›ä»¥ä¸‹å·¥å…·ï¼š
1. åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€æµ‹å’Œç®¡ç†å†…å­˜ä½¿ç”¨
2. åŸºäºå¯ç”¨å†…å­˜è‡ªåŠ¨è°ƒæ•´åºåˆ—é•¿åº¦
3. æä¾›å†…å­˜å®‰å…¨çš„é…ç½®é»˜è®¤å€¼
4. åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§å†…å­˜ä½¿ç”¨

ç›®æ ‡æ˜¯åœ¨é•¿åºåˆ—è®­ç»ƒæœŸé—´é˜²æ­¢å†…å­˜æº¢å‡ºï¼Œ
åŒæ—¶ä¿æŒè®­ç»ƒæœ‰æ•ˆæ€§ã€‚
"""

import jax
import jax.numpy as jnp
import psutil
import gc
from typing import Dict, Tuple, Optional
import warnings


def get_memory_info() -> Dict[str, float]:
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨ä¿¡æ¯"""
    try:
        # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        
        # è·å–JAXè®¾å¤‡å†…å­˜ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        devices = jax.devices()
        device_memory = {}
        
        for i, device in enumerate(devices):
            try:
                if hasattr(device, 'memory_stats'):
                    stats = device.memory_stats()
                    device_memory[f'device_{i}'] = {
                        'used': stats.get('bytes_in_use', 0) / 1e9,  # GB å·²ä½¿ç”¨
                        'total': stats.get('peak_bytes_in_use', 0) / 1e9  # GB æ€»è®¡
                    }
            except:
                pass  # è®¾å¤‡ä¸æ”¯æŒå†…å­˜ç»Ÿè®¡
        
        return {
            'system_total_gb': memory.total / 1e9,
            'system_available_gb': memory.available / 1e9,
            'system_used_percent': memory.percent,
            'device_memory': device_memory
        }
    except Exception as e:
        warnings.warn(f"Could not get memory info: {e}")
        return {'system_total_gb': 8.0, 'system_available_gb': 4.0, 'system_used_percent': 50.0}


def estimate_memory_usage(batch_size: int, sequence_length: int, model_size: str = "medium") -> float:
    """
    ä¼°è®¡ç»™å®šé…ç½®çš„å†…å­˜ä½¿ç”¨é‡
    
    å‚æ•°:
        batch_size: è®­ç»ƒæ‰¹å¤„ç†å¤§å°
        sequence_length: BPTTåºåˆ—é•¿åº¦ 
        model_size: "small"ã€"medium"æˆ–"large"
        
    è¿”å›å€¼:
        ä¼°è®¡çš„å†…å­˜ä½¿ç”¨é‡ï¼ˆGBï¼‰
    """
    
    # åŸºç¡€å†…å­˜ä¼°è®¡ï¼ˆç²—ç•¥è¿‘ä¼¼ï¼‰
    base_memory = {
        "small": 1.0,   # GB
        "medium": 2.5,  # GB  
        "large": 5.0    # GB
    }
    
    # å†…å­˜ç¼©æ”¾å› å­
    batch_factor = batch_size / 16.0  # å‚è€ƒæ‰¹å¤„ç†å¤§å°
    sequence_factor = sequence_length / 20.0  # å‚è€ƒåºåˆ—é•¿åº¦
    
    # ä¼°è®¡æ€»å†…å­˜
    estimated_memory = base_memory[model_size] * batch_factor * sequence_factor
    
    # ä¸ºJAXç¼–è¯‘å’Œä¸­é—´å€¼æ·»åŠ ç¼“å†²åŒº
    estimated_memory *= 1.5
    
    return estimated_memory


def get_memory_safe_config(base_config, target_memory_gb: float = 4.0):
    """
    è°ƒæ•´é…ç½®ä»¥ç¡®ä¿å†…å­˜å®‰å…¨
    
    å‚æ•°:
        base_config: è¦è°ƒæ•´çš„åŸºç¡€é…ç½®
        target_memory_gb: ç›®æ ‡æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆGBï¼‰
        
    è¿”å›å€¼:
        å†…å­˜å®‰å…¨çš„é…ç½®
    """
    config = base_config
    
    # è·å–å½“å‰å†…å­˜ä¿¡æ¯
    memory_info = get_memory_info()
    available_memory = min(target_memory_gb, memory_info['system_available_gb'] * 0.8)
    
    print(f"ğŸ§  Memory optimization target: {available_memory:.1f}GB")
    
    # ä»å½“å‰é…ç½®å¼€å§‹
    current_batch_size = config.training.batch_size
    current_seq_length = config.training.sequence_length
    
    # ä¼°è®¡å½“å‰å†…å­˜ä½¿ç”¨é‡
    current_memory = estimate_memory_usage(current_batch_size, current_seq_length, "medium")
    
    if current_memory <= available_memory:
        print(f"âœ… Current config fits in memory: {current_memory:.1f}GB")
        return config
    
    print(f"âš ï¸ Current config may exceed memory: {current_memory:.1f}GB > {available_memory:.1f}GB")
    print("ğŸ”§ Adjusting configuration for memory safety...")
    
    # è°ƒæ•´å‚æ•°ä»¥é€‚åº”å†…å­˜
    # ä¼˜å…ˆçº§ï¼šé¦–å…ˆå‡å°‘åºåˆ—é•¿åº¦ï¼Œç„¶åå‡å°‘æ‰¹å¤„ç†å¤§å°
    
    # å°è¯•å‡å°‘åºåˆ—é•¿åº¦
    safe_seq_length = current_seq_length
    while safe_seq_length > 5:
        test_memory = estimate_memory_usage(current_batch_size, safe_seq_length, "medium")
        if test_memory <= available_memory:
            break
        safe_seq_length = max(5, int(safe_seq_length * 0.8))
    
    # å¦‚æœä»ç„¶å¤ªå¤§ï¼Œå‡å°‘æ‰¹å¤„ç†å¤§å°
    safe_batch_size = current_batch_size
    while safe_batch_size > 1:
        test_memory = estimate_memory_usage(safe_batch_size, safe_seq_length, "medium")
        if test_memory <= available_memory:
            break
        safe_batch_size = max(1, int(safe_batch_size * 0.8))
    
    # æ›´æ–°é…ç½®
    if safe_seq_length != current_seq_length:
        config.training.sequence_length = safe_seq_length
        print(f"   Reduced sequence length: {current_seq_length} â†’ {safe_seq_length}")
    
    if safe_batch_size != current_batch_size:
        config.training.batch_size = safe_batch_size
        print(f"   Reduced batch size: {current_batch_size} â†’ {safe_batch_size}")
    
    # åŒæ—¶è°ƒæ•´å…¶ä»–å†…å­˜æ•æ„Ÿå‚æ•°
    if current_memory > available_memory * 1.5:
        # ä¸ºä¸¥é‡å—é™çš„å†…å­˜å‡å°‘æ¨¡å‹å¤§å°
        config.policy.hidden_dims = [min(128, d) for d in config.policy.hidden_dims]
        config.gcbf.gnn.hidden_dims = [min(128, d) for d in config.gcbf.gnn.hidden_dims]
        print("   Reduced model sizes for memory constraints")
    
    final_memory = estimate_memory_usage(
        config.training.batch_size, 
        config.training.sequence_length, 
        "medium"
    )
    
    print(f"âœ… Memory-optimized config: {final_memory:.1f}GB (target: {available_memory:.1f}GB)")
    
    return config


def clear_jax_cache():
    """æ¸…é™¤JAXç¼–è¯‘ç¼“å­˜å¹¶è¿è¡Œåƒåœ¾å›æ”¶"""
    try:
        # æ¸…é™¤JAXç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(jax, 'clear_caches'):
            jax.clear_caches()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        print("ğŸ§¹ Cleared JAX cache and ran garbage collection")
    except Exception as e:
        warnings.warn(f"Could not clear cache: {e}")


def monitor_training_memory(step: int, clear_every: int = 50):
    """åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§å†…å­˜ä½¿ç”¨é‡ï¼Œå¿…è¦æ—¶æ¸…é™¤ç¼“å­˜"""
    if step % clear_every == 0 and step > 0:
        memory_info = get_memory_info()
        
        if memory_info['system_used_percent'] > 85:
            print(f"âš ï¸ High memory usage at step {step}: {memory_info['system_used_percent']:.1f}%")
            clear_jax_cache()
            
            # æ¸…ç†åå†æ¬¡æ£€æŸ¥
            new_memory_info = get_memory_info()
            print(f"   Memory after cleanup: {new_memory_info['system_used_percent']:.1f}%")


def get_debug_config(base_config):
    """è·å–å…·æœ‰æœ€å°å†…å­˜ä½¿ç”¨é‡çš„è°ƒè¯•é…ç½®"""
    config = base_config
    
    # è°ƒè¯•çš„æœ€å°è®¾ç½®
    config.training.batch_size = 2
    config.training.sequence_length = 5
    config.training.num_epochs = 2
    config.training.batches_per_epoch = 3
    config.training.validation_batch_size = 2
    
    # é™ä½æ¨¡å‹å¤æ‚åº¦
    config.policy.hidden_dims = [32, 32]
    config.gcbf.gnn.hidden_dims = [64, 64, 32]
    config.gcbf.k_neighbors = 3
    config.gcbf.max_neighbors = 4
    
    # ç¦ç”¨æ˜‚è´µçš„åŠŸèƒ½
    config.optimization.use_checkpoint = False
    config.optimization.nested_checkpoint = False
    config.logging.video_logging = False
    config.training.curriculum.enable = False
    
    print("ğŸ› Using debug configuration with minimal memory usage")
    return config


def validate_memory_config(config) -> bool:
    """éªŒè¯é…ç½®å¯¹äºå¯ç”¨å†…å­˜æ˜¯åˆç†çš„"""
    memory_info = get_memory_info()
    estimated_usage = estimate_memory_usage(
        config.training.batch_size,
        config.training.sequence_length,
        "medium"
    )
    
    available_memory = memory_info['system_available_gb']
    
    if estimated_usage > available_memory * 0.9:
        print(f"âŒ Configuration may exceed available memory:")
        print(f"   Estimated usage: {estimated_usage:.1f}GB")
        print(f"   Available memory: {available_memory:.1f}GB")
        return False
    
    print(f"âœ… Memory configuration validated:")
    print(f"   Estimated usage: {estimated_usage:.1f}GB")
    print(f"   Available memory: {available_memory:.1f}GB")
    return True


if __name__ == "__main__":
    # æµ‹è¯•å†…å­˜å·¥å…·
    print("Testing memory optimization utilities...")
    
    memory_info = get_memory_info()
    print(f"System memory: {memory_info}")
    
    # æµ‹è¯•å†…å­˜ä¼°è®¡
    for batch_size in [2, 8, 16]:
        for seq_len in [5, 20, 50]:
            usage = estimate_memory_usage(batch_size, seq_len, "medium")
            print(f"Batch {batch_size}, Seq {seq_len}: ~{usage:.1f}GB")
#!/usr/bin/env python3
"""
KAGGLEè®­ç»ƒç»ˆæè§£å†³æ–¹æ¡ˆ - Safe Agile Flight
ç«¯åˆ°ç«¯å¯å¾®åˆ†è®­ç»ƒï¼Œå®Œå…¨è§£å†³æ‰€æœ‰Kaggleç¯å¢ƒé—®é¢˜

ğŸ¯ ä¸»è¦è§£å†³çš„é—®é¢˜ï¼š
1. âŒ fatal: destination path already exists and is not an empty directory
2. âŒ ä¾èµ–åŒ…å®‰è£…å¤±è´¥å’Œç‰ˆæœ¬å†²çª
3. âŒ æ¨¡å—å¯¼å…¥é”™è¯¯
4. âŒ å†…å­˜ä¸è¶³å¯¼è‡´è®­ç»ƒå¤±è´¥
5. âŒ JITç¼–è¯‘é—®é¢˜

âœ… è§£å†³æ–¹æ¡ˆç‰¹ç‚¹ï¼š
- è‡ªåŠ¨æ¸…ç†å’Œé‡å»ºç¯å¢ƒ
- æ¸è¿›å¼é²æ£’ä¾èµ–å®‰è£…
- å†…åµŒå¤‡ç”¨å®ç°ç¡®ä¿100%å¯ç”¨
- å†…å­˜ä¼˜åŒ–é…ç½®
- å®Œæ•´ç«¯åˆ°ç«¯æ¢¯åº¦æµéªŒè¯

ğŸš€ ä½¿ç”¨æ–¹æ³•ï¼š
åœ¨Kaggle Notebookä¸­ç›´æ¥è¿è¡Œï¼š
exec(open('/content/KAGGLE_TRAINING_FINAL.py').read())

æˆ–è€…ï¼š
!wget -O /content/train.py https://raw.githubusercontent.com/niannian0922/safe_agile_flight/main/KAGGLE_TRAINING_FINAL.py
exec(open('/content/train.py').read())
"""

print("ğŸš SAFE AGILE FLIGHT - KAGGLEç»ˆæè®­ç»ƒæ–¹æ¡ˆ")
print("ğŸ”¥ å½»åº•è§£å†³æ‰€æœ‰å·²çŸ¥é—®é¢˜")
print("=" * 80)

import subprocess
import sys
import os
import shutil
import time
import traceback
from pathlib import Path

# =============================================================================
# é˜¶æ®µ 1: ç¯å¢ƒå½»åº•æ¸…ç†ä¸é‡å»º
# =============================================================================
def stage1_environment_reset():
    """å½»åº•æ¸…ç†å¹¶é‡å»ºç¯å¢ƒ"""
    print("ğŸ§¹ é˜¶æ®µ1: ç¯å¢ƒå½»åº•æ¸…ç†ä¸é‡å»º")
    print("-" * 50)
    
    # 1.1 æ¸…ç†ç›®æ ‡ç›®å½•ï¼ˆè§£å†³git cloneé—®é¢˜ï¼‰
    target_paths = [
        '/kaggle/working/safe_agile_flight',
        '/kaggle/working/safe-agile-flight', 
        '/content/safe_agile_flight',
        '/content/safe-agile-flight'
    ]
    
    for path in target_paths:
        if Path(path).exists():
            try:
                shutil.rmtree(path, ignore_errors=True)
                print(f"   ğŸ—‘ï¸  æ¸…ç†: {path}")
            except Exception as e:
                print(f"   âš ï¸  æ¸…ç†è­¦å‘Š {path}: {e}")
        time.sleep(0.1)
    
    # 1.2 åˆ›å»ºå¹²å‡€çš„å·¥ä½œç›®å½•
    working_dirs = ['/kaggle/working', '/content']
    project_dir = None
    
    for wd in working_dirs:
        if Path(wd).exists():
            project_dir = Path(wd) / 'safe_agile_flight'
            break
    
    if project_dir is None:
        project_dir = Path.cwd() / 'safe_agile_flight'
    
    project_dir.mkdir(parents=True, exist_ok=True)
    print(f"   ğŸ“ å·¥ä½œç›®å½•: {project_dir}")
    
    # 1.3 ç¯å¢ƒå˜é‡ä¼˜åŒ–
    env_vars = {
        'PYTHONDONTWRITEBYTECODE': '1',  # é˜²æ­¢.pycæ–‡ä»¶
        'XLA_PYTHON_CLIENT_MEM_FRACTION': '0.75',  # GPUå†…å­˜é™åˆ¶
        'XLA_PYTHON_CLIENT_PREALLOCATE': 'false',  # ç¦ç”¨é¢„åˆ†é…
        'JAX_ENABLE_X64': 'false',  # ä½¿ç”¨float32èŠ‚çœå†…å­˜
        'JAX_PLATFORMS': '',  # è‡ªåŠ¨é€‰æ‹©å¹³å°
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
        
    print("   âœ… ç¯å¢ƒå˜é‡ä¼˜åŒ–å®Œæˆ")
    print(f"   ğŸ“Š æ¸…ç†å®Œæˆï¼Œå·¥ä½œç›®å½•: {project_dir}")
    return project_dir

project_dir = stage1_environment_reset()

# =============================================================================  
# é˜¶æ®µ 2: å¤šç­–ç•¥é¡¹ç›®ä»£ç è·å–
# =============================================================================
def stage2_get_project_code(project_dir):
    """å¤šç­–ç•¥è·å–é¡¹ç›®ä»£ç """
    print(f"\nğŸ“‚ é˜¶æ®µ2: å¤šç­–ç•¥é¡¹ç›®ä»£ç è·å–")
    print("-" * 50)
    
    strategies = [
        {
            'name': 'æµ…å…‹éš†',
            'cmd': ['git', 'clone', '--depth=1', '--quiet',
                   'https://github.com/niannian0922/safe_agile_flight.git', str(project_dir)],
            'timeout': 120
        },
        {
            'name': 'æ ‡å‡†å…‹éš†',
            'cmd': ['git', 'clone', '--quiet',
                   'https://github.com/niannian0922/safe_agile_flight.git', str(project_dir)],
            'timeout': 180
        },
        {
            'name': 'SSHå…‹éš†',
            'cmd': ['git', 'clone', 'git@github.com:niannian0922/safe_agile_flight.git', str(project_dir)],
            'timeout': 120
        }
    ]
    
    for strategy in strategies:
        try:
            print(f"   ğŸ”„ å°è¯•{strategy['name']}...")
            result = subprocess.run(
                strategy['cmd'], 
                check=True, 
                timeout=strategy['timeout'],
                capture_output=True, 
                text=True
            )
            print(f"   âœ… {strategy['name']}æˆåŠŸ")
            
            # éªŒè¯å…³é”®æ–‡ä»¶
            key_files = ['core/physics.py', 'configs/default_config.py', 'main.py']
            missing = []
            for kf in key_files:
                if not (project_dir / kf).exists():
                    missing.append(kf)
            
            if missing:
                print(f"   âš ï¸  ç¼ºå°‘å…³é”®æ–‡ä»¶: {missing}")
                continue
            else:
                print(f"   âœ… ä»£ç å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                return True, "é¡¹ç›®ä»£ç è·å–æˆåŠŸ"
                
        except subprocess.TimeoutExpired:
            print(f"   â° {strategy['name']}è¶…æ—¶")
        except subprocess.CalledProcessError as e:
            print(f"   âŒ {strategy['name']}å¤±è´¥: {e.stderr}")
        except Exception as e:
            print(f"   âŒ {strategy['name']}å¼‚å¸¸: {e}")
    
    # å¦‚æœæ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œåˆ›å»ºåŸºç¡€ç»“æ„
    print("   ğŸ”¨ åˆ›å»ºåŸºç¡€é¡¹ç›®ç»“æ„...")
    try:
        # åˆ›å»ºç›®å½•ç»“æ„
        dirs = ['core', 'configs', 'utils', 'tests']
        for d in dirs:
            (project_dir / d).mkdir(exist_ok=True)
            (project_dir / d / '__init__.py').touch()
        
        (project_dir / '__init__.py').touch()
        print("   âœ… åŸºç¡€ç»“æ„åˆ›å»ºå®Œæˆ")
        return False, "ä½¿ç”¨åŸºç¡€ç»“æ„ï¼Œéœ€è¦å†…åµŒå®ç°"
        
    except Exception as e:
        print(f"   âŒ åŸºç¡€ç»“æ„åˆ›å»ºå¤±è´¥: {e}")
        return False, "ç¯å¢ƒå‡†å¤‡å¤±è´¥"

code_available, code_status = stage2_get_project_code(project_dir)
print(f"   ğŸ“Š ä»£ç çŠ¶æ€: {code_status}")

# å°†é¡¹ç›®ç›®å½•åŠ å…¥Pythonè·¯å¾„
sys.path.insert(0, str(project_dir))

# =============================================================================
# é˜¶æ®µ 3: åˆ†å±‚æ¸è¿›å¼ä¾èµ–å®‰è£…
# =============================================================================
def stage3_install_dependencies():
    """åˆ†å±‚æ¸è¿›å¼ä¾èµ–å®‰è£…"""
    print(f"\nğŸ“¦ é˜¶æ®µ3: åˆ†å±‚æ¸è¿›å¼ä¾èµ–å®‰è£…")
    print("-" * 50)
    
    # ä¾èµ–å±‚çº§å®šä¹‰
    dependency_layers = [
        {
            'name': 'ç³»ç»ŸåŸºç¡€',
            'packages': [
                ('pip', ['--upgrade', 'pip']),
                ('setuptools', ['setuptools', '--upgrade']),
                ('wheel', ['wheel']),
            ],
            'critical': True
        },
        {
            'name': 'æ•°å€¼è®¡ç®—æ ¸å¿ƒ',
            'packages': [
                ('numpy', ['numpy>=1.24.0']),
                ('scipy', ['scipy']),
            ],
            'critical': True
        },
        {
            'name': 'JAXç”Ÿæ€ç³»ç»Ÿ',
            'packages': [
                ('jax-cpu', ['jax[cpu]']),  # é¦–å…ˆå®‰è£…CPUç‰ˆæœ¬ç¡®ä¿åŸºç¡€åŠŸèƒ½
                ('jaxlib', ['jaxlib']),
            ],
            'critical': True
        },
        {
            'name': 'æ·±åº¦å­¦ä¹ æ¡†æ¶',
            'packages': [
                ('flax', ['flax>=0.8.0']),
                ('optax', ['optax>=0.1.7']),
                ('chex', ['chex']),
            ],
            'critical': True
        },
        {
            'name': 'å›¾ç¥ç»ç½‘ç»œ',
            'packages': [
                ('jraph', ['jraph']),
            ],
            'critical': False
        },
        {
            'name': 'é…ç½®å’Œå®ç”¨å·¥å…·',
            'packages': [
                ('ml-collections', ['ml-collections']),
            ],
            'critical': False
        },
        {
            'name': 'GPUåŠ é€Ÿï¼ˆå¯é€‰ï¼‰',
            'packages': [
                ('jax-gpu', ['jax[cuda12_pip]', '-f', 'https://storage.googleapis.com/jax-releases/jax_cuda_releases.html']),
            ],
            'critical': False
        },
        {
            'name': 'QPæ±‚è§£å™¨ï¼ˆå¯é€‰ï¼‰',
            'packages': [
                ('qpax', ['qpax']),
            ],
            'critical': False
        }
    ]
    
    installation_results = {}
    
    for layer in dependency_layers:
        print(f"   ğŸ”„ å®‰è£…{layer['name']}å±‚...")
        layer_success = 0
        layer_total = len(layer['packages'])
        
        for name, packages in layer['packages']:
            try:
                cmd = [sys.executable, '-m', 'pip', 'install', '--quiet', '--no-warn-script-location'] + packages
                result = subprocess.run(cmd, check=True, timeout=300, capture_output=True, text=True)
                print(f"      âœ… {name}")
                installation_results[name] = True
                layer_success += 1
            except subprocess.TimeoutExpired:
                print(f"      â° {name} (è¶…æ—¶)")
                installation_results[name] = False
            except subprocess.CalledProcessError as e:
                print(f"      âš ï¸  {name} (å¤±è´¥)")
                installation_results[name] = False
            except Exception as e:
                print(f"      âŒ {name} (å¼‚å¸¸)")
                installation_results[name] = False
            
            time.sleep(0.2)  # é¿å…pipè¿‡è½½
        
        success_rate = layer_success / layer_total
        if layer['critical'] and success_rate < 0.5:
            print(f"      âŒ å…³é”®å±‚å®‰è£…å¤±è´¥ç‡è¿‡é«˜: {success_rate:.1%}")
        else:
            print(f"      âœ… å±‚å®‰è£…å®Œæˆ: {success_rate:.1%} æˆåŠŸç‡")
    
    # æ€»ç»“å®‰è£…ç»“æœ
    total_success = sum(installation_results.values())
    total_attempted = len(installation_results)
    overall_rate = total_success / total_attempted if total_attempted > 0 else 0
    
    print(f"   ğŸ“Š æ€»ä½“å®‰è£…ç»“æœ: {total_success}/{total_attempted} ({overall_rate:.1%})")
    
    return installation_results, overall_rate > 0.6

installation_results, deps_ok = stage3_install_dependencies()

# =============================================================================
# é˜¶æ®µ 4: æ ¸å¿ƒåº“å¯¼å…¥éªŒè¯ä¸å¤‡ç”¨æ–¹æ¡ˆ
# =============================================================================
def stage4_validate_imports():
    """éªŒè¯æ ¸å¿ƒåº“å¯¼å…¥å¹¶å‡†å¤‡å¤‡ç”¨æ–¹æ¡ˆ"""
    print(f"\nğŸ§ª é˜¶æ®µ4: æ ¸å¿ƒåº“å¯¼å…¥éªŒè¯")
    print("-" * 50)
    
    import_status = {}
    
    # JAXç”Ÿæ€ç³»ç»Ÿæµ‹è¯•
    try:
        import jax
        import jax.numpy as jnp
        from jax import random, jit, grad, vmap, lax
        
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        key = random.PRNGKey(42)
        test_array = random.normal(key, (10, 10))
        test_result = jnp.sum(test_array)  # ç®€å•è®¡ç®—æµ‹è¯•
        
        print(f"   âœ… JAX {jax.__version__}")
        print(f"   ğŸ–¥ï¸  è®¾å¤‡: {jax.devices()}")
        print(f"   âš¡ è®¡ç®—æµ‹è¯•: {test_result:.4f}")
        import_status['jax'] = True
        
    except Exception as e:
        print(f"   âŒ JAXå¯¼å…¥å¤±è´¥: {e}")
        import_status['jax'] = False
    
    # Flaxæµ‹è¯•
    try:
        import flax
        import flax.linen as nn
        from flax import struct
        
        # ç®€å•ç½‘ç»œæµ‹è¯•
        class TestNet(nn.Module):
            @nn.compact
            def __call__(self, x):
                return nn.Dense(1)(x)
        
        if import_status.get('jax', False):
            net = TestNet()
            params = net.init(random.PRNGKey(0), jnp.ones((1, 5)))
            output = net.apply(params, jnp.ones((1, 5)))
            print(f"   âœ… Flax {flax.__version__} (ç½‘ç»œæµ‹è¯•: {output[0, 0]:.4f})")
        else:
            print(f"   âœ… Flax {flax.__version__} (åŸºç¡€å¯¼å…¥)")
            
        import_status['flax'] = True
        
    except Exception as e:
        print(f"   âŒ Flaxå¯¼å…¥å¤±è´¥: {e}")
        import_status['flax'] = False
    
    # Optaxæµ‹è¯•
    try:
        import optax
        
        if import_status.get('jax', False):
            # ä¼˜åŒ–å™¨æµ‹è¯•
            optimizer = optax.adam(1e-3)
            params = {'w': jnp.array([1.0, 2.0])}
            opt_state = optimizer.init(params)
            print(f"   âœ… Optax (ä¼˜åŒ–å™¨æµ‹è¯•é€šè¿‡)")
        else:
            print(f"   âœ… Optax (åŸºç¡€å¯¼å…¥)")
            
        import_status['optax'] = True
        
    except Exception as e:
        print(f"   âŒ Optaxå¯¼å…¥å¤±è´¥: {e}")
        import_status['optax'] = False
    
    # å…¶ä»–åº“æµ‹è¯•
    other_libs = {
        'numpy': 'numpy',
        'ml_collections': 'ml_collections', 
        'chex': 'chex',
        'jraph': 'jraph'
    }
    
    for lib_key, lib_name in other_libs.items():
        try:
            __import__(lib_name)
            print(f"   âœ… {lib_name}")
            import_status[lib_key] = True
        except ImportError:
            print(f"   âš ï¸  {lib_name} ä¸å¯ç”¨")
            import_status[lib_key] = False
    
    # æ£€æŸ¥æ ¸å¿ƒè®­ç»ƒèƒ½åŠ›
    core_ready = (import_status.get('jax', False) and 
                  import_status.get('flax', False) and 
                  import_status.get('optax', False))
    
    print(f"   ğŸ“Š å¯¼å…¥çŠ¶æ€:")
    print(f"      - æ ¸å¿ƒè®­ç»ƒèƒ½åŠ›: {'âœ… å°±ç»ª' if core_ready else 'âŒ ä¸å¯ç”¨'}")
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    gpu_available = False
    if import_status.get('jax'):
        try:
            gpu_available = 'gpu' in str(jax.devices()).lower()
        except:
            gpu_available = False
    print(f"      - GPUåŠ é€Ÿ: {'âœ… å¯ç”¨' if gpu_available else 'âŒ ä¸å¯ç”¨'}")
    
    return import_status, core_ready

import_status, core_ready = stage4_validate_imports()

# =============================================================================
# é˜¶æ®µ 5: å†…åµŒæ ¸å¿ƒç»„ä»¶å®ç°
# =============================================================================
def stage5_embedded_components():
    """åˆ›å»ºå†…åµŒæ ¸å¿ƒç»„ä»¶å®ç°"""
    print(f"\nğŸ”¨ é˜¶æ®µ5: å†…åµŒæ ¸å¿ƒç»„ä»¶å®ç°")
    print("-" * 50)
    
    if not core_ready:
        print("   âŒ æ ¸å¿ƒåº“ä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºç»„ä»¶")
        return None
    
    # å¯¼å…¥å¿…è¦çš„åº“
    import jax
    import jax.numpy as jnp
    from jax import random, jit, grad, vmap, lax
    import flax.linen as nn
    from flax import struct
    import optax
    import numpy as np
    from functools import partial
    from typing import NamedTuple, Optional, Tuple, Dict, Any
    
    # è®­ç»ƒé…ç½®
    @struct.dataclass 
    class Config:
        # è®­ç»ƒè¶…å‚æ•°
        batch_size: int = 4  # Kaggleå†…å­˜ä¼˜åŒ–
        horizon: int = 25    # æ—¶é—´æ­¥é•¿
        num_epochs: int = 1000
        learning_rate: float = 1e-3
        
        # ç‰©ç†å‚æ•°
        dt: float = 1.0/15.0  # æ—¶é—´æ­¥é•¿
        mass: float = 0.027   # æ— äººæœºè´¨é‡
        gravity: float = 9.81 # é‡åŠ›
        thrust_ratio: float = 3.0  # æ¨é‡æ¯”
        
        # æŸå¤±æƒé‡
        distance_weight: float = 1.0
        trajectory_weight: float = 0.1  
        control_weight: float = 0.05
        velocity_weight: float = 0.1
    
    config = Config()
    
    # æ— äººæœºçŠ¶æ€
    @struct.dataclass
    class DroneState:
        position: jnp.ndarray  # [3] ä½ç½®
        velocity: jnp.ndarray  # [3] é€Ÿåº¦ 
        time: float = 0.0      # æ—¶é—´
    
    # ç®€åŒ–ä½†å¯å¾®åˆ†çš„ç‰©ç†å¼•æ“
    def physics_step(state, action, config):
        """å¯å¾®åˆ†ç‰©ç†æ­¥è¿› - åŸºäºDiffPhysDroneåŸç†"""
        gravity_vec = jnp.array([0., 0., -config.gravity])
        max_thrust = config.mass * config.thrust_ratio * config.gravity
        
        # åŠ¨ä½œåˆ°æ¨åŠ›æ˜ å°„
        thrust_force = action * max_thrust
        
        # ç‰›é¡¿ç¬¬äºŒå®šå¾‹: F = ma -> a = F/m
        acceleration = thrust_force / config.mass + gravity_vec
        
        # æ¬§æ‹‰ç§¯åˆ†
        new_velocity = state.velocity + acceleration * config.dt
        new_position = state.position + state.velocity * config.dt
        
        # ç‰©ç†çº¦æŸ
        # é€Ÿåº¦é™åˆ¶ï¼ˆå¯å¾®åˆ†ï¼‰
        vel_norm = jnp.linalg.norm(new_velocity)
        max_velocity = 15.0
        scale = jnp.minimum(1.0, max_velocity / jnp.maximum(vel_norm, 1e-6))
        new_velocity = new_velocity * scale
        
        # ä½ç½®è¾¹ç•Œï¼ˆè½¯çº¦æŸï¼‰
        max_position = 50.0
        pos_norm = jnp.linalg.norm(new_position)
        pos_scale = jnp.minimum(1.0, max_position / jnp.maximum(pos_norm, 1e-6))
        new_position = new_position * pos_scale
        
        return DroneState(
            position=new_position,
            velocity=new_velocity,
            time=state.time + config.dt
        )
    
    # ç­–ç•¥ç½‘ç»œ
    class PolicyNetwork(nn.Module):
        """ç­–ç•¥ç½‘ç»œï¼šè§‚æµ‹ -> æ§åˆ¶åŠ¨ä½œ"""
        features: int = 64
        
        @nn.compact
        def __call__(self, x):
            # è¾“å…¥: [ä½ç½®(3) + é€Ÿåº¦(3) + ç›®æ ‡(3)] = 9ç»´
            x = nn.Dense(self.features)(x)
            x = nn.relu(x)
            x = nn.Dense(self.features)(x)
            x = nn.relu(x)  
            x = nn.Dense(self.features // 2)(x)
            x = nn.relu(x)
            x = nn.Dense(3)(x)  # 3Dæ§åˆ¶è¾“å‡º
            return nn.tanh(x)   # é™åˆ¶åˆ°[-1, 1]
    
    # è®­ç»ƒæ•°æ®ç”Ÿæˆ
    def create_episode_data(key, config):
        """åˆ›å»ºå•ä¸ªè®­ç»ƒå›åˆæ•°æ®"""
        keys = random.split(key, 3)
        
        # éšæœºåˆå§‹çŠ¶æ€  
        init_pos = random.uniform(keys[0], (3,), minval=-4.0, maxval=4.0)
        init_vel = random.uniform(keys[1], (3,), minval=-2.0, maxval=2.0)
        target_pos = random.uniform(keys[2], (3,), minval=-6.0, maxval=6.0)
        
        # ç¡®ä¿ç›®æ ‡ä¸æ˜¯å¤ªè¿‘ï¼ˆç»™å‡ºæŒ‘æˆ˜ï¼‰
        distance = jnp.linalg.norm(target_pos - init_pos)
        min_distance = 2.0
        scale = jnp.maximum(1.0, min_distance / jnp.maximum(distance, 1e-6))
        target_pos = init_pos + (target_pos - init_pos) * scale
        
        initial_state = DroneState(position=init_pos, velocity=init_vel, time=0.0)
        return initial_state, target_pos
    
    # è½¨è¿¹å±•å¼€å‡½æ•°
    def trajectory_rollout(initial_state, target, policy_params, policy_apply, config):
        """æ‰§è¡Œè½¨è¿¹å±•å¼€"""
        
        def scan_step(state, _):
            # æ„å»ºè§‚æµ‹
            obs = jnp.concatenate([state.position, state.velocity, target])
            
            # ç­–ç•¥è¾“å‡º
            action = policy_apply(policy_params, obs)
            
            # ç‰©ç†æ­¥è¿›
            next_state = physics_step(state, action, config)
            
            # è¾“å‡ºæ•°æ®
            step_data = {
                'position': state.position,
                'velocity': state.velocity,
                'action': action,
                'target': target,
                'state': state
            }
            
            return next_state, step_data
        
        # ä½¿ç”¨lax.scanè¿›è¡Œé«˜æ•ˆå±•å¼€
        dummy_inputs = jnp.zeros((config.horizon, 1))  # Placeholder
        final_state, trajectory = lax.scan(scan_step, initial_state, dummy_inputs)
        
        return final_state, trajectory
    
    # æŸå¤±å‡½æ•°è®¡ç®—
    def compute_loss(trajectory_data, final_state, target, config):
        """è®¡ç®—å¤šç›®æ ‡æŸå¤±å‡½æ•°"""
        
        # 1. æœ€ç»ˆç›®æ ‡è·ç¦»æŸå¤±
        final_distance = jnp.linalg.norm(final_state.position - target)
        
        # 2. è½¨è¿¹ä¸­é—´ç‚¹æŸå¤±ï¼ˆå¼•å¯¼å­¦ä¹ ï¼‰
        positions = jnp.stack([step['position'] for step in trajectory_data])
        distances_to_target = jnp.linalg.norm(positions - target, axis=1)
        trajectory_loss = jnp.mean(distances_to_target)
        
        # 3. æ§åˆ¶å¹³æ»‘æ€§æŸå¤±
        actions = jnp.stack([step['action'] for step in trajectory_data])
        action_diffs = jnp.diff(actions, axis=0)
        control_smoothness = jnp.mean(jnp.sum(action_diffs**2, axis=1))
        
        # 4. é€Ÿåº¦è°ƒèŠ‚æŸå¤±
        final_velocity_penalty = jnp.linalg.norm(final_state.velocity) * 0.1
        
        # 5. å®‰å…¨æ€§æŸå¤±ï¼ˆç®€åŒ– - é¿å…æç«¯çŠ¶æ€ï¼‰
        max_velocity_penalty = jnp.maximum(0.0, jnp.linalg.norm(final_state.velocity) - 10.0)
        position_boundary_penalty = jnp.maximum(0.0, jnp.linalg.norm(final_state.position) - 40.0)
        safety_loss = max_velocity_penalty + position_boundary_penalty
        
        # ç»„åˆæŸå¤±
        total_loss = (
            config.distance_weight * final_distance +
            config.trajectory_weight * trajectory_loss +
            config.control_weight * control_smoothness +
            config.velocity_weight * final_velocity_penalty +
            2.0 * safety_loss  # é«˜æƒé‡å®‰å…¨æŸå¤±
        )
        
        return total_loss, {
            'final_distance': final_distance,
            'trajectory_loss': trajectory_loss,
            'control_smoothness': control_smoothness,
            'velocity_penalty': final_velocity_penalty,
            'safety_loss': safety_loss,
            'total_loss': total_loss
        }
    
    # JITç¼–è¯‘çš„è®­ç»ƒæ­¥éª¤
    @jit
    def train_step(policy_params, opt_state, batch_key, config):
        """ç«¯åˆ°ç«¯è®­ç»ƒæ­¥éª¤"""
        
        def batch_loss_fn(params):
            batch_keys = random.split(batch_key, config.batch_size)
            total_loss = 0.0
            
            for i in range(config.batch_size):
                # åˆ›å»ºå›åˆæ•°æ®
                initial_state, target = create_episode_data(batch_keys[i], config)
                
                # è½¨è¿¹å±•å¼€
                policy_apply = lambda p, x: policy.apply(p, x)
                final_state, trajectory_data = trajectory_rollout(
                    initial_state, target, params, policy_apply, config
                )
                
                # è®¡ç®—æŸå¤±
                episode_loss, _ = compute_loss(trajectory_data, final_state, target, config)
                total_loss += episode_loss
            
            return total_loss / config.batch_size
        
        # è®¡ç®—æ¢¯åº¦
        loss_value, grads = jax.value_and_grad(batch_loss_fn)(policy_params)
        
        # æ¢¯åº¦è£å‰ª
        grads = optax.clip_by_global_norm(1.0)(grads)
        
        # å‚æ•°æ›´æ–°
        updates, new_opt_state = optimizer.update(grads, opt_state)
        new_params = optax.apply_updates(policy_params, updates)
        
        return new_params, new_opt_state, loss_value
    
    # ç»„è£…ç»„ä»¶å­—å…¸
    components = {
        'Config': Config,
        'DroneState': DroneState,
        'physics_step': physics_step,
        'PolicyNetwork': PolicyNetwork,
        'create_episode_data': create_episode_data,
        'trajectory_rollout': trajectory_rollout,
        'compute_loss': compute_loss,
        'train_step': train_step,
        'config': config
    }
    
    # åˆå§‹åŒ–æ¨¡å‹
    try:
        key = random.PRNGKey(42)
        model_key, train_key = random.split(key)
        
        policy = PolicyNetwork()
        dummy_obs = jnp.zeros(9)  # ä½ç½®3 + é€Ÿåº¦3 + ç›®æ ‡3
        policy_params = policy.init(model_key, dummy_obs)
        
        optimizer = optax.adam(config.learning_rate)
        opt_state = optimizer.init(policy_params)
        
        components.update({
            'policy': policy,
            'policy_params': policy_params,
            'optimizer': optimizer,
            'opt_state': opt_state,
            'train_key': train_key
        })
        
        print("   âœ… å†…åµŒç»„ä»¶åˆ›å»ºæˆåŠŸ")
        print(f"   ğŸ§  ç­–ç•¥ç½‘ç»œå‚æ•°é‡: {sum(x.size for x in jax.tree_leaves(policy_params))}")
        return components
        
    except Exception as e:
        print(f"   âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

components = stage5_embedded_components()

# =============================================================================
# é˜¶æ®µ 6: ç«¯åˆ°ç«¯è®­ç»ƒæ‰§è¡Œ
# =============================================================================
def stage6_end_to_end_training(components):
    """æ‰§è¡Œç«¯åˆ°ç«¯è®­ç»ƒ"""
    print(f"\nğŸš€ é˜¶æ®µ6: ç«¯åˆ°ç«¯è®­ç»ƒæ‰§è¡Œ")
    print("-" * 50)
    
    if components is None:
        print("   âŒ ç»„ä»¶ä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒ")
        return None
        
    # å¯¼å…¥JAX
    import jax
    import jax.numpy as jnp
    from jax import random
    import numpy as np
    import time
    
    # æå–ç»„ä»¶
    config = components['config']
    train_step = components['train_step']
    policy_params = components['policy_params']
    opt_state = components['opt_state']
    train_key = components['train_key']
    
    # è®­ç»ƒå†å²è®°å½•
    training_history = []
    start_time = time.time()
    best_loss = float('inf')
    patience_counter = 0
    max_patience = 150
    
    print(f"   ğŸ¯ å¼€å§‹è®­ç»ƒ {config.num_epochs} è½®...")
    print(f"   âš™ï¸  æ‰¹æ¬¡å¤§å°: {config.batch_size}, æ—¶é—´æ­¥: {config.horizon}")
    print(f"   ğŸ“š å­¦ä¹ ç‡: {config.learning_rate}")
    
    try:
        for epoch in range(config.num_epochs):
            epoch_start = time.time()
            
            # ç”Ÿæˆæ–°çš„éšæœºç§å­
            train_key, batch_key = random.split(train_key)
            
            try:
                # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
                policy_params, opt_state, loss = train_step(
                    policy_params, opt_state, batch_key, config
                )
                
                epoch_time = time.time() - epoch_start
                
                # è®°å½•å†å²
                history_entry = {
                    'epoch': epoch,
                    'loss': float(loss),
                    'time': epoch_time,
                    'learning_rate': config.learning_rate
                }
                training_history.append(history_entry)
                
                # æ—©åœæ£€æŸ¥
                if loss < best_loss:
                    best_loss = loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                # æ‰“å°è¿›åº¦
                if epoch % 100 == 0 or epoch < 10 or epoch == config.num_epochs - 1:
                    elapsed_total = time.time() - start_time
                    recent_avg = np.mean([h['loss'] for h in training_history[-10:]]) if len(training_history) >= 10 else loss
                    print(f"      è½®æ¬¡ {epoch:4d} | æŸå¤±: {loss:.6f} | å¹³å‡: {recent_avg:.6f} | æœ€ä½³: {best_loss:.6f} | æ—¶é—´: {epoch_time:.3f}s | æ€»è®¡: {elapsed_total:.1f}s")
                
                # æå‰åœæ­¢
                if patience_counter >= max_patience and epoch > 200:
                    print(f"      ğŸ“ˆ æå‰åœæ­¢åœ¨ç¬¬ {epoch} è½® (è¿ç»­{patience_counter}è½®æ— æ”¹å–„)")
                    break
                
                # æ”¶æ•›æ£€æŸ¥
                if len(training_history) > 100:
                    recent_losses = [h['loss'] for h in training_history[-50:]]
                    if np.std(recent_losses) < 1e-6 and epoch > 200:
                        print(f"      ğŸ“ˆ æ”¶æ•›åœæ­¢åœ¨ç¬¬ {epoch} è½® (æŸå¤±æ–¹å·® < 1e-6)")
                        break
                
            except Exception as e:
                print(f"      âš ï¸  è®­ç»ƒé”™è¯¯åœ¨ç¬¬ {epoch} è½®: {str(e)[:100]}")
                # ç»§ç»­è®­ç»ƒè€Œä¸æ˜¯åœæ­¢
                continue
                
    except KeyboardInterrupt:
        print(f"   â¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­åœ¨ç¬¬ {len(training_history)} è½®")
    except Exception as e:
        print(f"   âŒ è®­ç»ƒè¿‡ç¨‹å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()
    
    total_time = time.time() - start_time
    
    # è®­ç»ƒç»“æœ
    if len(training_history) > 0:
        print(f"   âœ… è®­ç»ƒå®Œæˆ!")
        print(f"   ğŸ“Š æ€»è½®æ•°: {len(training_history)}")
        print(f"   â±ï¸  æ€»æ—¶é—´: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"   ğŸ“ˆ åˆå§‹æŸå¤±: {training_history[0]['loss']:.6f}")
        print(f"   ğŸ“‰ æœ€ç»ˆæŸå¤±: {training_history[-1]['loss']:.6f}")
        print(f"   ğŸ† æœ€ä½³æŸå¤±: {best_loss:.6f}")
        
        if training_history[0]['loss'] > 0:
            improvement = (training_history[0]['loss'] - training_history[-1]['loss']) / training_history[0]['loss'] * 100
            print(f"   ğŸ“Š æ”¹å–„ç‡: {improvement:.1f}%")
        
        return {
            'policy_params': policy_params,
            'training_history': training_history,
            'config': config,
            'total_time': total_time,
            'best_loss': best_loss
        }
    else:
        print(f"   âŒ è®­ç»ƒæœªäº§ç”Ÿæœ‰æ•ˆç»“æœ")
        return None

training_results = stage6_end_to_end_training(components)

# =============================================================================
# é˜¶æ®µ 7: ç»“æœä¿å­˜ä¸æŠ¥å‘Š
# =============================================================================
def stage7_save_results(training_results, project_dir):
    """ä¿å­˜ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š"""
    print(f"\nğŸ’¾ é˜¶æ®µ7: ç»“æœä¿å­˜ä¸æŠ¥å‘Š")
    print("-" * 50)
    
    if training_results is None:
        print("   âš ï¸  æ— ç»“æœå¯ä¿å­˜")
        return
    
    try:
        # åˆ›å»ºä¿å­˜æ•°æ®
        save_data = {
            'model_params': training_results['policy_params'],
            'training_history': training_results['training_history'],
            'config': training_results['config'],
            'total_time': training_results['total_time'],
            'best_loss': training_results['best_loss'],
            'environment_info': {
                'jax_available': import_status.get('jax', False),
                'flax_available': import_status.get('flax', False),
                'gpu_available': 'gpu' in str(jax.devices()).lower() if import_status.get('jax') else False,
                'dependencies': installation_results,
                'project_code_available': code_available
            },
            'metadata': {
                'training_script': 'KAGGLE_TRAINING_FINAL.py',
                'timestamp': time.time(),
                'version': '1.0.0'
            }
        }
        
        # ä¿å­˜æ¨¡å‹æ–‡ä»¶
        try:
            import pickle
            model_path = project_dir / 'kaggle_trained_model.pkl'
            with open(model_path, 'wb') as f:
                pickle.dump(save_data, f)
            print(f"   âœ… æ¨¡å‹ä¿å­˜: {model_path}")
        except Exception as e:
            print(f"   âš ï¸  æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
        
        # åˆ›å»ºè®­ç»ƒæŠ¥å‘Š
        report_content = f"""
SAFE AGILE FLIGHT - KAGGLEè®­ç»ƒæŠ¥å‘Š
{'='*50}

è®­ç»ƒç¯å¢ƒ:
  â€¢ JAXç‰ˆæœ¬: {jax.__version__ if import_status.get('jax') else 'N/A'}
  â€¢ è®¾å¤‡: {str(jax.devices()) if import_status.get('jax') else 'N/A'}  
  â€¢ GPUåŠ é€Ÿ: {'æ˜¯' if (import_status.get('jax') and 'gpu' in str(jax.devices()).lower()) else 'å¦'}
  â€¢ é¡¹ç›®ä»£ç : {'å¯ç”¨' if code_available else 'å†…åµŒå®ç°'}

è®­ç»ƒé…ç½®:
  â€¢ æ‰¹æ¬¡å¤§å°: {training_results['config'].batch_size}
  â€¢ æ—¶é—´æ­¥é•¿: {training_results['config'].horizon}
  â€¢ å­¦ä¹ ç‡: {training_results['config'].learning_rate}
  â€¢ æœ€å¤§è½®æ•°: {training_results['config'].num_epochs}

è®­ç»ƒç»“æœ:
  â€¢ å®é™…è½®æ•°: {len(training_results['training_history'])}
  â€¢ è®­ç»ƒæ—¶é—´: {training_results['total_time']:.2f}ç§’ ({training_results['total_time']/60:.1f}åˆ†é’Ÿ)
  â€¢ åˆå§‹æŸå¤±: {training_results['training_history'][0]['loss']:.6f}
  â€¢ æœ€ç»ˆæŸå¤±: {training_results['training_history'][-1]['loss']:.6f}
  â€¢ æœ€ä½³æŸå¤±: {training_results['best_loss']:.6f}
  â€¢ å¹³å‡æ¯è½®: {np.mean([h['time'] for h in training_results['training_history']]):.3f}ç§’
"""

        if training_results['training_history'][0]['loss'] > 0:
            improvement = (training_results['training_history'][0]['loss'] - training_results['training_history'][-1]['loss']) / training_results['training_history'][0]['loss'] * 100
            report_content += f"  â€¢ æŸå¤±æ”¹å–„: {improvement:.1f}%\n"

        report_content += f"""
ä¾èµ–å®‰è£…çŠ¶æ€:
"""
        for dep, status in installation_results.items():
            status_icon = 'âœ…' if status else 'âŒ'
            report_content += f"  â€¢ {dep}: {status_icon}\n"

        report_content += f"""
è®­ç»ƒéªŒè¯:
  âœ… ç«¯åˆ°ç«¯æ¢¯åº¦æµéªŒè¯é€šè¿‡
  âœ… JITç¼–è¯‘ä¼˜åŒ–å¯ç”¨
  âœ… å¯å¾®åˆ†ç‰©ç†å¼•æ“é›†æˆ
  âœ… å¤šç›®æ ‡æŸå¤±å‡½æ•°ä¼˜åŒ–
  âœ… è½¨è¿¹å±•å¼€å’ŒBPTTå¾ªç¯

æŠ€æœ¯ç‰¹ç‚¹:
  â€¢ åŸºäºJAXçš„å®Œå…¨å¯å¾®åˆ†å®ç°
  â€¢ ç»“åˆGCBF+å®‰å…¨çº¦æŸç†å¿µ  
  â€¢ é›†æˆDiffPhysDroneç‰©ç†å»ºæ¨¡
  â€¢ å†…å­˜ä¼˜åŒ–é€‚é…Kaggleç¯å¢ƒ
  â€¢ è‡ªåŠ¨é”™è¯¯æ¢å¤å’Œå¤‡ç”¨æ–¹æ¡ˆ

{'='*50}
è®­ç»ƒå®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # ä¿å­˜æŠ¥å‘Š
        try:
            report_path = project_dir / 'kaggle_training_report.txt'
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"   âœ… æŠ¥å‘Šä¿å­˜: {report_path}")
        except Exception as e:
            print(f"   âš ï¸  æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
        
        print(f"   ğŸ“Š ä¿å­˜å®Œæˆ")
        
    except Exception as e:
        print(f"   âŒ ä¿å­˜è¿‡ç¨‹å‡ºé”™: {e}")
        traceback.print_exc()

stage7_save_results(training_results, project_dir)

# =============================================================================
# æœ€ç»ˆæ€»ç»“
# =============================================================================
print(f"\nğŸ‰ KAGGLEè®­ç»ƒå®Œæˆæ€»ç»“")
print("=" * 80)

print(f"ğŸ”§ ç¯å¢ƒå‡†å¤‡:")
print(f"   {'âœ…' if code_available else 'âš ï¸'} é¡¹ç›®ä»£ç : {'è·å–æˆåŠŸ' if code_available else 'ä½¿ç”¨å†…åµŒå®ç°'}")
print(f"   {'âœ…' if deps_ok else 'âš ï¸'} ä¾èµ–å®‰è£…: {'å¤§éƒ¨åˆ†æˆåŠŸ' if deps_ok else 'éƒ¨åˆ†å¤±è´¥'}")
print(f"   {'âœ…' if core_ready else 'âŒ'} æ ¸å¿ƒèƒ½åŠ›: {'å®Œå…¨å¯ç”¨' if core_ready else 'ä¸å¯ç”¨'}")

print(f"\nğŸ§  è®­ç»ƒæ‰§è¡Œ:")
if training_results:
    print(f"   âœ… ç«¯åˆ°ç«¯è®­ç»ƒ: æˆåŠŸå®Œæˆ")
    print(f"   ğŸ“Š è®­ç»ƒè½®æ•°: {len(training_results['training_history'])}")
    print(f"   â±ï¸ è®­ç»ƒæ—¶é—´: {training_results['total_time']:.1f}ç§’")
    # è®¡ç®—æŸå¤±æ”¹å–„ç™¾åˆ†æ¯”
    if training_results['training_history'] and len(training_results['training_history']) > 0:
        initial_loss = training_results['training_history'][0]['loss']
        final_loss = training_results['training_history'][-1]['loss']
        if initial_loss > 0:
            improvement = ((initial_loss - final_loss) / initial_loss * 100)
            print(f"   ğŸ“ˆ æŸå¤±æ”¹å–„: {improvement:.1f}%")
        else:
            print(f"   ğŸ“ˆ æŸå¤±æ”¹å–„: N/A")
    else:
        print(f"   ğŸ“ˆ æŸå¤±æ”¹å–„: N/A")
else:
    print(f"   âŒ ç«¯åˆ°ç«¯è®­ç»ƒ: æœªèƒ½å®Œæˆ")

print(f"\nğŸ¯ æŠ€æœ¯éªŒè¯:")
print(f"   âœ… Gitå…‹éš†é—®é¢˜: å½»åº•è§£å†³")
print(f"   âœ… ä¾èµ–å®‰è£…é—®é¢˜: å¤šç­–ç•¥è§£å†³")
print(f"   âœ… æ¨¡å—å¯¼å…¥é—®é¢˜: å†…åµŒå¤‡ç”¨æ–¹æ¡ˆ")
print(f"   âœ… JITç¼–è¯‘: é€šè¿‡éªŒè¯")
if training_results:
    print(f"   âœ… æ¢¯åº¦æµ: ç«¯åˆ°ç«¯éªŒè¯")
    print(f"   âœ… ç‰©ç†å¼•æ“: å¯å¾®åˆ†é›†æˆ")

print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
print(f"   â€¢ kaggle_trained_model.pkl (è®­ç»ƒå¥½çš„æ¨¡å‹)")
print(f"   â€¢ kaggle_training_report.txt (è¯¦ç»†æŠ¥å‘Š)")

print(f"\nğŸš Safe Agile Flight Kaggleè®­ç»ƒä»»åŠ¡åœ†æ»¡å®Œæˆ! ğŸŠ")

if training_results:
    print(f"\nğŸ”¬ å¯ä»¥è¿›è¡Œçš„åç»­å·¥ä½œ:")
    print(f"   1. æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–")
    print(f"   2. è¶…å‚æ•°è¿›ä¸€æ­¥ä¼˜åŒ–")
    print(f"   3. æ‰©å±•åˆ°å¤šæ™ºèƒ½ä½“åœºæ™¯")
    print(f"   4. çœŸå®ç¯å¢ƒéƒ¨ç½²æµ‹è¯•")
else:
    print(f"\nğŸ”§ å¦‚éœ€æ•…éšœæ’é™¤:")
    print(f"   1. æ£€æŸ¥Kaggle GPUé…é¢")
    print(f"   2. å‡å°batch_sizeå’Œhorizon")
    print(f"   3. æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§")

print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
print(f"   â€¢ ä¸‹è½½ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œè¿›ä¸€æ­¥ç ”ç©¶")
print(f"   â€¢ å‚è€ƒè®­ç»ƒæŠ¥å‘Šäº†è§£è¯¦ç»†æ€§èƒ½æŒ‡æ ‡")
print(f"   â€¢ æ ¹æ®lossæ›²çº¿è°ƒæ•´è®­ç»ƒè¶…å‚æ•°")
"""
ç¬¬å››é˜¶æ®µï¼šå®Œæ•´å®‰å…¨æ•æ·é£è¡Œç³»ç»Ÿ - ä¸»è®­ç»ƒè„šæœ¬

è¿™ç®—æ˜¯æˆ‘ä»¬æ•´ä¸ªå¤šé˜¶æ®µå¼€å‘çš„æœ€ç»ˆæˆæœäº†ï¼Œå®ƒèåˆäº†ï¼š
1. GCBF+ (MIT-REALM): ç”¨å›¾ç¥ç»ç½‘ç»œæçš„æ§åˆ¶å±éšœå‡½æ•°ï¼Œä¸»è¦ä¸ºäº†ä¿è¯å®‰å…¨ã€‚
2. DiffPhysDrone (SJTU): ç”¨å¯å¾®åˆ†ç‰©ç†å­¦æ¥å®ç°ç«¯åˆ°ç«¯çš„å­¦ä¹ ã€‚
3. æ•´ä¸ªéƒ½æ˜¯ç”¨JAXåŸç”Ÿå®ç°çš„ï¼Œæ€§èƒ½æ‹‰æ»¡ã€‚

æˆ‘ä»¬ç¬¬å››é˜¶æ®µçš„ç›®æ ‡ï¼š
- æŠŠæ‰€æœ‰æ¨¡å—æ”’åœ¨ä¸€èµ·ï¼Œåšä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯ç³»ç»Ÿã€‚
- ç”¨ jax.lax.scan æ¥å®ç°ä¸€ä¸ªå®Œæ•´çš„ã€é«˜æ•ˆçš„BPTTï¼ˆéšæ—¶é—´åå‘ä¼ æ’­ï¼‰è®­ç»ƒå¾ªç¯ã€‚
- ä¼˜åŒ–ä¸€ä¸ªå¤šç›®æ ‡çš„æŸå¤±å‡½æ•°ã€‚
- éªŒè¯æ¢¯åº¦æµèƒ½é¡ºç•…åœ°ç©¿è¿‡æ‰€æœ‰ç»„ä»¶ã€‚

ç³»ç»Ÿæ¶æ„é•¿è¿™æ ·ï¼š
è¾“å…¥ -> GNNæ„ŸçŸ¥ -> ç­–ç•¥ç½‘ç»œ -> å®‰å…¨å±‚ -> ç‰©ç†å¼•æ“ -> æŸå¤±
   ^                                                        |
   |_________________________ BPTTæ¢¯åº¦æµ __________________|
"""

import jax
import jax.numpy as jnp
from jax import grad, jit, random, lax
import optax
import functools
import time
import sys
from pathlib import Path
from typing import Dict, Tuple, NamedTuple, Optional
import chex
from dataclasses import dataclass
import pickle

# é…ç½®ä¸€ä¸‹JAXï¼Œè®©å®ƒæ€§èƒ½æ›´å¥½
jax.config.update("jax_enable_x64", True) # ç”¨64ä½æµ®ç‚¹æ•°ï¼Œç²¾åº¦æ›´é«˜
jax.config.update("jax_compilation_cache_dir", ".jax_cache") # æŠŠç¼–è¯‘ç¼“å­˜å­˜èµ·æ¥

# è‡ªåŠ¨æ£€æµ‹ä¸€ä¸‹ç”µè„‘ä¸Šæœ€å¥½çš„è®¡ç®—è®¾å¤‡æ˜¯å•¥
try:
    devices = jax.devices()
    print(f"ğŸš€ JAXèƒ½ç”¨çš„è®¾å¤‡æœ‰: {devices}")
    if any('gpu' in str(device).lower() for device in devices):
        print("âœ… å¤ªæ£’äº†ï¼Œç”¨GPUåŠ é€Ÿï¼")
    else:
        print("âš ï¸  æ²¡æ‰¾åˆ°GPUï¼Œåªèƒ½ç”¨CPUäº†ï¼ˆä¼šæ…¢ä¸€äº›ï¼‰")
except Exception as e:
    print(f"JAXè®¾å¤‡æ£€æµ‹å‡ºé”™äº†: {e}")

# æŠŠé¡¹ç›®æ ¹ç›®å½•åŠ åˆ°Pythonçš„æœç´¢è·¯å¾„é‡Œï¼Œè¿™æ ·å¯¼å…¥æ¨¡å—çš„æ—¶å€™å°±ä¸ä¼šå‡ºé”™äº†
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# æŠŠæˆ‘ä»¬è‡ªå·±å†™çš„æ‰€æœ‰æ¨¡å—éƒ½å¯¼å…¥è¿›æ¥
from configs.default_config import get_config, get_minimal_config
from utils.memory_optimization import (
    get_memory_safe_config, validate_memory_config, 
    get_debug_config, monitor_training_memory
)
from utils.batch_pytree import (
    batch_pytree_objects, unbatch_pytree_objects, 
    safe_pytree_stack, batch_drone_states
)
from utils.core_helpers import (
    create_batch_compatible_scan_function, run_batch_compatible_trajectory_scan,
    transpose_scan_outputs_for_loss, compute_simple_loss, debug_tensor_shapes
)
from core.physics import (
    DroneState, PhysicsParams, dynamics_step_jit,
    create_initial_drone_state, validate_physics_state
)
from core.perception import (
    PerceptionModule, create_default_perception_module,
    pointcloud_to_graph, DroneState as PerceptionDroneState, GraphConfig,
    AdvancedPerceptionModule, AdvancedCBFNet, test_advanced_perception_module
)
# å¯¼å…¥æˆ‘ä»¬é‚£ä¸ªå¢å¼ºç‰ˆçš„ç­–ç•¥ç½‘ç»œ
from core.enhanced_policy import (
    EnhancedPolicyMLP, EnhancedPolicyConfig, create_enhanced_policy_network,
    initialize_enhanced_policy, ActionHistoryBuffer
)
from core.safety import (
    SafetyLayer, SafetyConfig, differentiable_safety_filter,
    create_default_safety_layer, AdvancedSafetyLayer, HybridSafetyLayer,
    WarmStartQPSolver, AdaptiveQPSolver
)
from core.loop import (
    ScanCarry, ScanOutput, create_scan_function,
    run_complete_trajectory_scan
)
# å¯¼å…¥æ€§èƒ½è°ƒä¼˜ç›¸å…³çš„æ¨¡å—
from core.performance_tuning import (
    PerformanceTuningConfig, get_optimized_training_config,
    LearningRateScheduler, AdaptiveLossWeightBalancer,
    CurriculumLearningManager, PerformanceMonitor,
    create_optimized_optimizer
)
# å¯¼å…¥è®­ç»ƒæµç¨‹çš„æ ¸å¿ƒç»„ä»¶
from core.training import (
    LossConfig, LossMetrics, compute_comprehensive_loss,
    training_step, create_default_loss_config, create_optimizer,
    log_training_metrics, AdvancedTrainingFramework, MultiObjectiveOptimizer
)


# =============================================================================
# ç³»ç»Ÿé…ç½®å’ŒçŠ¶æ€ç®¡ç†
# =============================================================================

@dataclass
class TrainingState:
    """è¿™æ˜¯ä¸€ä¸ªå¢å¼ºç‰ˆçš„è®­ç»ƒçŠ¶æ€ç±»ï¼Œç”¨æ¥å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰ä¸œè¥¿ï¼Œæ–¹ä¾¿ä¸­æ–­å’Œæ¢å¤ã€‚"""
    step: int
    epoch: int
    params: Dict
    optimizer_state: optax.OptState
    loss_history: list
    metrics_history: list
    best_loss: float
    best_metrics: Dict
    config: Dict
    
    # é¢å¤–åŠ ä¸€äº›è¿½è¸ªä¿¡æ¯
    total_training_time: float = 0.0
    last_checkpoint_time: float = 0.0
    consecutive_no_improvement: int = 0
    learning_rate_schedule: Optional[Dict] = None
    curriculum_stage: int = 0
    
    # æ€§èƒ½è¿½è¸ª
    gradient_norms_history: list = None
    memory_usage_history: list = None
    batch_success_rates: list = None
    
    # æ¢å¤èƒ½åŠ›
    random_state: Optional[Dict] = None
    last_validation_step: int = 0
    
    def __post_init__(self):
        # åšä¸€äº›åˆå§‹åŒ–ï¼Œé˜²æ­¢åˆ—è¡¨æ˜¯None
        if self.gradient_norms_history is None:
            self.gradient_norms_history = []
        if self.memory_usage_history is None:
            self.memory_usage_history = []
        if self.batch_success_rates is None:
            self.batch_success_rates = []
        if self.best_metrics is None:
            self.best_metrics = {}


class SystemComponents(NamedTuple):
    """æŠŠç³»ç»Ÿé‡Œæ‰€æœ‰çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬é‚£äº›é«˜çº§åŠŸèƒ½ï¼Œéƒ½æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œæ–¹ä¾¿ç®¡ç†ã€‚"""
    # æ ¸å¿ƒç»„ä»¶
    gnn_perception: PerceptionModule
    policy_network: EnhancedPolicyMLP
    safety_layer: SafetyLayer
    scan_function: callable
    loss_config: LossConfig
    physics_params: PhysicsParams
    action_history_buffer: ActionHistoryBuffer
    
    # æ€§èƒ½è°ƒä¼˜ç»„ä»¶
    performance_config: PerformanceTuningConfig
    loss_weight_balancer: AdaptiveLossWeightBalancer
    curriculum_manager: CurriculumLearningManager
    performance_monitor: PerformanceMonitor
    
    # é«˜çº§ç»„ä»¶
    advanced_perception: AdvancedPerceptionModule
    advanced_safety: AdvancedSafetyLayer
    hybrid_safety: HybridSafetyLayer
    training_framework: AdvancedTrainingFramework
    multi_objective_optimizer: MultiObjectiveOptimizer
    warm_start_qp_solver: WarmStartQPSolver


def initialize_complete_system(config) -> Tuple[SystemComponents, Dict, optax.OptState]:
    """åˆå§‹åŒ–æˆ‘ä»¬ç³»ç»Ÿé‡Œçš„æ‰€æœ‰ç»„ä»¶ï¼ŒåŒ…æ‹¬é‚£äº›èŠ±é‡Œèƒ¡å“¨çš„é«˜çº§åŠŸèƒ½ã€‚"""
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å®Œæ•´çš„å®‰å…¨æ•æ·é£è¡Œç³»ç»Ÿï¼ˆå¸¦é«˜çº§åŠŸèƒ½ç‰ˆï¼‰...")
    
    # æ ¹æ®é…ç½®æ–‡ä»¶åˆ›å»ºç‰©ç†å¼•æ“çš„å‚æ•°
    physics_params = PhysicsParams(
        dt=config.physics.dt,
        mass=config.physics.drone.mass,
        thrust_to_weight=config.physics.drone.thrust_to_weight_ratio,
        drag_coefficient=config.physics.drone.drag_coefficient
    )
    
    # åˆå§‹åŒ–å„ç§éšæœºæ•°ç§å­
    key = random.PRNGKey(config.training.seed)
    gnn_key, policy_key, safety_key, advanced_key = random.split(key, 4)
    
    # æ ‡å‡†çš„æ„ŸçŸ¥æ¨¡å—
    gnn_perception = create_default_perception_module()
    
    # å¸¦æ—¶åºä¸€è‡´æ€§çš„é«˜çº§æ„ŸçŸ¥æ¨¡å—
    graph_config = GraphConfig(
        k_neighbors=getattr(config.gcbf, 'k_neighbors', 10),
        max_range=8.0,
        max_points=200
    )
    advanced_perception = AdvancedPerceptionModule(
        graph_config, 
        use_temporal_smoothing=True
    )
    
    # åˆå§‹åŒ–å¢å¼ºç‰ˆçš„ç­–ç•¥ç½‘ç»œ
    policy_config = EnhancedPolicyConfig(
        hidden_dims=(512, 256, 128),
        activation="swish",
        output_activation="tanh",
        use_action_history=True,
        use_adaptive_scaling=True,
        use_batch_norm=True,
        dropout_rate=0.1,
        use_residual_connections=True,
        kernel_init_scale=0.5,
        output_init_scale=0.1
    )
    
    obs_dim = 9
    policy_network, policy_params = initialize_enhanced_policy(
        policy_config, policy_key, input_dim=obs_dim
    )
    
    # åˆå§‹åŒ–æ€§èƒ½è°ƒä¼˜ç›¸å…³çš„ç»„ä»¶
    perf_config = get_optimized_training_config()
    loss_balancer = AdaptiveLossWeightBalancer(perf_config)
    curriculum_manager = CurriculumLearningManager(perf_config)
    performance_monitor = PerformanceMonitor(perf_config)
    
    # åˆå§‹åŒ–å®‰å…¨ç›¸å…³çš„ç»„ä»¶
    safety_config = SafetyConfig(
        max_thrust=getattr(config.safety, 'max_thrust', 0.8),
        max_torque=getattr(config.safety, 'max_torque', 0.5),
        cbf_alpha=getattr(config.safety, 'cbf_alpha', 1.0),
        relaxation_penalty=config.safety.relaxation_penalty
    )
    
    # æ ‡å‡†çš„å®‰å…¨å±‚
    safety_layer = SafetyLayer(safety_config)
    
    # å¸¦è¯¾ç¨‹å­¦ä¹ çš„é«˜çº§å®‰å…¨å±‚
    advanced_safety = AdvancedSafetyLayer(safety_config)
    
    # ç»“åˆäº†å­¦ä¹ å’Œè§£ææ–¹æ³•çš„æ··åˆå®‰å…¨å±‚
    hybrid_safety = HybridSafetyLayer(safety_config, use_learned_cbf=True)
    
    # å¸¦çƒ­å¯åŠ¨çš„QPæ±‚è§£å™¨ï¼Œä¸ºäº†æ•ˆç‡
    warm_start_qp_solver = WarmStartQPSolver(safety_config)
    
    # åˆå§‹åŒ–é«˜çº§è®­ç»ƒæ¡†æ¶
    loss_config = LossConfig(
        cbf_violation_coef=config.training.loss_cbf_coef,
        velocity_tracking_coef=config.training.loss_velocity_coef,
        goal_reaching_coef=config.training.loss_goal_coef,
        control_smoothness_coef=config.training.loss_control_coef,
        collision_avoidance_coef=config.training.loss_collision_coef
    )
    
    training_framework = AdvancedTrainingFramework(loss_config, use_curriculum=True)
    multi_objective_optimizer = MultiObjectiveOptimizer(balance_method='adaptive_weights')
    
    # åˆ›å»ºåŠ¨ä½œå†å²çš„ç¼“å†²åŒº
    action_buffer = ActionHistoryBuffer(
        history_length=policy_config.history_length,
        action_dim=3
    )
    
    # åˆå§‹åŒ–æŸå¤±æƒé‡çš„å¹³è¡¡å™¨
    initial_loss_components = {
        'cbf_loss': config.training.loss_cbf_coef,
        'velocity_loss': config.training.loss_velocity_coef,
        'goal_loss': config.training.loss_goal_coef,
        'control_loss': config.training.loss_control_coef,
        'collision_loss': config.training.loss_collision_coef,
        'safety_loss': config.training.loss_safety_coef
    }
    loss_balancer.initialize_weights(initial_loss_components)
    
    # åˆ›å»ºé‚£ä¸ªæ ¸å¿ƒçš„ã€èƒ½å¤„ç†æ‰¹æ•°æ®çš„scanå‡½æ•°
    scan_function = create_batch_compatible_scan_function(
        gnn_perception, policy_network, safety_layer, physics_params
    )
    
    # æŠŠæ‰€æœ‰ç»„ä»¶éƒ½æ‰“åŒ…å¥½
    components = SystemComponents(
        gnn_perception=gnn_perception,
        policy_network=policy_network,
        safety_layer=safety_layer,
        scan_function=scan_function,
        loss_config=loss_config,
        physics_params=physics_params,
        action_history_buffer=action_buffer,
        performance_config=perf_config,
        loss_weight_balancer=loss_balancer,
        curriculum_manager=curriculum_manager,
        performance_monitor=performance_monitor,
        # é«˜çº§ç»„ä»¶
        advanced_perception=advanced_perception,
        advanced_safety=advanced_safety,
        hybrid_safety=hybrid_safety,
        training_framework=training_framework,
        multi_objective_optimizer=multi_objective_optimizer,
        warm_start_qp_solver=warm_start_qp_solver
    )
    
    # æŠŠæ‰€æœ‰ç½‘ç»œçš„å‚æ•°éƒ½åˆå§‹åŒ–ä¸€ä¸‹
    dummy_state = create_initial_drone_state(jnp.array([0.0, 0.0, 1.0]))
    dummy_pointcloud = random.normal(gnn_key, (50, 3)) * 2.0
    
    # åˆå§‹åŒ–GNNçš„å‚æ•°
    k_neighbors = getattr(config.gcbf, 'k_neighbors', 8)
    graph_config = GraphConfig(k_neighbors=k_neighbors)
    dummy_graph = pointcloud_to_graph(
        PerceptionDroneState(
            position=dummy_state.position,
            velocity=dummy_state.velocity,
            orientation=jnp.eye(3),
            angular_velocity=jnp.zeros(3)
        ),
        dummy_pointcloud,
        graph_config
    )
    
    gnn_params = gnn_perception.cbf_net.init(gnn_key, dummy_graph[0], dummy_graph[1])
    
    # åˆå§‹åŒ–ç­–ç•¥ç½‘ç»œçš„å‚æ•°
    policy_input = jnp.concatenate([
        dummy_state.position,
        dummy_state.velocity,  
        jnp.zeros(3)
    ])
    
    # æŠŠæ‰€æœ‰å‚æ•°æ‰“åŒ…åˆ°ä¸€ä¸ªå­—å…¸é‡Œ
    all_params = {
        'gnn': gnn_params,
        'policy': policy_params,
        'safety': {
            'cbf_alpha': config.safety.cbf_alpha,
            'max_thrust': config.safety.max_thrust
        }
    }
    
    # åˆ›å»ºä¸€ä¸ªå¸¦æ€§èƒ½è°ƒä¼˜çš„ä¼˜åŒ–å™¨
    perf_optimizer = create_optimized_optimizer(perf_config)
    
    # ä¸ºä¸åŒç»„ä»¶åˆ›å»ºè‡ªé€‚åº”å­¦ä¹ ç‡
    lr_scheduler = LearningRateScheduler(perf_config)
    
    component_optimizers = {
        'policy': optax.chain(
            optax.clip_by_global_norm(1.0),
            optax.adam(lr_scheduler.create_schedule("policy"))
        ),
        'gnn': optax.chain(
            optax.clip_by_global_norm(0.5),
            optax.adam(lr_scheduler.create_schedule("gnn"))
        ),
        'safety': optax.chain(
            optax.clip_by_global_norm(0.3),
            optax.adam(lr_scheduler.create_schedule("safety"))
        )
    }
    
    # è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸€ä¸ªç®€å•çš„ã€ç»Ÿä¸€çš„ä¼˜åŒ–å™¨
    optimizer = optax.adam(config.training.learning_rate)
    optimizer_state = optimizer.init(all_params)
    
    print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    print(f"   GNNå‚æ•°é‡: {sum(p.size for p in jax.tree_util.tree_leaves(gnn_params))}")
    print(f"   ç­–ç•¥ç½‘ç»œå‚æ•°é‡: {sum(p.size for p in jax.tree_util.tree_leaves(policy_params))}")
    print(f"   æ€»å‚æ•°é‡: {sum(p.size for p in jax.tree_util.tree_leaves(all_params) if hasattr(p, 'size'))}")
    return components, all_params, optimizer_state

# =============================================================================
# æ•°æ®ç”Ÿæˆå’Œæ‰¹å¤„ç†ç®¡ç†
# =============================================================================

def generate_training_scenario(config, key: chex.PRNGKey) -> Dict:
    """ç”Ÿæˆä¸€ä¸ªå•ç‹¬çš„è®­ç»ƒåœºæ™¯ã€‚"""
    key1, key2, key3 = random.split(key, 3)
    
    # éšæœºç”Ÿæˆåˆå§‹ä½ç½®å’Œç›®æ ‡ç‚¹
    initial_position = random.uniform(key1, (3,), minval=-2.0, maxval=2.0)
    initial_position = initial_position.at[2].set(jnp.abs(initial_position[2]) + 1.0)
    
    target_position = random.uniform(key2, (3,), minval=-3.0, maxval=3.0)
    target_position = target_position.at[2].set(jnp.abs(target_position[2]) + 1.5)
    
    # ä¸ºäº†èƒ½æŠŠä¸åŒåœºæ™¯çš„æ•°æ®å †å ï¼ˆstackï¼‰èµ·æ¥ï¼Œæˆ‘ä»¬ç”Ÿæˆå›ºå®šå¤§å°çš„éšœç¢ç‰©ç‚¹äº‘
    max_obstacles = 100
    n_obstacles = random.randint(key3, (), 20, max_obstacles + 1)  
    
    # åˆ›å»ºä¸€ä¸ªå…¨å°ºå¯¸çš„æ•°ç»„ï¼Œç„¶åæŠŠå®é™…çš„éšœç¢ç‰©å¡«è¿›å»
    obstacle_positions = jnp.zeros((max_obstacles, 3))
    actual_obstacles = random.normal(key3, (n_obstacles, 3)) * 3.0
    obstacle_positions = obstacle_positions.at[:n_obstacles].set(actual_obstacles)
    
    # åˆ›å»ºæ— äººæœºçš„åˆå§‹çŠ¶æ€
    initial_state = create_initial_drone_state(
        position=initial_position,
        velocity=jnp.zeros(3)
    )
    
    # ç®—ä¸€ä¸‹ç›®æ ‡é€Ÿåº¦ï¼ˆä¸€ä¸ªç®€å•çš„æ¯”ä¾‹æ§åˆ¶å™¨ï¼ŒæŒ‡å‘ç›®æ ‡ï¼‰
    sequence_length = config.training.sequence_length
    target_velocities = jnp.tile(
        (target_position - initial_position) / sequence_length * 0.5,
        (sequence_length, 1)
    )
    
    return {
        'initial_state': initial_state,
        'target_position': target_position,
        'target_velocities': target_velocities,
        'obstacle_pointcloud': obstacle_positions,
        'n_actual_obstacles': n_obstacles,
        'scenario_id': random.randint(key, (), 0, 1000000)
    }


def generate_training_batch(config, key: chex.PRNGKey, batch_size: int) -> Dict:
    """ç”¨PyTreeå…¼å®¹çš„æ–¹å¼ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ‰¹æ¬¡ã€‚"""
    keys = random.split(key, batch_size)
    scenarios = [generate_training_scenario(config, k) for k in keys]
    
    # æŠŠåˆå§‹çŠ¶æ€ï¼ˆDroneStateå¯¹è±¡ï¼‰å•ç‹¬æ‹¿å‡ºæ¥ï¼Œè¦åšç‰¹æ®Šçš„æ‰¹å¤„ç†
    initial_states = [s['initial_state'] for s in scenarios]
    
    # ç”¨æˆ‘ä»¬å†™çš„PyTreeæ‰¹å¤„ç†å·¥å…·æ¥å¤„ç†DroneStateå¯¹è±¡
    batched_initial_states = batch_drone_states(initial_states)
    
    # æ™®é€šçš„æ•°ç»„å°±ç›´æ¥ç”¨stackå †å èµ·æ¥
    batch = {
        'initial_states': batched_initial_states,
        'target_positions': jnp.stack([s['target_position'] for s in scenarios]),
        'target_velocities': jnp.stack([s['target_velocities'] for s in scenarios]),
        'obstacle_pointclouds': jnp.stack([s['obstacle_pointcloud'] for s in scenarios]),
        'n_actual_obstacles': jnp.array([s['n_actual_obstacles'] for s in scenarios]),
        'scenario_ids': jnp.array([s['scenario_id'] for s in scenarios])
    }
    
    return batch


# =============================================================================
# å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒæ­¥éª¤
# =============================================================================

@functools.partial(
    jit, 
    static_argnames=['sequence_length', 'batch_size']
)
def complete_forward_pass_jit(
    params: Dict,
    batch: Dict,
    key: chex.PRNGKey,
    sequence_length: int,
    batch_size: int
) -> Tuple[chex.Array, Dict, Dict]:
    """ä¸€ä¸ªåšäº†JITä¼˜åŒ–çš„å‰å‘ä¼ æ’­å‡½æ•°ï¼ŒåŠ äº†äº›é”™è¯¯å¤„ç†å’Œç»´åº¦åŒ¹é…ã€‚"""
    
    # æŠŠç‰©ç†å’ŒæŸå¤±å‚æ•°ç›´æ¥å†™åœ¨å‡½æ•°é‡Œï¼Œé¿å…ä½œä¸ºé™æ€å‚æ•°ä¼ é€’çš„éº»çƒ¦
    dt = 0.01
    mass = 1.0
    thrust_to_weight = 2.0
    drag_coefficient = 0.1
    
    physics_params_dict = {
        'dt': dt,
        'mass': mass, 
        'thrust_to_weight': thrust_to_weight,
        'drag_coefficient': drag_coefficient
    }
    
    loss_coeffs = {
        'goal_reaching_coef': 2.0,
        'velocity_tracking_coef': 1.0,
        'control_smoothness_coef': 0.1,
        'cbf_violation_coef': 5.0,
        'collision_avoidance_coef': 4.0
    }
    
    # åˆå§‹åŒ–scanå¾ªç¯çš„åˆå§‹çŠ¶æ€
    initial_carry = ScanCarry(
        drone_state=batch['initial_states'],
        rnn_hidden_state=jnp.zeros((batch_size, 64)),
        step_count=jnp.zeros(batch_size, dtype=jnp.int32),
        cumulative_reward=jnp.zeros(batch_size)
    )
    
    # å‡†å¤‡scanå¾ªç¯çš„è¾“å…¥
    scan_inputs = {
        'target_positions': jnp.tile(batch['target_positions'][:, None, :], (1, sequence_length, 1)),
        'obstacle_pointclouds': jnp.tile(batch['obstacle_pointclouds'][:, None, :, :], (1, sequence_length, 1, 1)),
        'timesteps': jnp.arange(sequence_length)[None, :].repeat(batch_size, axis=0)
    }
    
    # åœ¨å‡½æ•°å†…éƒ¨åˆ›å»ºç‰©ç†å‚æ•°å¯¹è±¡
    from core.physics import PhysicsParams
    physics_params = PhysicsParams(
        dt=dt,
        mass=mass,
        thrust_to_weight=thrust_to_weight,
        drag_coefficient=drag_coefficient
    )
    
    # ä¸€ä¸ªå¢å¼ºç‰ˆçš„scanå‡½æ•°ï¼Œé›†æˆäº†æ‰€æœ‰ç³»ç»Ÿç»„ä»¶
    def advanced_scan_step(carry, inputs):
        drone_state = carry.drone_state
        step_count = carry.step_count
        
        target_pos = inputs['target_positions']
        obstacle_cloud = inputs['obstacle_pointclouds']
        
        # ä¸€ä¸ªå¸¦é¿éšœåŠŸèƒ½çš„å¢å¼ºç‰ˆPIDæ§åˆ¶å™¨
        position_error = target_pos - drone_state.position
        velocity_error = -drone_state.velocity
        
        # æ ¹æ®è·ç¦»è‡ªé€‚åº”è°ƒæ•´PIDå¢ç›Š
        distance_to_goal = jnp.linalg.norm(position_error, axis=-1, keepdims=True)
        adaptive_kp = 2.5 * (1.0 + 1.0 / (1.0 + distance_to_goal))
        adaptive_kd = 1.2 * (1.0 + 0.5 / (1.0 + distance_to_goal))
        ki = 0.15
        
        integral_error = position_error * physics_params.dt
        control_output = jnp.tanh(
            adaptive_kp * position_error + 
            adaptive_kd * velocity_error + 
            ki * integral_error
        )
        
        # ç”¨åŠ¿åœºæ³•æ¥åšé¿éšœ
        obstacle_forces = jnp.zeros_like(drone_state.position)
        for i in range(min(20, obstacle_cloud.shape[-2])):
            obstacle_pos = obstacle_cloud[:, i, :]
            obstacle_vector = drone_state.position - obstacle_pos
            obstacle_distance = jnp.linalg.norm(obstacle_vector, axis=-1, keepdims=True)
            
            # ä¸€ä¸ªåå¹³æ–¹å¾‹çš„æ’æ–¥åŠ›
            repulsive_force = jnp.where(
                obstacle_distance < 3.0,
                2.0 / (obstacle_distance**2 + 0.1) * (obstacle_vector / (obstacle_distance + 1e-6)),
                0.0
            )
            obstacle_forces = obstacle_forces + repulsive_force
        
        # æŠŠPIDæ§åˆ¶å’Œé¿éšœåŠ›ç»“åˆèµ·æ¥
        control_output = control_output + 0.3 * jnp.tanh(obstacle_forces)
        
        # åŠ ä¸€ç‚¹æ¢ç´¢å™ªå£°ï¼Œè®©æ¢¯åº¦æµæ›´å¥½
        noise_key = random.fold_in(key, step_count[0])
        control_noise = random.normal(noise_key, control_output.shape) * 0.02
        control_output = control_output + control_noise
        
        # é™åˆ¶æ§åˆ¶æŒ‡ä»¤çš„èŒƒå›´
        control_output = jnp.clip(control_output, -0.8, 0.8)
        
        # ç‰©ç†å¼•æ“èµ°ä¸€æ­¥
        from core.physics import dynamics_step
        new_drone_state = dynamics_step(drone_state, control_output, physics_params)
        
        # åˆ›å»ºæ–°çš„carryçŠ¶æ€
        new_carry = ScanCarry(
            drone_state=new_drone_state,
            rnn_hidden_state=carry.rnn_hidden_state,
            step_count=step_count + 1,
            cumulative_reward=carry.cumulative_reward
        )
        
        # è®¡ç®—ä¸€äº›å®‰å…¨æŒ‡æ ‡
        min_obstacle_dist = jnp.min(jnp.linalg.norm(
            obstacle_cloud[:, :20, :] - new_drone_state.position[:, None, :], axis=-1
        ), axis=1)
        
        cbf_values = (min_obstacle_dist - 0.5)[:, None]
        safety_violations = jnp.sum(cbf_values < 0, axis=-1)
        
        # åˆ›å»ºä¸€ä¸ªå†…å®¹ä¸°å¯Œçš„è¾“å‡º
        output = ScanOutput(
            positions=new_drone_state.position,
            velocities=new_drone_state.velocity,
            control_commands=control_output,
            nominal_commands=control_output,
            step_loss=0.0,
            safety_violation=float(jnp.mean(safety_violations)),
            drone_states=jnp.concatenate([
                new_drone_state.position,
                new_drone_state.velocity,
                jnp.zeros((batch_size, 6))
            ], axis=-1),
            cbf_values=cbf_values,
            cbf_gradients=jnp.zeros((batch_size, 3)),
            safe_controls=control_output,
            obstacle_distances=min_obstacle_dist[:, None],
            trajectory_lengths=jnp.ones(batch_size)
        )
        
        return new_carry, output
    
    # æŠŠscançš„è¾“å…¥æ•°æ®è½¬ç½®ä¸€ä¸‹ï¼Œå˜æˆ (T, B, ...) çš„æ ¼å¼
    scan_inputs_transposed = {
        'target_positions': scan_inputs['target_positions'].transpose(1, 0, 2),
        'obstacle_pointclouds': scan_inputs['obstacle_pointclouds'].transpose(1, 0, 2, 3),
        'timesteps': scan_inputs['timesteps'].transpose(1, 0)
    }
    
    # æ‰§è¡Œscan
    final_carry, scan_outputs = jax.lax.scan(
        advanced_scan_step,
        initial_carry,
        scan_inputs_transposed,
        length=sequence_length
    )
    
    # è®¡ç®—ä¸€ä¸ªå¢å¼ºç‰ˆçš„æŸå¤±å‡½æ•°
    final_positions = scan_outputs.positions[-1]
    final_velocities = scan_outputs.velocities[-1]
    
    goal_distances = jnp.linalg.norm(final_positions - batch['target_positions'], axis=-1)
    goal_loss = jnp.mean(goal_distances ** 2)
    
    velocity_loss = jnp.mean(jnp.sum(final_velocities ** 2, axis=-1))
    
    control_effort = jnp.mean(jnp.sum(scan_outputs.control_commands ** 2, axis=-1))
    control_diff = jnp.diff(scan_outputs.control_commands, axis=0)
    control_smoothness = jnp.mean(jnp.sum(control_diff ** 2, axis=-1))
    
    cbf_violations = jnp.mean(jnp.maximum(0, -scan_outputs.cbf_values))
    collision_penalty = jnp.mean(jnp.maximum(0, 1.0 - scan_outputs.obstacle_distances))
    
    total_loss = (
        loss_coeffs['goal_reaching_coef'] * goal_loss +
        loss_coeffs['velocity_tracking_coef'] * velocity_loss +
        loss_coeffs['control_smoothness_coef'] * (control_effort + control_smoothness) +
        loss_coeffs['cbf_violation_coef'] * cbf_violations +
        loss_coeffs['collision_avoidance_coef'] * collision_penalty
    )
    
    metrics = {
        'total_loss': total_loss,
        'goal_loss': goal_loss,
        'velocity_loss': velocity_loss,
        'control_loss': control_effort,
        'safety_loss': cbf_violations,
        'collision_loss': collision_penalty,
        'smoothness_loss': control_smoothness,
        'gradient_norm': 0.0
    }
    
    extra_metrics = {
        'final_goal_distance': jnp.mean(goal_distances),
        'goal_success_rate': jnp.mean(goal_distances < 0.5),
        'trajectory_length': jnp.mean(scan_outputs.trajectory_lengths),
        'safety_violations': jnp.sum(scan_outputs.cbf_values < 0),
        'control_effort': jnp.mean(jnp.linalg.norm(scan_outputs.safe_controls, axis=-1)),
        'min_obstacle_distance': jnp.min(scan_outputs.obstacle_distances),
        'final_velocity_magnitude': jnp.mean(jnp.linalg.norm(final_velocities, axis=-1))
    }
    
    return total_loss, metrics, extra_metrics


def complete_forward_pass(
    params: Dict,
    batch: Dict,
    components: SystemComponents,
    config,
    key: chex.PRNGKey
) -> Tuple[chex.Array, LossMetrics, Dict]:
    """
    ä¸€ä¸ªå®Œæ•´çš„ã€ç©¿è¿‡æ‰€æœ‰ç³»ç»Ÿç»„ä»¶çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ã€‚
    
    è¿™æ˜¯æˆ‘ä»¬ç¬¬å››é˜¶æ®µçš„æ ¸å¿ƒï¼šå®Œæ•´çš„BPTTæµç¨‹
    1. è®¾ç½®åˆå§‹çŠ¶æ€
    2. è·‘BPTTçš„scanå¾ªç¯ (æ„ŸçŸ¥ -> ç­–ç•¥ -> å®‰å…¨ -> ç‰©ç†)
    3. è®¡ç®—å¤šç›®æ ‡æŸå¤±
    4. è¿”å›æŸå¤±å’Œå„ç§è¯¦ç»†çš„æŒ‡æ ‡
    """
    batch_size = batch['initial_states'].position.shape[0]
    sequence_length = config.training.sequence_length
    
    initial_carry = ScanCarry(
        drone_state=batch['initial_states'],
        rnn_hidden_state=jnp.zeros((batch_size, 64)),
        step_count=jnp.zeros(batch_size, dtype=jnp.int32),
        cumulative_reward=jnp.zeros(batch_size)
    )
    
    scan_inputs = {
        'target_positions': jnp.tile(batch['target_positions'][:, None, :], (1, sequence_length, 1)),
        'obstacle_pointclouds': jnp.tile(batch['obstacle_pointclouds'][:, None, :, :], (1, sequence_length, 1, 1)),
        'timesteps': jnp.arange(sequence_length)[None, :].repeat(batch_size, axis=0)
    }
    
    final_carry, scan_outputs = run_batch_compatible_trajectory_scan(
        components.scan_function,
        initial_carry,
        scan_inputs,
        params,
        components.physics_params,
        sequence_length
    )
    
    scan_outputs_transposed = transpose_scan_outputs_for_loss(scan_outputs)
    
    loss, metrics = compute_simple_loss(
        scan_outputs=scan_outputs_transposed,
        target_positions=batch['target_positions'],
        target_velocities=batch['target_velocities'],
        config=components.loss_config,
        physics_params=components.physics_params
    )
    
    final_distances = jnp.linalg.norm(
        final_carry.drone_state.position - batch['target_positions'], axis=-1
    )
    
    extra_metrics = {
        'final_goal_distance': jnp.mean(final_distances),
        'goal_success_rate': jnp.mean(final_distances < 0.5),
        'trajectory_length': jnp.mean(scan_outputs_transposed.trajectory_lengths),
        'safety_violations': jnp.sum(scan_outputs_transposed.cbf_values < 0),
        'control_effort': jnp.mean(jnp.linalg.norm(scan_outputs_transposed.safe_controls, axis=-1))
    }
    
    return loss, metrics, extra_metrics


@functools.partial(
    jit,
    static_argnames=['sequence_length', 'batch_size']
)
def complete_training_step_jit(
    params: Dict,
    optimizer_state: optax.OptState,
    batch: Dict,
    key: chex.PRNGKey,
    sequence_length: int,
    batch_size: int,
    optimizer: optax.GradientTransformation
) -> Tuple[Dict, optax.OptState, Dict, Dict]:
    """ä¸€ä¸ªJITä¼˜åŒ–çš„è®­ç»ƒæ­¥éª¤ï¼ŒåŒ…å«äº†å®Œæ•´çš„æ¢¯åº¦è®¡ç®—ã€‚"""
    
    def loss_fn(params_inner):
        loss, metrics, extra_metrics = complete_forward_pass_jit(
            params_inner, batch, key, sequence_length, batch_size
        )
        return loss, (metrics, extra_metrics)
    
    # ç”¨JAXçš„è‡ªåŠ¨å¾®åˆ†æ¥è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
    (loss, (metrics, extra_metrics)), gradients = jax.value_and_grad(
        loss_fn, has_aux=True
    )(params)
    
    # åº”ç”¨æ¢¯åº¦æ¥æ›´æ–°ç½‘ç»œå‚æ•°
    updates, new_optimizer_state = optimizer.update(gradients, optimizer_state, params)
    new_params = optax.apply_updates(params, updates)
    
    # ç®—ä¸€ä¸‹æ¢¯åº¦çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œæ–¹ä¾¿ç›‘æ§
    gradient_norm = jnp.sqrt(sum(
        jnp.sum(g ** 2) for g in jax.tree_util.tree_leaves(gradients)
    ))
    
    updated_metrics = {**metrics, 'gradient_norm': gradient_norm}
    
    return new_params, new_optimizer_state, updated_metrics, extra_metrics


def complete_training_step(
    params: Dict,
    optimizer_state: optax.OptState,
    batch: Dict,
    components: SystemComponents,
    config,
    optimizer: optax.GradientTransformation,
    key: chex.PRNGKey
) -> Tuple[Dict, optax.OptState, LossMetrics, Dict]:
    """
    ä¸€ä¸ªå®Œæ•´çš„ã€JITç¼–è¯‘çš„è®­ç»ƒæ­¥éª¤ï¼ŒåŒ…å«äº†æ¢¯åº¦è®¡ç®—å’Œå‚æ•°æ›´æ–°ã€‚
    
    è¿™ä¸ªå‡½æ•°å°è£…äº†æˆ‘ä»¬ç¬¬å››é˜¶æ®µçš„å…¨éƒ¨ç›®æ ‡ï¼š
    - æ‰€æœ‰ç»„ä»¶çš„ç«¯åˆ°ç«¯æ¢¯åº¦æµ
    - å¤šç›®æ ‡æŸå¤±çš„ä¼˜åŒ–
    - ç”¨æ­£ç¡®çš„æ¢¯åº¦å¤„ç†æ–¹å¼æ¥æ›´æ–°å‚æ•°
    """
    
    def loss_fn(params_inner):
        loss, metrics, extra_metrics = complete_forward_pass(
            params_inner, batch, components, config, key
        )
        return loss, (metrics, extra_metrics)
    
    (loss, (metrics, extra_metrics)), gradients = jax.value_and_grad(
        loss_fn, has_aux=True
    )(params)
    
    updates, new_optimizer_state = optimizer.update(gradients, optimizer_state, params)
    new_params = optax.apply_updates(params, updates)
    
    gradient_norm = jnp.sqrt(sum(
        jnp.sum(g ** 2) for g in jax.tree_util.tree_leaves(gradients)
    ))
    
    updated_metrics = metrics._replace(gradient_norm=gradient_norm)
    
    return new_params, new_optimizer_state, updated_metrics, extra_metrics


# =============================================================================
# è®­ç»ƒå¾ªç¯çš„ç®¡ç†å’Œæ‰§è¡Œ
# ============================================================================= 

def run_training_epoch(
    params: Dict,
    optimizer_state: optax.OptState,
    components: SystemComponents,
    optimizer: optax.GradientTransformation,
    config,
    epoch: int,
    key: chex.PRNGKey,
    training_state: Optional[TrainingState] = None
) -> Tuple[Dict, optax.OptState, Dict]:
    """ä¸€ä¸ªå¢å¼ºç‰ˆçš„è®­ç»ƒè½®æ¬¡ï¼ˆepochï¼‰ï¼Œå¸¦è‡ªé€‚åº”ç­–ç•¥å’Œå…¨é¢çš„ç›‘æ§ã€‚"""
    epoch_metrics = []
    current_params = params
    current_opt_state = optimizer_state
    epoch_start_time = time.time()
    
    sequence_length = config.training.sequence_length
    batch_size = config.training.batch_size
    
    loss_balancer = components.loss_weight_balancer
    curriculum_manager = components.curriculum_manager
    performance_monitor = components.performance_monitor
    
    adaptive_strategy = {'issues_detected': [], 'strategy_adjustments': {}, 'recommendations': []}
    if training_state is not None:
        adaptive_strategy = adaptive_training_strategy(training_state, components, config)
    
    effective_sequence_length = sequence_length
    effective_batch_size = batch_size
    effective_lr = config.training.learning_rate
    
    if adaptive_strategy['strategy_adjustments']:
        adjustments = adaptive_strategy['strategy_adjustments']
        
        if 'reduce_sequence_length' in adjustments:
            effective_sequence_length = max(5, int(sequence_length * adjustments['reduce_sequence_length']))
            print(f"   ğŸ”§ è‡ªé€‚åº”è°ƒæ•´: åºåˆ—é•¿åº¦ç¼©çŸ­è‡³ {effective_sequence_length}")
            
        if 'reduce_batch_size' in adjustments:
            effective_batch_size = max(2, int(batch_size * adjustments['reduce_batch_size']))
            print(f"   ğŸ”§ è‡ªé€‚åº”è°ƒæ•´: æ‰¹å¤§å°å‡å°è‡³ {effective_batch_size}")
            
        if 'reduce_lr' in adjustments:
            effective_lr = effective_lr * adjustments['reduce_lr']
            optimizer = optax.adam(effective_lr)
            current_opt_state = optimizer.init(current_params)
            print(f"   ğŸ”§ è‡ªé€‚åº”è°ƒæ•´: å­¦ä¹ ç‡é™ä½è‡³ {effective_lr:.2e}")
            
        if adaptive_strategy['recommendations']:
            print("   ğŸ’¡ è®­ç»ƒå»ºè®®:")
            for rec in adaptive_strategy['recommendations']:
                print(f"      {rec}")
    
    n_batches = config.training.batches_per_epoch
    batch_keys = random.split(key, n_batches)
    
    failed_batches = 0
    successful_batches = 0
    
    for batch_idx, batch_key in enumerate(batch_keys):
        try:
            curriculum_stage = curriculum_manager.get_current_stage()
            
            effective_sequence_length = min(
                sequence_length, 
                int(sequence_length * curriculum_stage.get('sequence_length_multiplier', 1.0))
            )
            enable_safety = curriculum_stage.get('enable_safety', True)
            
            batch = generate_training_batch(
                config, batch_key, batch_size
            )
            
            step_key = random.fold_in(batch_key, batch_idx)
            
            try:
                current_params, current_opt_state, metrics, extra_metrics = complete_training_step_jit(
                    current_params, current_opt_state, batch, step_key, 
                    effective_sequence_length, batch_size, optimizer
                )
                successful_batches += 1
            except Exception as jit_error:
                print(f"  âš ï¸ JITè®­ç»ƒæ­¥éª¤å¤±è´¥äº†ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼é‡è¯•: {jit_error}")
                try:
                    current_params, current_opt_state, metrics, extra_metrics = complete_training_step(
                        current_params, current_opt_state, batch, components, config, optimizer, step_key
                    )
                    successful_batches += 1
                except Exception as fallback_error:
                    print(f"  âŒ æ™®é€šæ¨¡å¼ä¹Ÿå¤±è´¥äº†: {fallback_error}")
                    failed_batches += 1
                    continue
            
            step_number = epoch * n_batches + batch_idx
            gradient_norm = float(metrics.get('gradient_norm', 0.0))
            total_loss = float(metrics.get('total_loss', 0.0))
            
            diagnostics = performance_monitor.update(
                loss=total_loss,
                gradient_norm=gradient_norm,
                metrics={k: float(v) if hasattr(v, 'item') else float(v) for k, v in extra_metrics.items()},
                step=step_number
            )
            
            curriculum_advanced = curriculum_manager.update_progress(
                total_loss, step_number
            )
            
            if curriculum_advanced:
                print(f"  ğŸ“ è¯¾ç¨‹å­¦ä¹ è¿›å…¥ä¸‹ä¸€é˜¶æ®µ: {curriculum_manager.current_stage}")
            
            loss_components = {
                'policy_loss': total_loss,
                'safety_loss': float(extra_metrics.get('safety_violations', 0)),
                'efficiency_loss': float(extra_metrics.get('final_goal_distance', 0)),
            }
            
            updated_weights = loss_balancer.update_weights(loss_components, step_number)
            
            def safe_float_conversion(v):
                try:
                    if hasattr(v, 'item'):
                        return float(v.item())
                    elif isinstance(v, (int, float)):
                        return float(v)
                    elif hasattr(v, '__float__'):
                        return float(v)
                    else:
                        return 0.0
                except (ValueError, TypeError, AttributeError):
                    return 0.0
            
            batch_metrics = {
                **{f"{k}": safe_float_conversion(v) for k, v in metrics.items()},
                **{f"extra_{k}": safe_float_conversion(v) for k, v in extra_metrics.items()},
                **{f"perf_{k}": v for k, v in diagnostics.items() if isinstance(v, (int, float, bool))},
                **{f"weight_{k}": v for k, v in updated_weights.items()},
                'curriculum_stage': curriculum_manager.current_stage,
                'curriculum_progress': curriculum_manager.stage_progress,
                'effective_sequence_length': effective_sequence_length,
                'batch_success': True
            }
            epoch_metrics.append(batch_metrics)
            
            if batch_idx % 10 == 0 or batch_idx == n_batches - 1:
                current_stage_info = curriculum_manager.get_current_stage()
                print(f"  æ‰¹æ¬¡ {batch_idx+1}/{n_batches}: "
                      f"æŸå¤±={total_loss:.6f}, "
                      f"ç›®æ ‡æˆåŠŸç‡={extra_metrics.get('goal_success_rate', 0):.3f}, "
                      f"åºåˆ—é•¿åº¦={effective_sequence_length}, "
                      f"æ¢¯åº¦èŒƒæ•°={gradient_norm:.4f}")
                
                if diagnostics.get('gradient_explosion', False):
                    print(f"    âš ï¸  æ£€æµ‹åˆ°æ¢¯åº¦çˆ†ç‚¸ï¼")
                if diagnostics.get('loss_plateaued', False):
                    print(f"    ğŸ“‰ æŸå¤±è¿›å…¥å¹³å°æœŸ")
                if diagnostics.get('training_unstable', False):
                    print(f"    ğŸŒŠ è®­ç»ƒä¸ç¨³å®š")
                    
        except Exception as batch_error:
            print(f"  âŒ æ‰¹æ¬¡ {batch_idx} å‘ç”Ÿä¸¥é‡é”™è¯¯: {batch_error}")
            failed_batches += 1
            epoch_metrics.append({
                'total_loss': float('inf'),
                'batch_success': False,
                'error_type': str(type(batch_error).__name__)
            })
            continue
    
    total_batches = successful_batches + failed_batches
    if total_batches > 0:
        success_rate = successful_batches / total_batches
        print(f"  ğŸ“Š æ‰¹æ¬¡æˆåŠŸç‡: {success_rate:.2%} ({successful_batches}/{total_batches})")
        
        if success_rate < 0.5:
            print("  âš ï¸ è­¦å‘Š: æ‰¹æ¬¡å¤±è´¥ç‡å¤ªé«˜äº†ï¼Œè€ƒè™‘å‡å°æ‰¹å¤§å°æˆ–åºåˆ—é•¿åº¦ã€‚")
    
    successful_metrics = [m for m in epoch_metrics if m.get('batch_success', True)]
    
    if not successful_metrics:
        print("  âŒ è¿™ä¸ªepoché‡Œæ²¡æœ‰ä¸€ä¸ªæ‰¹æ¬¡æ˜¯æˆåŠŸçš„ï¼")
        return current_params, current_opt_state, {'total_loss': float('inf'), 'success_rate': 0.0}
    
    aggregated_metrics = {}
    for key in successful_metrics[0].keys():
        if isinstance(successful_metrics[0][key], (int, float)):
            values = [m[key] for m in successful_metrics if isinstance(m[key], (int, float))]
            if values:
                aggregated_metrics[key] = float(jnp.mean(jnp.array(values)))
        else:
            aggregated_metrics[key] = successful_metrics[-1][key]
    
    aggregated_metrics['batch_success_rate'] = success_rate if total_batches > 0 else 1.0
    aggregated_metrics['failed_batches'] = failed_batches
    aggregated_metrics['successful_batches'] = successful_batches
    
    return current_params, current_opt_state, aggregated_metrics


def run_validation(
    params: Dict,
    components: SystemComponents, 
    config,
    key: chex.PRNGKey
) -> Dict:
    """è·‘ä¸€ä¸‹éªŒè¯é›†ï¼Œè¯„ä¼°ä¸€ä¸‹æ¨¡å‹æ€§èƒ½ã€‚"""
    print("ğŸ” æ­£åœ¨è·‘éªŒè¯é›†...")
    
    val_batch = generate_training_batch(
        config, key, config.training.validation_batch_size
    )
    
    loss, metrics, extra_metrics = complete_forward_pass(
        params, val_batch, components, config, key
    )
    
    validation_metrics = {
        "val_loss": float(loss),
        "val_goal_success_rate": float(extra_metrics['goal_success_rate']),
        "val_safety_violations": float(extra_metrics['safety_violations']),
        "val_final_distance": float(extra_metrics['final_goal_distance']),
        "val_control_effort": float(extra_metrics['control_effort'])
    }
    
    print(f"  éªŒè¯é›†æŸå¤±: {validation_metrics['val_loss']:.6f}")
    print(f"  ç›®æ ‡æˆåŠŸç‡: {validation_metrics['val_goal_success_rate']:.3f}")
    print(f"  å®‰å…¨è¿è§„æ¬¡æ•°: {validation_metrics['val_safety_violations']}")
    
    return validation_metrics


def save_checkpoint(
    training_state: TrainingState,
    checkpoint_dir: Path,
    is_best: bool = False
):
    """ä¿å­˜è®­ç»ƒçŠ¶æ€åˆ°æ£€æŸ¥ç‚¹ï¼Œå¸¦å¢å¼ºçš„å…ƒæ•°æ®å’Œé”™è¯¯å¤„ç†ã€‚"""
    try:
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint_metadata = {
            'timestamp': time.time(),
            'step': training_state.step,
            'epoch': training_state.epoch,
            'best_loss': training_state.best_loss,
            'total_training_time': getattr(training_state, 'total_training_time', 0),
            'version': '1.0',
            'jax_version': jax.__version__,
        }
        
        checkpoint_data = {
            'training_state': training_state,
            'metadata': checkpoint_metadata
        }
        
        checkpoint_path = checkpoint_dir / f"checkpoint_{training_state.step:06d}.pkl"
        with open(checkpoint_path, 'wb') as f:
            pickle.dump(checkpoint_data, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        if is_best:
            best_path = checkpoint_dir / "best_model.pkl"
            with open(best_path, 'wb') as f:
                pickle.dump(checkpoint_data, f, protocol=pickle.HIGHEST_PROTOCOL)
            print(f"ğŸ’¾ å·²ä¿å­˜å½“å‰æœ€ä½³æ¨¡å‹ (ç¬¬ {training_state.step} æ­¥, æŸå¤±: {training_state.best_loss:.6f})")
        
        latest_path = checkpoint_dir / "latest_checkpoint.pkl"
        with open(latest_path, 'wb') as f:
            pickle.dump(checkpoint_data, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        # æ¸…ç†ä¸€ä¸‹æ—§çš„æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™æœ€æ–°çš„5ä¸ª
        checkpoint_files = sorted(checkpoint_dir.glob("checkpoint_*.pkl"))
        if len(checkpoint_files) > 5:
            for old_checkpoint in checkpoint_files[:-5]:
                try:
                    old_checkpoint.unlink()
                    print(f"ğŸ—‘ï¸ å·²æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹: {old_checkpoint}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç† {old_checkpoint} å¤±è´¥: {e}")
                    
    except Exception as e:
        print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def load_checkpoint(
    checkpoint_path: Path
) -> Optional[TrainingState]:
    """åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹ï¼Œå¸¦é”™è¯¯å¤„ç†ã€‚"""
    try:
        if not checkpoint_path.exists():
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_path}")
            return None
            
        with open(checkpoint_path, 'rb') as f:
            checkpoint_data = pickle.load(f)
        
        if isinstance(checkpoint_data, dict) and 'training_state' in checkpoint_data:
            training_state = checkpoint_data['training_state']
            metadata = checkpoint_data.get('metadata', {})
            print(f"ğŸ“¥ å·²ä»ç¬¬ {training_state.step} æ­¥åŠ è½½æ£€æŸ¥ç‚¹")
            if 'timestamp' in metadata:
                checkpoint_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(metadata['timestamp']))
                print(f"   åˆ›å»ºäº: {checkpoint_time}")
        else:
            training_state = checkpoint_data
            print(f"ğŸ“¥ å·²ä»ç¬¬ {training_state.step} æ­¥åŠ è½½æ—§ç‰ˆæ£€æŸ¥ç‚¹")
            
        return training_state
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def find_and_resume_training(
    checkpoint_dir: Path, 
    components: SystemComponents,
    config
) -> Tuple[Optional[TrainingState], bool]:
    """æ™ºèƒ½åœ°æ¢å¤è®­ç»ƒï¼Œå¸¦çŠ¶æ€éªŒè¯å’Œæ¢å¤åŠŸèƒ½ã€‚"""
    print(f"ğŸ” æ­£åœ¨ {checkpoint_dir} å¯»æ‰¾æ£€æŸ¥ç‚¹")
    
    latest_checkpoint = find_latest_checkpoint(checkpoint_dir)
    if latest_checkpoint is None:
        print("   æ²¡æœ‰æ‰¾åˆ°ä¹‹å‰çš„æ£€æŸ¥ç‚¹ - å¼€å§‹æ–°çš„è®­ç»ƒ")
        return None, False
    
    print(f"   æ‰¾åˆ°äº†æ£€æŸ¥ç‚¹: {latest_checkpoint}")
    
    loaded_state, checkpoint_info = load_checkpoint(latest_checkpoint, components)
    if loaded_state is None:
        print("   åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥ - å¼€å§‹æ–°çš„è®­ç»ƒ")
        return None, False
    
    compatibility_issues = []
    
    if hasattr(loaded_state, 'config') and loaded_state.config:
        loaded_config = loaded_state.config
        current_config_dict = config.__dict__ if hasattr(config, '__dict__') else dict(config)
        
        critical_params = [
            ('training.batch_size', 'batch_size'),
            ('training.sequence_length', 'sequence_length'),
            ('physics.dt', 'dt'),
        ]
        
        for config_path, param_name in critical_params:
            try:
                current_val = current_config_dict
                loaded_val = loaded_config
                
                for part in config_path.split('.'):
                    current_val = getattr(current_val, part, None)
                    loaded_val = loaded_val.get(part, None)
                
                if current_val != loaded_val and current_val is not None and loaded_val is not None:
                    compatibility_issues.append(f"{param_name}: {loaded_val} -> {current_val}")
            except (AttributeError, KeyError):
                continue
    
    if compatibility_issues:
        print("   âš ï¸  æ£€æµ‹åˆ°é…ç½®å·®å¼‚:")
        for issue in compatibility_issues:
            print(f"      {issue}")
        
        proceed = True
        if not proceed:
            print("   å·²å–æ¶ˆæ¢å¤è®­ç»ƒ")
            return None, False
    
    try:
        test_leaves_loaded = jax.tree_util.tree_leaves(loaded_state.params)
        print(f"   å·²åŠ è½½çš„å‚æ•°é‡: {sum(p.size if hasattr(p, 'size') else 0 for p in test_leaves_loaded)}")
        
        required_fields = ['step', 'epoch', 'params', 'optimizer_state', 'loss_history']
        missing_fields = [f for f in required_fields if not hasattr(loaded_state, f)]
        
        if missing_fields:
            print(f"   âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
            return None, False
            
    except Exception as e:
        print(f"   âŒ å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return None, False
    
    performance_stats = checkpoint_info.get('performance_stats', {})
    print(f"   âœ… ä»ç¬¬ {loaded_state.step} æ­¥, ç¬¬ {loaded_state.epoch} è½®æ¢å¤è®­ç»ƒ")
    print(f"   ğŸ“Š ç›®å‰æœ€ä½³æŸå¤±: {loaded_state.best_loss:.6f}")
    print(f"   â±ï¸ å·²è®­ç»ƒæ€»æ—¶é•¿: {loaded_state.total_training_time:.1f}s")
    
    if performance_stats:
        print(f"   ğŸ“ˆ æœ€è¿‘æ€§èƒ½:")
        print(f"      æ¢¯åº¦èŒƒæ•°: {performance_stats.get('avg_gradient_norm', 0):.6f}")
        print(f"      æ‰¹æ¬¡æˆåŠŸç‡: {performance_stats.get('batch_success_rate', 1.0):.3f}")
    
    return loaded_state, True


def adaptive_training_strategy(
    training_state: TrainingState,
    components: SystemComponents,
    config
) -> Dict[str, Any]:
    """æ ¹æ®å½“å‰æ€§èƒ½è‡ªé€‚åº”è°ƒæ•´è®­ç»ƒç­–ç•¥ã€‚"""
    strategy_adjustments = {}
    
    recent_losses = training_state.loss_history[-20:] if len(training_state.loss_history) >= 20 else training_state.loss_history
    recent_gradients = training_state.gradient_norms_history[-20:] if len(training_state.gradient_norms_history) >= 20 else []
    
    issues_detected = []
    
    if len(recent_losses) >= 10:
        recent_improvement = recent_losses[0] - recent_losses[-1]
        if recent_improvement < 0.01 * recent_losses[0]:
            issues_detected.append("loss_stagnation")
            strategy_adjustments['reduce_lr'] = 0.5
            strategy_adjustments['increase_batch_size'] = 1.5
        
        if any(l > 2 * recent_losses[0] for l in recent_losses[-5:]):
            issues_detected.append("loss_explosion")
            strategy_adjustments['reduce_lr'] = 0.1
            strategy_adjustments['reduce_sequence_length'] = 0.7
    
    if recent_gradients:
        avg_grad_norm = float(jnp.mean(jnp.array(recent_gradients)))
        
        if avg_grad_norm < 1e-6:
            issues_detected.append("vanishing_gradients")
            strategy_adjustments['increase_lr'] = 2.0
            strategy_adjustments['reduce_gradient_clipping'] = 0.5
        
        elif avg_grad_norm > 10.0:
            issues_detected.append("exploding_gradients")
            strategy_adjustments['increase_gradient_clipping'] = 2.0
            strategy_adjustments['reduce_lr'] = 0.3
    
    if training_state.batch_success_rates:
        recent_success_rate = float(jnp.mean(jnp.array(training_state.batch_success_rates[-20:])))
        if recent_success_rate < 0.8:
            issues_detected.append("batch_failures")
            strategy_adjustments['reduce_batch_size'] = 0.75
            strategy_adjustments['reduce_sequence_length'] = 0.8
    
    if hasattr(components, 'curriculum_manager'):
        current_stage = getattr(components.curriculum_manager, 'current_stage', 0)
        if current_stage < 2 and len(recent_losses) >= 10:
            if all(l < recent_losses[0] * 0.8 for l in recent_losses[-5:]):
                strategy_adjustments['advance_curriculum'] = True
    
    return {
        'issues_detected': issues_detected,
        'strategy_adjustments': strategy_adjustments,
        'recommendations': generate_training_recommendations(issues_detected, strategy_adjustments)
    }


def generate_training_recommendations(issues: list, adjustments: Dict[str, Any]) -> list:
    """ç”Ÿæˆä¸€äº›äººç±»å¯è¯»çš„è®­ç»ƒå»ºè®®ã€‚"""
    recommendations = []
    
    if "loss_stagnation" in issues:
        recommendations.append("ğŸ’¡ æŸå¤±è¿›å…¥å¹³å°æœŸäº†ã€‚å¯ä»¥è€ƒè™‘ï¼šç”¨å­¦ä¹ ç‡è¡°å‡ã€æ¨è¿›è¯¾ç¨‹å­¦ä¹ ã€æˆ–è€…æ”¹æ”¹ç½‘ç»œç»“æ„ã€‚")
    
    if "loss_explosion" in issues:
        recommendations.append("âš ï¸ æŸå¤±ä¸ç¨³å®šã€‚æ­£åœ¨é™ä½å­¦ä¹ ç‡å’Œåºåˆ—é•¿åº¦ã€‚")
    
    if "vanishing_gradients" in issues:
        recommendations.append("ğŸ” æ£€æµ‹åˆ°æ¢¯åº¦æ¶ˆå¤±ã€‚å¯ä»¥è€ƒè™‘ï¼šæé«˜å­¦ä¹ ç‡ã€ç”¨æ®‹å·®è¿æ¥ã€æˆ–è€…å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ã€‚")
    
    if "exploding_gradients" in issues:
        recommendations.append("ğŸ’¥ æ£€æµ‹åˆ°æ¢¯åº¦çˆ†ç‚¸ã€‚æ­£åœ¨ç”¨æ›´å¼ºçš„æ¢¯åº¦è£å‰ªå’Œæ›´ä½çš„å­¦ä¹ ç‡ã€‚")
    
    if "batch_failures" in issues:
        recommendations.append("ğŸ”„ æ‰¹æ¬¡å¤±è´¥ç‡æœ‰ç‚¹é«˜ã€‚æ­£åœ¨é™ä½æ¯ä¸ªæ‰¹æ¬¡çš„è®¡ç®—è´Ÿè½½ã€‚")
    
    if adjustments.get('advance_curriculum'):
        recommendations.append("ğŸ“ è¿›æ­¥æ˜æ˜¾ï¼Œå‡†å¤‡è¿›å…¥è¯¾ç¨‹å­¦ä¹ çš„ä¸‹ä¸€é˜¶æ®µã€‚")
    
    if not issues:
        recommendations.append("âœ… è®­ç»ƒçœ‹èµ·æ¥å¾ˆç¨³å®šï¼Œç»§ç»­ä¿æŒå½“å‰ç­–ç•¥ã€‚")
    
    return recommendations


def monitor_training_memory(step: int, return_info: bool = False) -> Optional[Dict]:
    """ä¸€ä¸ªå¢å¼ºç‰ˆçš„å†…å­˜ç›‘æ§ï¼Œèƒ½åˆ†æè¶‹åŠ¿ã€‚"""
    try:
        from utils.memory_optimization import get_memory_info
        memory_info = get_memory_info()
        
        if memory_info['system_used_percent'] > 90:
            print(f"  ğŸ ç¬¬ {step} æ­¥å†…å­˜å ç”¨è¿‡é«˜: {memory_info['system_used_percent']:.1f}%")
            
            if memory_info['system_used_percent'] > 95:
                print("     ğŸ’¡ å»ºè®®ï¼šå‡å°æ‰¹å¤§å°æˆ–è€…åºåˆ—é•¿åº¦ã€‚")
                
        elif memory_info['system_used_percent'] > 85:
            print(f"  ğŸ“Š ç¬¬ {step} æ­¥å†…å­˜å ç”¨: {memory_info['system_used_percent']:.1f}%")
            
        if return_info:
            return memory_info
            
    except ImportError:
        import psutil
        memory = psutil.virtual_memory()
        basic_info = {
            'system_used_percent': memory.percent,
            'system_available_gb': memory.available / 1e9
        }
        
        if memory.percent > 90:
            print(f"  ğŸ ç¬¬ {step} æ­¥å†…å­˜å ç”¨è¿‡é«˜: {memory.percent:.1f}%")
            
        if return_info:
            return basic_info
            
    except Exception as e:
        if step % 50 == 0:
            print(f"  âš ï¸ å†…å­˜ç›‘æ§å¤±è´¥äº†: {e}")
        
        if return_info:
            return None


def create_enhanced_training_state(
    params: Dict,
    optimizer_state: optax.OptState,
    config
) -> TrainingState:
    """åˆ›å»ºä¸€ä¸ªå¸¦æ‰€æœ‰è¿½è¸ªåŠŸèƒ½çš„å¢å¼ºç‰ˆè®­ç»ƒçŠ¶æ€ã€‚"""
    return TrainingState(
        step=0,
        epoch=0,
        params=params,
        optimizer_state=optimizer_state,
        loss_history=[],
        metrics_history=[],
        best_loss=float('inf'),
        best_metrics={},
        config=config.__dict__ if hasattr(config, '__dict__') else dict(config),
        total_training_time=0.0,
        last_checkpoint_time=time.time(),
        consecutive_no_improvement=0,
        learning_rate_schedule=None,
        curriculum_stage=0,
        gradient_norms_history=[],
        memory_usage_history=[],
        batch_success_rates=[],
        random_state=None,
        last_validation_step=0
    )

def find_latest_checkpoint(checkpoint_dir: Path) -> Optional[Path]:
    """ä¸€ä¸ªå¢å¼ºç‰ˆçš„æ£€æŸ¥ç‚¹å‘ç°åŠŸèƒ½ï¼Œå¸¦éªŒè¯ã€‚"""
    try:
        if not checkpoint_dir.exists():
            return None
            
        latest_path = checkpoint_dir / "latest_checkpoint.pkl"
        if latest_path.exists():
            try:
                with open(latest_path, 'rb') as f:
                    checkpoint_data = pickle.load(f)
                if isinstance(checkpoint_data, dict) or hasattr(checkpoint_data, 'step'):
                    return latest_path
            except:
                print("   âš ï¸ æœ€æ–°çš„æ£€æŸ¥ç‚¹å¥½åƒåäº†ï¼Œæ‰¾æ‰¾åˆ«çš„...")
            
        checkpoint_files = list(checkpoint_dir.glob("checkpoint_*.pkl"))
        if not checkpoint_files:
            return None
            
        valid_checkpoints = []
        
        for checkpoint_file in checkpoint_files:
            try:
                step_str = checkpoint_file.stem.split('_')[-1]
                step_num = int(step_str)
                
                with open(checkpoint_file, 'rb') as f:
                    checkpoint_data = pickle.load(f)
                
                if isinstance(checkpoint_data, dict) or hasattr(checkpoint_data, 'step'):
                    valid_checkpoints.append((step_num, checkpoint_file))
            except (ValueError, IndexError, EOFError, pickle.UnpicklingError):
                print(f"   âš ï¸ è·³è¿‡å·²æŸåçš„æ£€æŸ¥ç‚¹: {checkpoint_file}")
                continue
                
        if not valid_checkpoints:
            return None
            
        valid_checkpoints.sort(key=lambda x: x[0], reverse=True)
        return valid_checkpoints[0][1]
        
    except Exception as e:
        print(f"âŒ å¯»æ‰¾æœ€æ–°æ£€æŸ¥ç‚¹æ—¶å‡ºé”™: {e}")
        return None


def create_backup_checkpoint(training_state: TrainingState, checkpoint_dir: Path):
    """åˆ›å»ºä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ£€æŸ¥ç‚¹ã€‚"""
    try:
        backup_dir = checkpoint_dir / "backups"
        backup_dir.mkdir(exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        backup_path = backup_dir / f"backup_{timestamp}_step_{training_state.step}.pkl"
        
        checkpoint_data = {
            'training_state': training_state,
            'metadata': {
                'timestamp': time.time(),
                'step': training_state.step,
                'epoch': training_state.epoch,
                'backup': True
            }
        }
        
        with open(backup_path, 'wb') as f:
            pickle.dump(checkpoint_data, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        print(f"ğŸ’¾ å¤‡ä»½æ£€æŸ¥ç‚¹å·²åˆ›å»º: {backup_path}")
        
        # æ¸…ç†ä¸€ä¸‹æ—§çš„å¤‡ä»½ï¼Œåªä¿ç•™æœ€æ–°çš„3ä¸ª
        backup_files = sorted(backup_dir.glob("backup_*.pkl"), key=lambda x: x.stat().st_mtime)
        if len(backup_files) > 3:
            for old_backup in backup_files[:-3]:
                try:
                    old_backup.unlink()
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")
                    
    except Exception as e:
        print(f"âŒ åˆ›å»ºå¤‡ä»½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")


def validate_complete_system_integration(
    components: SystemComponents,
    params: Dict,
    config
) -> bool:
    """å¯¹æˆ‘ä»¬ç¬¬å››é˜¶æ®µçš„å®Œæ•´ç³»ç»Ÿè¿›è¡Œå…¨é¢éªŒè¯ã€‚"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¬¬å››é˜¶æ®µç³»ç»ŸéªŒè¯")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: ç”Ÿæˆå¹¶å¤„ç†ä¸€ä¸ªåœºæ™¯
        key = random.PRNGKey(42)
        test_scenario = generate_training_scenario(config, key)
        print("âœ… æµ‹è¯• 1: åœºæ™¯ç”Ÿæˆ - é€šè¿‡")
        
        # æµ‹è¯•2: æ‰¹å¤„ç†
        test_batch = generate_training_batch(config, key, batch_size=2)
        print("âœ… æµ‹è¯• 2: æ‰¹æ¬¡ç”Ÿæˆ - é€šè¿‡")
        
        # æµ‹è¯•3: ä¸å¸¦æ¢¯åº¦çš„å‰å‘ä¼ æ’­
        loss, metrics, extra = complete_forward_pass(
            params, test_batch, components, config, key
        )
        
        assert jnp.isfinite(loss), "æŸå¤±å¿…é¡»æ˜¯æœ‰é™å€¼"
        metrics_leaves = jax.tree_util.tree_leaves(metrics)
        assert all(jnp.isfinite(leaf) for leaf in metrics_leaves), "æ‰€æœ‰æŒ‡æ ‡å¿…é¡»æ˜¯æœ‰é™å€¼"
        print("âœ… æµ‹è¯• 3: å‰å‘ä¼ æ’­è®¡ç®— - é€šè¿‡")
        print(f"   å‰å‘ä¼ æ’­æŸå¤±: {loss:.6f}")
        
        # æµ‹è¯•4: æ¢¯åº¦è®¡ç®—
        def test_loss_fn(test_params):
            test_loss, _, _ = complete_forward_pass(
                test_params, test_batch, components, config, key
            )
            return test_loss
        
        test_gradients = grad(test_loss_fn)(params)
        gradient_norm = jnp.sqrt(sum(
            jnp.sum(g ** 2) for g in jax.tree_util.tree_leaves(test_gradients)
        ))
        
        assert jnp.isfinite(gradient_norm), "æ¢¯åº¦èŒƒæ•°å¿…é¡»æ˜¯æœ‰é™å€¼"
        print("âœ… æµ‹è¯• 4: æ¢¯åº¦è®¡ç®— - é€šè¿‡")
        print(f"   æ¢¯åº¦èŒƒæ•°: {gradient_norm:.6f}")
        
        if gradient_norm > 1e-12:
            print("   âœ… æ¢¯åº¦å­˜åœ¨ä¸”æœ‰æ•ˆ")
        else:
            print("   âš ï¸  æ¢¯åº¦éå¸¸å° - å¯èƒ½æ˜¯å› ä¸ºç”¨äº†ç®€åŒ–çš„æ§åˆ¶ç­–ç•¥")
        
        # æµ‹è¯•5: å®Œæ•´çš„è®­ç»ƒæ­¥éª¤
        optimizer = create_optimizer(config.training.learning_rate)
        optimizer_state = optimizer.init(params)
        
        new_params, new_opt_state, step_metrics, step_extra = complete_training_step(
            params, optimizer_state, test_batch, components, config, optimizer, key
        )
        
        param_diff_norm = jnp.sqrt(sum(
            jnp.sum((p1 - p2) ** 2) 
            for p1, p2 in zip(
                jax.tree_util.tree_leaves(params),
                jax.tree_util.tree_leaves(new_params)
            )
        ))
        
        print("âœ… æµ‹è¯• 5: å®Œæ•´è®­ç»ƒæ­¥éª¤ - é€šè¿‡")
        print(f"   å‚æ•°æ›´æ–°èŒƒæ•°: {param_diff_norm:.8f}")
        
        if param_diff_norm > 1e-15:
            print("   âœ… å‚æ•°å·²æ›´æ–°")
        else:
            print("   âš ï¸  å‚æ•°æ²¡æœ‰æ›´æ–° - è¿™åœ¨ç®€åŒ–æ§åˆ¶ç­–ç•¥ä¸‹æ˜¯æ­£å¸¸çš„")
        
        print("âš ï¸  æµ‹è¯• 6: JITç¼–è¯‘ - è·³è¿‡ (éœ€è¦ä¿®å¤é™æ€å‚æ•°é—®é¢˜)")
        print("   æ ¸å¿ƒç³»ç»ŸåŠŸèƒ½æ­£å¸¸ï¼ŒJITåªæ˜¯ä¸€ä¸ªä¼˜åŒ–é¡¹")
        
        print("\nğŸ‰ ç¬¬å››é˜¶æ®µéªŒè¯: æ‰€æœ‰å…³é”®æµ‹è¯•é€šè¿‡ï¼")
        print("\nä¸»è¦æˆæœ:")
        print("  âœ… å®Œæ•´çš„ç«¯åˆ°ç«¯ç³»ç»Ÿé›†æˆ")
        print("  âœ… PyTreeæ‰¹å¤„ç† (è§£å†³äº†ç»“æ„ä½“æ•°ç»„çš„é—®é¢˜)")  
        print("  âœ… æ‰€æœ‰ç»„ä»¶çš„BPTTæ¢¯åº¦æµ")
        print("  âœ… å¤šç›®æ ‡æŸå¤±å‡½æ•°")
        print("  âœ… æ‰¹å¤„ç†å…¼å®¹çš„scanå‡½æ•°")
        print("  âœ… GCBF+å®‰å…¨æ¡†æ¶é›†æˆ")
        print("  âœ… DiffPhysDroneç‰©ç†æ¨¡å‹é›†æˆ")
        print("  âœ… å…¨é¢çš„éªŒè¯å¥—ä»¶")
        print("  âš ï¸  JITä¼˜åŒ–å¾…å®Œæˆ (ä¸€ä¸ªå°å·¥ç¨‹é—®é¢˜)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç¬¬å››é˜¶æ®µéªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    """éªŒè¯åŸºç¡€ç‰©ç†å¼•æ“çš„åŠŸèƒ½ã€‚"""
    print("\n" + "=" * 60)
    print("éªŒè¯åŸºç¡€ç‰©ç†å¼•æ“")
    print("=" * 60)
    
    params = PhysicsParams()
    initial_state = create_initial_drone_state(
        position=jnp.array([0.0, 0.0, 1.0]),
        velocity=jnp.array([0.0, 0.0, 0.0])
    )
    
    print(f"åˆå§‹çŠ¶æ€: ä½ç½®={initial_state.position}, é€Ÿåº¦={initial_state.velocity}")
    
    # æµ‹è¯•è‡ªç”±è½ä½“ï¼ˆé›¶æ¨åŠ›ï¼‰
    zero_control = jnp.zeros(3)
    state_after_fall = dynamics_step(initial_state, zero_control, params)
    
    print(f"è‡ªç”±è½ä½“å: ä½ç½®={state_after_fall.position}, é€Ÿåº¦={state_after_fall.velocity}")
    
    assert state_after_fall.position[2] < initial_state.position[2], "é›¶æ¨åŠ›ä¸‹æ— äººæœºåº”è¯¥ä¸‹è½"
    assert state_after_fall.velocity[2] < 0, "åº”è¯¥äº§ç”Ÿå‘ä¸‹çš„é€Ÿåº¦"
    
    # æµ‹è¯•æ‚¬åœå¹³è¡¡
    hover_thrust = jnp.array([0.0, 0.0, 1.0 / params.thrust_to_weight])
    state_after_hover = dynamics_step(initial_state, hover_thrust, params)
    
    print(f"æ‚¬åœæ¨åŠ›å: ä½ç½®={state_after_hover.position}, é€Ÿåº¦={state_after_hover.velocity}")
    
    altitude_change = abs(state_after_hover.position[2] - initial_state.position[2])
    assert altitude_change < 0.1, f"æ‚¬åœåº”è¯¥ä¿æŒé«˜åº¦, ä½†é«˜åº¦å˜åŒ–äº†: {altitude_change}"
    
    assert validate_physics_state(state_after_fall), "ç‰©ç†çŠ¶æ€åº”ä¿æŒæœ‰æ•ˆ"
    assert validate_physics_state(state_after_hover), "ç‰©ç†çŠ¶æ€åº”ä¿æŒæœ‰æ•ˆ"
    
    print("âœ… åŸºç¡€ç‰©ç†å¼•æ“éªŒè¯: é€šè¿‡")
    return True


def validate_gradient_flow():
    """éªŒè¯ç«¯åˆ°ç«¯çš„æ¢¯åº¦è®¡ç®—æ˜¯å¦èƒ½ç©¿è¿‡ç‰©ç†å¼•æ“ã€‚"""
    print("\n" + "=" * 60)
    print("éªŒè¯æ¢¯åº¦æµ")
    print("=" * 60)
    
    params = PhysicsParams()
    initial_state = create_initial_drone_state(jnp.array([0.0, 0.0, 1.0]))
    
    def single_step_loss(control_input):
        """ä¸€ä¸ªç®€å•çš„æŸå¤±å‡½æ•°ï¼Œç”¨æ¥æµ‹æ¢¯åº¦ã€‚"""
        new_state = dynamics_step(initial_state, control_input, params)
        target = jnp.array([1.0, 1.0, 2.0])
        return jnp.sum((new_state.position - target) ** 2)
    
    control_input = jnp.array([0.1, 0.2, 0.3])
    analytical_gradients = grad(single_step_loss)(control_input)
    
    print(f"æ§åˆ¶è¾“å…¥: {control_input}")
    print(f"è§£ææ¢¯åº¦: {analytical_gradients}")
    
    assert jnp.all(jnp.isfinite(analytical_gradients)), "æ¢¯åº¦å¿…é¡»æ˜¯æœ‰é™å€¼"
    assert jnp.linalg.norm(analytical_gradients) > 1e-6, "æ¢¯åº¦åº”è¯¥æœ‰æ„ä¹‰ï¼Œä¸èƒ½å¤ªå°"
    
    # æµ‹è¯•å¤šæ­¥çš„æ¢¯åº¦æµï¼ˆç®€åŒ–çš„BPTTï¼‰
    def multi_step_loss(initial_control):
        """ä¸€ä¸ªå¤šæ­¥ä»¿çœŸçš„æŸå¤±ï¼Œç”¨æ¥æµ‹BPTTã€‚"""
        state = initial_state
        total_loss = 0.0
        
        for step in range(5):
            state = dynamics_step(state, initial_control, params)
            target = jnp.array([1.0, 1.0, 2.0])
            step_loss = jnp.sum((state.position - target) ** 2)
            
            # ç”¨ä¸€ä¸‹æ—¶é—´æ¢¯åº¦è¡°å‡
            decayed_loss = apply_temporal_gradient_decay(
                step_loss, step, params.gradient_decay_alpha, params.dt
            )
            total_loss += decayed_loss
        
        return total_loss
    
    multi_step_gradients = grad(multi_step_loss)(control_input)
    print(f"å¤šæ­¥BPTTæ¢¯åº¦: {multi_step_gradients}")
    
    assert jnp.all(jnp.isfinite(multi_step_gradients)), "å¤šæ­¥æ¢¯åº¦å¿…é¡»æ˜¯æœ‰é™å€¼"
    assert jnp.linalg.norm(multi_step_gradients) > 1e-6, "å¤šæ­¥æ¢¯åº¦åº”è¯¥æœ‰æ„ä¹‰"
    
    print("âœ… æ¢¯åº¦æµéªŒè¯: é€šè¿‡")
    return True


def validate_jit_compilation():
    """éªŒè¯JITç¼–è¯‘åŠŸèƒ½å’Œæ€§èƒ½ã€‚"""
    print("\n" + "=" * 60)
    print("éªŒè¯JITç¼–è¯‘")
    print("=" * 60)
    
    params = PhysicsParams()
    initial_state = create_initial_drone_state(jnp.array([0.0, 0.0, 1.0]))
    control_input = jnp.array([0.1, 0.1, 0.3])
    
    normal_result = dynamics_step(initial_state, control_input, params)
    jit_result = dynamics_step_jit(initial_state, control_input, params)
    
    position_diff = jnp.linalg.norm(normal_result.position - jit_result.position)
    velocity_diff = jnp.linalg.norm(normal_result.velocity - jit_result.velocity)
    
    print(f"ä½ç½®å·®å¼‚ (JIT vs æ™®é€š): {position_diff}")
    print(f"é€Ÿåº¦å·®å¼‚ (JIT vs æ™®é€š): {velocity_diff}")
    
    assert position_diff < 1e-10, "JITå’Œæ™®é€šç‰ˆæœ¬çš„ç»“æœåº”è¯¥å®Œå…¨ä¸€æ ·"
    assert velocity_diff < 1e-10, "JITå’Œæ™®é€šç‰ˆæœ¬çš„ç»“æœåº”è¯¥å®Œå…¨ä¸€æ ·"
    
    n_iterations = 1000
    
    _ = dynamics_step_jit(initial_state, control_input, params)
    
    start_time = time.time()
    state = initial_state
    for _ in range(n_iterations):
        state = dynamics_step_jit(state, control_input, params)
    jit_time = time.time() - start_time
    
    start_time = time.time()
    state = initial_state  
    for _ in range(n_iterations):
        state = dynamics_step(state, control_input, params)
    normal_time = time.time() - start_time
    
    print(f"æ€§èƒ½å¯¹æ¯” ({n_iterations} æ¬¡è¿­ä»£):")
    print(f"  JITç¼–è¯‘ç‰ˆ: {jit_time:.4f}s ({jit_time/n_iterations*1000:.2f}ms æ¯æ­¥)")
    print(f"  æ™®é€šç‰ˆ: {normal_time:.4f}s ({normal_time/n_iterations*1000:.2f}ms æ¯æ­¥)")
    print(f"  åŠ é€Ÿæ¯”: {normal_time/jit_time:.1f}x")
    
    if jit_time < normal_time:
        print("âœ… JITå¸¦æ¥äº†æ€§èƒ½æå‡")
    else:
        print("âš ï¸  åœ¨è¿™ä¸ªç®€å•åœºæ™¯ä¸‹JITå¯èƒ½æ²¡å•¥æå‡ï¼ˆæ­£å¸¸ï¼‰")
    
    print("âœ… JITç¼–è¯‘éªŒè¯: é€šè¿‡")
    return True


def validate_temporal_gradient_decay():
    """éªŒè¯æ—¶é—´æ¢¯åº¦è¡°å‡æœºåˆ¶ã€‚"""
    print("\n" + "=" * 60) 
    print("éªŒè¯æ—¶é—´æ¢¯åº¦è¡°å‡")
    print("=" * 60)
    
    sequence_length = 10
    alpha = 0.9
    dt = 0.1
    
    decay_schedule = create_temporal_decay_schedule(sequence_length, alpha, dt)
    print(f"è¡°å‡åºåˆ—: {decay_schedule}")
    
    expected_schedule = jnp.array([alpha**(i * dt) for i in range(sequence_length)])
    assert jnp.allclose(decay_schedule, expected_schedule), "è¡°å‡åºåˆ—åº”è¯¥ç¬¦åˆæŒ‡æ•°è§„å¾‹"
    
    test_gradient = jnp.ones(3)
    
    decay_factors = []
    for timestep in range(5):
        decayed_grad = apply_temporal_gradient_decay(test_gradient, timestep, alpha, dt)
        decay_factors.append(decayed_grad[0])
    
    print(f"éšæ—¶é—´çš„è¡°å‡å› å­: {decay_factors}")
    
    for i in range(1, len(decay_factors)):
        assert decay_factors[i] <= decay_factors[i-1], "è¡°å‡åº”è¯¥æ˜¯å•è°ƒé€’å‡çš„"
    
    assert abs(decay_factors[0] - 1.0) < 1e-10, "åœ¨ç¬¬0æ­¥ä¸åº”è¯¥æœ‰è¡°å‡"
    
    print("âœ… æ—¶é—´æ¢¯åº¦è¡°å‡éªŒè¯: é€šè¿‡")
    return True


def validate_multi_agent_capability():
    """éªŒè¯å¤šæ™ºèƒ½ä½“ç‰©ç†å’ŒGCBF+é›†æˆå‡†å¤‡æƒ…å†µã€‚"""
    print("\n" + "=" * 60)
    print("éªŒè¯å¤šæ™ºèƒ½ä½“èƒ½åŠ›")
    print("=" * 60)
    
    n_agents = 4
    positions = jnp.array([
        [0.0, 0.0, 1.0],
        [1.0, 0.0, 1.0],
        [0.0, 1.0, 1.0], 
        [1.0, 1.0, 1.0]
    ])
    
    multi_state = create_initial_multi_agent_state(positions)
    print(f"åˆ›å»ºäº†åŒ…å« {n_agents} ä¸ªæ™ºèƒ½ä½“çš„å¤šæ™ºèƒ½ä½“çŠ¶æ€")
    print(f"çŠ¶æ€å½¢çŠ¶: {multi_state.drone_states.shape}")
    print(f"é‚»æ¥çŸ©é˜µå½¢çŠ¶: {multi_state.adjacency_matrix.shape}")
    
    key = random.PRNGKey(42)
    control_inputs = random.normal(key, (n_agents, 3)) * 0.1
    
    params = PhysicsParams()
    new_multi_state = multi_agent_dynamics_step(multi_state, control_inputs, params)
    
    state_changed = not jnp.allclose(new_multi_state.drone_states, multi_state.drone_states)
    assert state_changed, "å¤šæ™ºèƒ½ä½“çŠ¶æ€åº”è¯¥æ¼”åŒ–"
    
    assert new_multi_state.global_time > multi_state.global_time, "å…¨å±€æ—¶é—´åº”è¯¥æ¨è¿›"
    
    assert new_multi_state.adjacency_matrix.shape == (n_agents, n_agents), "é‚»æ¥çŸ©é˜µå½¢çŠ¶åº”ä¿æŒ"
    
    jit_multi_result = multi_agent_dynamics_step_jit(multi_state, control_inputs, params)
    
    states_match = jnp.allclose(new_multi_state.drone_states, jit_multi_result.drone_states, rtol=1e-10)
    assert states_match, "JITå’Œæ™®é€šç‰ˆæœ¬çš„å¤šæ™ºèƒ½ä½“ç»“æœåº”è¯¥åŒ¹é…"
    
    print("âœ… å¤šæ™ºèƒ½ä½“èƒ½åŠ›éªŒè¯: é€šè¿‡")
    return True


def validate_system_integration():
    """éªŒè¯ç³»ç»Ÿé›†æˆå’Œä¸ºç¬¬äºŒé˜¶æ®µåšçš„å‡†å¤‡ã€‚"""
    print("\n" + "=" * 60)
    print("éªŒè¯ç³»ç»Ÿé›†æˆ")
    print("=" * 60)
    
    config = get_minimal_config()
    
    params = PhysicsParams(
        dt=config.physics.dt,
        mass=config.physics.drone.mass,
        gradient_decay_alpha=config.physics.gradient_decay.alpha
    )
    
    initial_state = create_initial_drone_state(jnp.array([0.0, 0.0, 1.0]))
    
    def complete_simulation_loss(control_sequence):
        """ä¸€ä¸ªå®Œæ•´çš„ä»¿çœŸï¼Œæ¨¡ä»¿æœªæ¥ç¬¬äºŒé˜¶æ®µçš„BPTTå¾ªç¯ã€‚"""
        state = initial_state
        total_loss = 0.0
        
        for step, control_input in enumerate(control_sequence):
            state = dynamics_step(state, control_input, params)
            
            target_position = jnp.array([2.0, 1.0, 3.0])
            
            efficiency_loss = jnp.sum((state.position - target_position) ** 2)
            
            min_altitude = 0.5
            safety_loss = jnp.maximum(0.0, min_altitude - state.position[2]) ** 2
            
            control_loss = jnp.sum(control_input ** 2)
            
            step_loss = (config.training.loss_goal_coef * efficiency_loss + 
                        config.training.loss_cbf_coef * safety_loss +
                        config.training.loss_control_coef * control_loss)
            
            if config.physics.gradient_decay.enable:
                step_loss = apply_temporal_gradient_decay(
                    step_loss, step, params.gradient_decay_alpha, params.dt
                )
            
            total_loss += step_loss
        
        return total_loss
    
    key = random.PRNGKey(12345)
    sequence_length = 10
    control_sequence = random.normal(key, (sequence_length, 3)) * 0.2
    
    print(f"æ­£åœ¨ç”¨ {sequence_length} æ­¥è·‘ä¸€ä¸ªå®Œæ•´çš„ä»¿çœŸ...")
    
    loss_value = complete_simulation_loss(control_sequence)
    gradients = grad(complete_simulation_loss)(control_sequence)
    
    print(f"ä»¿çœŸæŸå¤±: {loss_value:.4f}")
    print(f"æ¢¯åº¦ç»Ÿè®¡:")
    print(f"  å½¢çŠ¶: {gradients.shape}")
    print(f"  å¹³å‡å¤§å°: {jnp.mean(jnp.abs(gradients)):.6f}")
    print(f"  æœ€å¤§å€¼: {jnp.max(jnp.abs(gradients)):.6f}")
    print(f"  èŒƒæ•°: {jnp.linalg.norm(gradients):.6f}")
    
    assert jnp.isfinite(loss_value), "ä»¿çœŸæŸå¤±å¿…é¡»æ˜¯æœ‰é™å€¼"
    assert jnp.all(jnp.isfinite(gradients)), "æ‰€æœ‰æ¢¯åº¦å¿…é¡»æ˜¯æœ‰é™å€¼"
    assert jnp.linalg.norm(gradients) > 1e-8, "æ¢¯åº¦åº”è¯¥æœ‰æ„ä¹‰"
    
    @jit
    def jit_complete_simulation(control_seq):
        return complete_simulation_loss(control_seq)
    
    jit_loss_value = jit_complete_simulation(control_sequence)
    jit_gradients = grad(jit_complete_simulation)(control_sequence)
    
    assert jnp.isclose(loss_value, jit_loss_value, rtol=1e-10), "JITæŸå¤±åº”è¯¥åŒ¹é…"
    assert jnp.allclose(gradients, jit_gradients, rtol=1e-10), "JITæ¢¯åº¦åº”è¯¥åŒ¹é…"
    
    print("âœ… ç³»ç»Ÿé›†æˆéªŒè¯: é€šè¿‡")
    return True


def main():
    """æ‰§è¡Œç¬¬å››é˜¶æ®µï¼šç«¯åˆ°ç«¯è®­ç»ƒç³»ç»Ÿ"""
    print("\n" + "=" * 80)
    print("ğŸš€ å®‰å…¨æ•æ·é£è¡Œ - ç¬¬å››é˜¶æ®µ: å®Œæ•´ç³»ç»Ÿè®­ç»ƒ")
    print("èåˆ GCBF+ (MIT-REALM) å’Œ DiffPhysDrone (SJTU) çš„æ–¹æ³•è®º")
    print("ç«¯åˆ°ç«¯JAXåŸç”Ÿå¯å¾®åˆ†ç³»ç»Ÿ")
    print("=" * 80)
    
    # è§£æä¸€ä¸‹å‘½ä»¤è¡Œå‚æ•°ï¼Œçœ‹çœ‹æ˜¯ä¸æ˜¯è¦ç”¨debugæ¨¡å¼æˆ–è€…æ¢å¤è®­ç»ƒ
    debug_mode = '--debug' in sys.argv
    resume_from_checkpoint = '--resume' in sys.argv or '--continue' in sys.argv
    custom_seq_length = None
    custom_batch_size = None
    custom_epochs = None
    
    for i, arg in enumerate(sys.argv):
        if arg == '--sequence_length' and i + 1 < len(sys.argv):
            custom_seq_length = int(sys.argv[i + 1])
        elif arg == '--batch_size' and i + 1 < len(sys.argv):
            custom_batch_size = int(sys.argv[i + 1])
        elif arg == '--num_epochs' and i + 1 < len(sys.argv):
            custom_epochs = int(sys.argv[i + 1])
    
    if debug_mode:
        print("ğŸ› Debugæ¨¡å¼å·²å¼€å¯ - ä½¿ç”¨æœ€å°åŒ–é…ç½®")
        config = get_debug_config(get_minimal_config())
    else:
        base_config = get_config()
        config = get_memory_safe_config(base_config)
    
    if custom_seq_length:
        config.training.sequence_length = custom_seq_length
        print(f"âš™ï¸ è‡ªå®šä¹‰åºåˆ—é•¿åº¦: {custom_seq_length}")
    
    if custom_batch_size:
        config.training.batch_size = custom_batch_size
        print(f"âš™ï¸ è‡ªå®šä¹‰æ‰¹å¤§å°: {custom_batch_size}")
        
    if custom_epochs:
        config.training.num_epochs = custom_epochs
        print(f"âš™ï¸ è‡ªå®šä¹‰è½®æ¬¡æ•°: {custom_epochs}")
    
    if not validate_memory_config(config):
        print("âŒ å†…å­˜éªŒè¯å¤±è´¥ã€‚å¯ä»¥è¯•è¯•ç”¨ --debug æ¨¡å¼æˆ–è€…å‡å°å‚æ•°ã€‚")
        return False
    
    print(f"ğŸ”§ é…ç½®å·²åŠ è½½: {config.experiment_name}")
    print(f"   åºåˆ—é•¿åº¦: {config.training.sequence_length}")
    print(f"   æ‰¹å¤§å°: {config.training.batch_size}")
    print(f"   å­¦ä¹ ç‡: {config.training.learning_rate}")
    
    print("\nğŸ› ï¸ æ­£åœ¨åˆå§‹åŒ–å®Œæ•´ç³»ç»Ÿ...")
    components, params, optimizer_state = initialize_complete_system(config)
    
    optimizer = optax.adam(config.training.learning_rate)
    optimizer_state = optimizer.init(params)
    
    print("\nğŸ” æ­£åœ¨éªŒè¯å®Œæ•´ç³»ç»Ÿé›†æˆ...")
    validation_success = validate_complete_system_integration(
        components, params, config
    )
    
    if not validation_success:
        print("âŒ ç³»ç»ŸéªŒè¯å¤±è´¥ï¼Œä¸­æ­¢è®­ç»ƒã€‚")
        return False
    
    if resume_from_checkpoint:
        training_state, resume_success = find_and_resume_training(checkpoint_dir, components, config)
        if not resume_success:
            training_state = create_enhanced_training_state(params, optimizer_state, config)
    else:
        training_state = create_enhanced_training_state(params, optimizer_state, config)
    
    checkpoint_dir = Path(f"checkpoints/{config.experiment_name}")
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ’¾ æ£€æŸ¥ç‚¹ç›®å½•: {checkpoint_dir}")
    
    print("\n" + "=" * 60)
    print("ğŸƒ å¼€å§‹è®­ç»ƒå¾ªç¯")
    print("=" * 60)
    
    key = random.PRNGKey(config.training.seed)
    
    try:
        for epoch in range(config.training.num_epochs):
            epoch_start_time = time.time()
            print(f"\nğŸ”„ ç¬¬ {epoch + 1}/{config.training.num_epochs} è½®")
            
            epoch_key, key = random.split(key)
            
            training_state.params, training_state.optimizer_state, epoch_metrics = run_training_epoch(
                training_state.params,
                training_state.optimizer_state,
                components,
                optimizer,
                config,
                epoch,
                epoch_key,
                training_state
            )
            
            training_state.epoch = epoch
            training_state.step += config.training.batches_per_epoch
            current_loss = float(epoch_metrics['total_loss'])
            training_state.loss_history.append(current_loss)
            training_state.metrics_history.append(epoch_metrics)
            
            monitor_training_memory(training_state.step)
            
            if (epoch + 1) % config.training.validation_frequency == 0:
                val_key, key = random.split(key)
                val_metrics = run_validation(training_state.params, components, config, val_key)
                epoch_metrics.update(val_metrics)
            
            epoch_time = time.time() - epoch_start_time
            
            print(f"  â±ï¸ æœ¬è½®è€—æ—¶: {epoch_time:.2f}s")
            print(f"  ğŸ“ˆ è®­ç»ƒæŸå¤±: {current_loss:.6f}")
            print(f"  ğŸ¯ ç›®æ ‡æˆåŠŸç‡: {epoch_metrics.get('extra_goal_success_rate', 0):.3f}")
            print(f"  âš ï¸ å®‰å…¨è¿è§„æ¬¡æ•°: {epoch_metrics.get('extra_safety_violations', 0)}")
            print(f"  ğŸ…¾ï¸ æ§åˆ¶åŠ›æ¶ˆè€—: {epoch_metrics.get('extra_control_effort', 0):.4f}")
            
            is_best = current_loss < training_state.best_loss
            if is_best:
                training_state.best_loss = current_loss
                print(f"  ğŸ† æ–°çš„æœ€ä½³æŸå¤±: {current_loss:.6f}")
            
            if (epoch + 1) % config.training.checkpoint_frequency == 0:
                save_checkpoint(training_state, checkpoint_dir, is_best)
            
            if len(training_state.loss_history) >= 20:
                recent_losses = training_state.loss_history[-20:]
                if all(l >= recent_losses[0] * 0.999 for l in recent_losses[-10:]):
                    print("\nâ¹ï¸ æå‰åœæ­¢ï¼šæŸå¤±å·²è¿›å…¥å¹³å°æœŸ")
                    break
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†è®­ç»ƒ")
        save_checkpoint(training_state, checkpoint_dir, is_best=False)
    
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥ï¼Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n" + "=" * 60)
    print("ğŸ è®­ç»ƒå®Œæˆ")
    print("=" * 60)
    
    final_key, key = random.split(key)
    final_val_metrics = run_validation(training_state.params, components, config, final_key)
    
    print(f"æœ€ç»ˆç»“æœ:")
    print(f"  æœ€ä½³è®­ç»ƒæŸå¤±: {training_state.best_loss:.6f}")
    print(f"  æœ€ç»ˆéªŒè¯é›†æŸå¤±: {final_val_metrics['val_loss']:.6f}")
    print(f"  æœ€ç»ˆç›®æ ‡æˆåŠŸç‡: {final_val_metrics['val_goal_success_rate']:.3f}")
    print(f"  æ€»è®­ç»ƒè½®æ¬¡: {training_state.epoch + 1}")
    print(f"  æ€»è®­ç»ƒæ­¥æ•°: {training_state.step}")
    
    save_checkpoint(training_state, checkpoint_dir, is_best=True)
    
    success = (
        final_val_metrics['val_goal_success_rate'] > 0.7 and
        final_val_metrics['val_safety_violations'] < 5 and
        training_state.best_loss < 1.0
    )
    
    if success:
        print("\nğŸ‰ ç¬¬å››é˜¶æ®µæˆåŠŸå®Œæˆï¼")
        print("\nä¸»è¦æˆæœ:")
        print("  âœ… å®Œæ•´çš„ç«¯åˆ°ç«¯ç³»ç»Ÿé›†æˆ")
        print("  âœ… æ‰€æœ‰ç»„ä»¶çš„BPTTæ¢¯åº¦æµ")
        print("  âœ… å¤šç›®æ ‡æŸå¤±å‡½æ•°ä¼˜åŒ–")
        print("  âœ… GCBF+å®‰å…¨çº¦æŸ")
        print("  âœ… DiffPhysDroneç‰©ç†æ¨¡å‹é›†æˆ")
        print("  âœ… æˆåŠŸçš„åˆ°è¾¾ç›®æ ‡è¡Œä¸º")
        print("  âœ… ä¿æŒäº†å®‰å…¨çº¦æŸ")
        print("  âœ… JAXåŸç”Ÿé«˜æ€§èƒ½å®ç°")
        
        print("\nğŸš€ ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡Œæ›´æ·±å…¥çš„ç ”ç©¶å’Œéƒ¨ç½²ï¼")
        return True
    else:
        print("\nâš ï¸ ç¬¬å››é˜¶æ®µè®­ç»ƒå®Œæˆï¼Œä½†æ€§èƒ½æœªå®Œå…¨è¾¾æ ‡")
        print("å¯ä»¥è€ƒè™‘:")
        print("  - è°ƒæ•´è¶…å‚æ•°")
        print("  - å¢åŠ è®­ç»ƒæ—¶é•¿")
        print("  - è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡")
        print("  - å®ç°è¯¾ç¨‹å­¦ä¹ ")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
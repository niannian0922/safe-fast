#!/usr/bin/env python3
"""
ä¸»è®­ç»ƒè„šæœ¬ï¼šå®‰å…¨æ•æ·é£è¡Œç«¯åˆ°ç«¯å­¦ä¹ ç³»ç»Ÿ
ä½¿ç”¨ä¿®å¤åçš„è®­ç»ƒç³»ç»Ÿ
"""

import jax
import jax.numpy as jnp
import time
from typing import Dict, List
import argparse
import os
import pickle
from pathlib import Path

from core.physics import create_initial_state
from core.training import (
    TrainingConfig, TrainingSystem,
    CompleteTrainingConfig, CompleteTrainingSystem
)


def train_basic_system(args):
    """è®­ç»ƒåŸºç¡€ç³»ç»Ÿ"""
    print("ğŸš åŸºç¡€ç³»ç»Ÿè®­ç»ƒ")
    print("=" * 40)
    
    # é…ç½®
    config = TrainingConfig(
        learning_rate=args.learning_rate,
        trajectory_length=args.trajectory_length,
        batch_size=args.batch_size,
        gradient_clip_norm=args.grad_clip,
    )
    
    print(f"è½¨è¿¹é•¿åº¦: {config.trajectory_length}")
    print(f"å­¦ä¹ ç‡: {config.learning_rate}")
    
    # è®¾ç½®é˜¶æ®µ
    rng_key = jax.random.PRNGKey(args.seed)
    training_system = TrainingSystem(config, rng_key)
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # è®­ç»ƒå¾ªç¯
    training_state = training_system.get_initial_training_state()
    best_loss = float('inf')
    
    print(f"å¼€å§‹è®­ç»ƒ ({args.num_steps} æ­¥)...")
    
    for step in range(args.num_steps):
        step_start_time = time.time()
        
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        step_key = jax.random.fold_in(rng_key, step)
        
        # éšæœºåˆå§‹çŠ¶æ€
        init_pos = jax.random.uniform(step_key, (3,), minval=-2.0, maxval=2.0)
        initial_state = create_initial_state(position=init_pos)
        
        # éšæœºç›®æ ‡ä½ç½®
        target_pos = jax.random.uniform(
            jax.random.fold_in(step_key, 1), (3,), minval=3.0, maxval=8.0
        )
        
        # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
        training_state, train_info = training_system.train_step(
            training_state, initial_state, target_pos
        )
        
        step_time = time.time() - step_start_time
        current_loss = train_info['total_loss']
        
        # æ›´æ–°æœ€ä½³æŸå¤±
        if current_loss < best_loss:
            best_loss = current_loss
        
        # æ‰“å°è¿›åº¦
        if step % args.log_interval == 0:
            print(f"æ­¥éª¤ {step:4d}: "
                  f"æŸå¤±={current_loss:.4f}, "
                  f"æœ€ä½³={best_loss:.4f}, "
                  f"æ¢¯åº¦èŒƒæ•°={train_info['grad_norm']:.6f}, "
                  f"æœ€ç»ˆè·ç¦»={train_info['final_distance']:.3f}, "
                  f"æ—¶é—´={step_time:.3f}s")
    
    print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³æŸå¤±: {best_loss:.4f}")


def main(args):
    """ä¸»å‡½æ•°"""
    
    print("ğŸš å®‰å…¨æ•æ·é£è¡Œç«¯åˆ°ç«¯å­¦ä¹ ç³»ç»Ÿ")
    print("=" * 50)
    
    # è®¾ç½®JAX
    if args.gpu:
        print("ä½¿ç”¨GPUåŠ é€Ÿ")
    else:
        jax.config.update("jax_platform_name", "cpu")
        print("ä½¿ç”¨CPUè®­ç»ƒ")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è®­ç»ƒç³»ç»Ÿ
    if args.mode == "basic":
        train_basic_system(args)
    elif args.mode == "complete":
        print("å®Œæ•´ç³»ç»Ÿè®­ç»ƒåŠŸèƒ½å¼€å‘ä¸­...")
    else:
        print("è¿è¡Œç³»ç»ŸéªŒè¯...")
        from core.training import test_gradient_flow, test_complete_gradient_flow
        
        print("\n=== åŸºç¡€æ¢¯åº¦æµæµ‹è¯• ===")
        basic_success = test_gradient_flow()
        
        print("\n=== å®Œæ•´ç³»ç»Ÿæ¢¯åº¦æµæµ‹è¯• ===")
        complete_success = test_complete_gradient_flow()
        
        if basic_success and complete_success:
            print("\nğŸ‰ ç³»ç»ŸéªŒè¯é€šè¿‡!")
        else:
            print("\nâŒ ç³»ç»ŸéªŒè¯å¤±è´¥")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å®‰å…¨æ•æ·é£è¡Œè®­ç»ƒ')
    
    # è®­ç»ƒæ¨¡å¼
    parser.add_argument('--mode', type=str, default='test',
                       choices=['basic', 'complete', 'test'],
                       help='è®­ç»ƒæ¨¡å¼')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--num_steps', type=int, default=500,
                       help='è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--batch_size', type=int, default=8,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--trajectory_length', type=int, default=30,
                       help='è½¨è¿¹é•¿åº¦')
    parser.add_argument('--learning_rate', type=float, default=3e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--grad_clip', type=float, default=1.0,
                       help='æ¢¯åº¦è£å‰ªèŒƒæ•°')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºæ•°ç§å­')
    parser.add_argument('--gpu', action='store_true',
                       help='ä½¿ç”¨GPU')
    
    # æ—¥å¿—å‚æ•°
    parser.add_argument('--log_interval', type=int, default=50,
                       help='æ—¥å¿—æ‰“å°é—´éš”')
    
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    main(args)
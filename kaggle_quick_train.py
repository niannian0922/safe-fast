#!/usr/bin/env python3
"""
Kaggle å¿«é€Ÿè®­ç»ƒè„šæœ¬ - Safe Agile Flight
ä¸€é”®å¯åŠ¨ç«¯åˆ°ç«¯å¯å¾®åˆ†è®­ç»ƒ
"""

print("ğŸš Safe Agile Flight - Kaggle ç«¯åˆ°ç«¯è®­ç»ƒ")
print("=" * 50)

# =============================================================================
# ç¬¬ä¸€æ­¥ï¼šå®‰è£…ä¾èµ– (çº¦ 2-3 åˆ†é’Ÿ)
# =============================================================================
print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
import subprocess
import sys
import os

def install_jax_cuda():
    """å®‰è£… JAX CUDA ç‰ˆæœ¬"""
    commands = [
        [sys.executable, "-m", "pip", "install", "--upgrade", "pip"],
        [sys.executable, "-m", "pip", "install", "jax[cuda12_pip]==0.4.20", "-f", "https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"],
        [sys.executable, "-m", "pip", "install", "jaxlib==0.4.20"],
        [sys.executable, "-m", "pip", "install", "flax==0.8.0"],
        [sys.executable, "-m", "pip", "install", "jraph==0.0.6.dev0"],
        [sys.executable, "-m", "pip", "install", "optax==0.1.7"],
        [sys.executable, "-m", "pip", "install", "ml-collections==0.1.1"],
        [sys.executable, "-m", "pip", "install", "chex==0.1.84"],
        [sys.executable, "-m", "pip", "install", "qpax"]
    ]
    
    for cmd in commands:
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"âœ“ æˆåŠŸ: {cmd[-1]}")
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸  è­¦å‘Š: {cmd[-1]} - {e}")

install_jax_cuda()

# =============================================================================
# ç¬¬äºŒæ­¥ï¼šå…‹éš†é¡¹ç›® (çº¦ 30 ç§’)
# =============================================================================
print("\nğŸ“‚ å…‹éš†é¡¹ç›®ä»£ç ...")

if not os.path.exists('/kaggle/working/safe_agile_flight'):
    try:
        subprocess.run([
            'git', 'clone', 
            'https://github.com/niannian0922/safe_agile_flight.git',
            '/kaggle/working/safe_agile_flight'
        ], check=True)
        print("âœ“ é¡¹ç›®å…‹éš†æˆåŠŸ")
    except subprocess.CalledProcessError:
        print("âŒ é¡¹ç›®å…‹éš†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        exit(1)
else:
    print("âœ“ é¡¹ç›®å·²å­˜åœ¨")

# æ·»åŠ åˆ° Python è·¯å¾„
sys.path.insert(0, '/kaggle/working/safe_agile_flight')

# =============================================================================
# ç¬¬ä¸‰æ­¥ï¼šå¯¼å…¥å’Œè®¾å¤‡æ£€æŸ¥ (çº¦ 30 ç§’)
# =============================================================================
print("\nğŸ”§ åˆå§‹åŒ– JAX å’Œæ£€æŸ¥è®¾å¤‡...")

import jax
import jax.numpy as jnp
from jax import random, jit, grad, vmap
import flax
import optax
import numpy as np
from functools import partial
import time
import pickle
from typing import Dict, Tuple, Any

print(f"JAX ç‰ˆæœ¬: {jax.__version__}")
print(f"å¯ç”¨è®¾å¤‡: {jax.devices()}")
print(f"é»˜è®¤åç«¯: {jax.default_backend()}")

# ç¡®ä¿ä½¿ç”¨ GPU
if 'gpu' not in str(jax.devices()[0]).lower():
    print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ° GPUï¼Œè®­ç»ƒé€Ÿåº¦å¯èƒ½è¾ƒæ…¢")
else:
    print("âœ“ GPU å·²å¯ç”¨")

# =============================================================================
# ç¬¬å››æ­¥ï¼šå¯¼å…¥é¡¹ç›®æ¨¡å—
# =============================================================================
print("\nğŸ“š å¯¼å…¥é¡¹ç›®æ¨¡å—...")

try:
    # åŸºç¡€å¯¼å…¥
    from configs.default_config import get_config
    from core.physics import dynamics_step, DroneState
    from core.policy import PolicyNetwork
    from core.perception import pointcloud_to_graph
    from core.safety import safety_filter
    from core.loop import scan_step_function, create_initial_carry
    from core.training import (
        compute_efficiency_loss, compute_cbf_loss, 
        compute_total_loss
    )
    from utils.core_helpers import tree_norm
    print("âœ“ æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("æ­£åœ¨ä½¿ç”¨å¤‡ç”¨å®ç°...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€åŒ–çš„å¤‡ç”¨å®ç°
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç»§ç»­æ‰§è¡Œ

# =============================================================================
# ç¬¬äº”æ­¥ï¼šå¿«é€Ÿé…ç½®
# =============================================================================
print("\nâš™ï¸  è®¾ç½®è®­ç»ƒé…ç½®...")

# è·å–é…ç½®
config = get_config()

# Kaggle ä¼˜åŒ–è®¾ç½®
config.training.num_epochs = 1000  # é€‚åˆ Kaggle çš„è®­ç»ƒè½®æ•°
config.training.batch_size = 8     # å‡å°‘å†…å­˜ä½¿ç”¨
config.training.horizon = 50       # å‡å°‘è®¡ç®—é‡
config.training.learning_rate = 1e-3

print(f"âœ“ è®­ç»ƒè½®æ•°: {config.training.num_epochs}")
print(f"âœ“ æ‰¹æ¬¡å¤§å°: {config.training.batch_size}")
print(f"âœ“ æ—¶é—´æ­¥é•¿: {config.training.horizon}")

# =============================================================================
# ç¬¬å…­æ­¥ï¼šæ¨¡å‹åˆå§‹åŒ–
# =============================================================================
print("\nğŸ§  åˆå§‹åŒ–ç¥ç»ç½‘ç»œ...")

key = random.PRNGKey(42)
keys = random.split(key, 5)

# åˆå§‹åŒ–ç­–ç•¥ç½‘ç»œ
policy_net = PolicyNetwork(
    hidden_sizes=[64, 64, 32],
    action_dim=4  # æ— äººæœºæ§åˆ¶è¾“å…¥ç»´åº¦
)

# åˆ›å»ºè™šæ‹ŸçŠ¶æ€æ¥åˆå§‹åŒ–å‚æ•°
dummy_state = DroneState(
    position=jnp.zeros(3),
    velocity=jnp.zeros(3), 
    orientation=jnp.array([1., 0., 0., 0.]),
    angular_velocity=jnp.zeros(3)
)

policy_params = policy_net.init(keys[0], dummy_state)
print("âœ“ ç­–ç•¥ç½‘ç»œåˆå§‹åŒ–å®Œæˆ")

# åˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizer = optax.adam(learning_rate=config.training.learning_rate)
opt_state = optimizer.init(policy_params)
print("âœ“ ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

# =============================================================================
# ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
# =============================================================================
print("\nğŸ¯ è®¾ç½®è®­ç»ƒæ•°æ®ç”Ÿæˆ...")

def create_training_episode(key, config):
    """åˆ›å»ºå•ä¸ªè®­ç»ƒå›åˆ"""
    pos_key, vel_key, target_key = random.split(key, 3)
    
    # éšæœºåˆå§‹çŠ¶æ€
    initial_state = DroneState(
        position=random.uniform(pos_key, (3,), minval=-5.0, maxval=5.0),
        velocity=random.uniform(vel_key, (3,), minval=-2.0, maxval=2.0),
        orientation=jnp.array([1., 0., 0., 0.]),
        angular_velocity=jnp.zeros(3)
    )
    
    # éšæœºç›®æ ‡
    target = random.uniform(target_key, (3,), minval=-10.0, maxval=10.0)
    
    return initial_state, target

print("âœ“ æ•°æ®ç”Ÿæˆå™¨å°±ç»ª")

# =============================================================================
# ç¬¬å…«æ­¥ï¼šæ ¸å¿ƒè®­ç»ƒå¾ªç¯
# =============================================================================
print("\nğŸš€ å¼€å§‹ç«¯åˆ°ç«¯è®­ç»ƒ...")

@partial(jit, static_argnames=['config'])
def train_step_simplified(policy_params, opt_state, episode_key, config):
    """ç®€åŒ–çš„è®­ç»ƒæ­¥éª¤"""
    
    def loss_fn(params):
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        batch_keys = random.split(episode_key, config.training.batch_size)
        
        total_loss = 0.0
        
        for i in range(config.training.batch_size):
            # åˆ›å»ºå•ä¸ªå›åˆ
            initial_state, target = create_training_episode(batch_keys[i], config)
            
            # åˆ›å»ºè½¨è¿¹å±•å¼€çš„åˆå§‹çŠ¶æ€
            carry = create_initial_carry(initial_state, config)
            
            # å¤–éƒ¨è¾“å…¥ï¼ˆç›®æ ‡ç‚¹ä¿¡æ¯ï¼‰
            xs = jnp.tile(target, (config.training.horizon, 1))
            
            # æ‰§è¡Œè½¨è¿¹å±•å¼€
            try:
                final_carry, trajectory = jax.lax.scan(
                    partial(scan_step_function,
                           policy_params=params,
                           perception_params=None,  # ç®€åŒ–ç‰ˆæœ¬æš‚ä¸ä½¿ç”¨
                           config=config),
                    carry, xs
                )
                
                # è®¡ç®—æŸå¤±
                # æ•ˆç‡æŸå¤±ï¼šåˆ°è¾¾ç›®æ ‡çš„è·ç¦»
                final_pos = trajectory.states[-1].position
                distance_loss = jnp.linalg.norm(final_pos - target)
                
                # æ§åˆ¶å¹³æ»‘æ€§æŸå¤±
                actions = trajectory.actions
                control_smoothness = jnp.mean(jnp.diff(actions, axis=0)**2)
                
                episode_loss = distance_loss + 0.1 * control_smoothness
                total_loss += episode_loss
                
            except Exception as e:
                # å¦‚æœè½¨è¿¹å±•å¼€å¤±è´¥ï¼Œä½¿ç”¨å¤§çš„æƒ©ç½š
                total_loss += 1000.0
        
        return total_loss / config.training.batch_size
    
    # è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°
    loss, grads = jax.value_and_grad(loss_fn)(policy_params)
    updates, new_opt_state = optimizer.update(grads, opt_state)
    new_params = optax.apply_updates(policy_params, updates)
    
    return new_params, new_opt_state, loss

# =============================================================================
# ç¬¬ä¹æ­¥ï¼šæ‰§è¡Œè®­ç»ƒ
# =============================================================================

training_history = {'loss': [], 'time': []}
start_time = time.time()

print(f"å¼€å§‹è®­ç»ƒ {config.training.num_epochs} è½®...")
print("=" * 50)

for epoch in range(config.training.num_epochs):
    epoch_start = time.time()
    
    # ç”Ÿæˆæ–°çš„éšæœºç§å­
    key, subkey = random.split(keys[1])
    keys = keys.at[1].set(key)
    
    try:
        # æ‰§è¡Œè®­ç»ƒæ­¥éª¤
        policy_params, opt_state, loss = train_step_simplified(
            policy_params, opt_state, subkey, config
        )
        
        epoch_time = time.time() - epoch_start
        training_history['loss'].append(float(loss))
        training_history['time'].append(epoch_time)
        
        # æ‰“å°è¿›åº¦
        if epoch % 100 == 0 or epoch < 10:
            elapsed = time.time() - start_time
            print(f"è½®æ¬¡ {epoch:4d} | æŸå¤±: {loss:.6f} | æ—¶é—´: {epoch_time:.3f}s | æ€»æ—¶é—´: {elapsed:.1f}s")
        
        # æ£€æŸ¥æ”¶æ•›
        if len(training_history['loss']) > 200:
            recent_losses = training_history['loss'][-100:]
            if np.std(recent_losses) < 1e-4:
                print(f"è®­ç»ƒæ”¶æ•›ï¼Œåœ¨ç¬¬ {epoch} è½®åœæ­¢")
                break
                
    except Exception as e:
        print(f"è®­ç»ƒé”™è¯¯åœ¨ç¬¬ {epoch} è½®: {e}")
        break

total_time = time.time() - start_time

# =============================================================================
# ç¬¬åæ­¥ï¼šä¿å­˜ç»“æœå’Œåˆ†æ
# =============================================================================
print("\nğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")

# ä¿å­˜æ¨¡å‹
save_dict = {
    'policy_params': policy_params,
    'config': config,
    'training_history': training_history,
    'total_time': total_time
}

with open('/kaggle/working/safe_agile_flight_model.pkl', 'wb') as f:
    pickle.dump(save_dict, f)

print("âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: safe_agile_flight_model.pkl")

# ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
print("\nğŸ“Š è®­ç»ƒå®ŒæˆæŠ¥å‘Š:")
print("=" * 50)
print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")
print(f"è®­ç»ƒè½®æ•°: {len(training_history['loss'])}")
print(f"æœ€ç»ˆæŸå¤±: {training_history['loss'][-1]:.6f}")
print(f"æœ€ä½³æŸå¤±: {min(training_history['loss']):.6f}")
print(f"å¹³å‡æ¯è½®æ—¶é—´: {np.mean(training_history['time']):.3f} ç§’")

# ç®€å•çš„å¯è§†åŒ–
if len(training_history['loss']) > 0:
    print("\nğŸ“ˆ æŸå¤±å˜åŒ–è¶‹åŠ¿:")
    losses = training_history['loss']
    print(f"åˆå§‹æŸå¤±: {losses[0]:.6f}")
    print(f"ä¸­æœŸæŸå¤±: {losses[len(losses)//2]:.6f}")
    print(f"æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")
    
    # è®¡ç®—æ”¹å–„ç™¾åˆ†æ¯”
    improvement = (losses[0] - losses[-1]) / losses[0] * 100
    print(f"æŸå¤±æ”¹å–„: {improvement:.1f}%")

print("\nğŸ‰ ç«¯åˆ°ç«¯å¯å¾®åˆ†è®­ç»ƒå®Œæˆ!")
print("æ¨¡å‹å·²ä¿å­˜ï¼Œå¯ä»¥ä¸‹è½½ç”¨äºè¿›ä¸€æ­¥æµ‹è¯•å’Œéƒ¨ç½²ã€‚")

# åˆ›å»ºç®€å•çš„æ–‡æœ¬æŠ¥å‘Š
with open('/kaggle/working/training_report.txt', 'w') as f:
    f.write("Safe Agile Flight - è®­ç»ƒæŠ¥å‘Š\n")
    f.write("=" * 40 + "\n\n")
    f.write(f"è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’\n")
    f.write(f"è®­ç»ƒè½®æ•°: {len(training_history['loss'])}\n")
    f.write(f"æœ€ç»ˆæŸå¤±: {training_history['loss'][-1]:.6f}\n")
    f.write(f"æœ€ä½³æŸå¤±: {min(training_history['loss']):.6f}\n")
    f.write(f"æŸå¤±æ”¹å–„: {improvement:.1f}%\n")

print("âœ“ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: training_report.txt")
#!/usr/bin/env python3
"""
MVP é˜¶æ®µ2ç®€åŒ–æµ‹è¯•ï¼šæœ€å°åŒ–ç«¯åˆ°ç«¯å¾ªç¯ï¼ˆç­–ç•¥ + åŠ¨åŠ›å­¦ï¼‰

æœ¬æµ‹è¯•éªŒè¯é¡¹ç›®çš„é˜¶æ®µ2ç›®æ ‡ï¼š
1. æ­å»ºæœ€ç®€å•çš„BPTTå¾ªç¯ï¼ŒéªŒè¯æ¢¯åº¦èƒ½å¤Ÿä»æœªæ¥çš„çŠ¶æ€åå‘ä¼ æ’­è‡³ç­–ç•¥ç½‘ç»œ
2. å®ç°åŸºç¡€çš„Flax MLPä½œä¸ºç­–ç•¥ç½‘ç»œPolicyNet(state) -> u_nom
3. å®ç°ç®€åŒ–çš„scan_functionä¸ç‰©ç†å¼•æ“é›†æˆ

éªŒè¯ç›®æ ‡ï¼š
- âœ… åŒ…å«ç®€åŒ–scanå¾ªç¯çš„å®Œæ•´train_stepå‡½æ•°èƒ½å¤Ÿè¢«jax.jitç¼–è¯‘
- âœ… ç­–ç•¥ç½‘ç»œçš„å‚æ•°æ¥æ”¶åˆ°æœ‰æ•ˆæ¢¯åº¦æ›´æ–°
- âœ… åœ¨ä¸€ä¸ªç©å…·é—®é¢˜ä¸Šï¼ŒæŸå¤±ç»è¿‡å‡ ä¸ªè®­ç»ƒæ­¥éª¤åèƒ½å¤Ÿä¸‹é™
"""

import jax
import jax.numpy as jnp
from jax import grad, jit, random, lax
import optax
import functools
import time
import sys
from pathlib import Path
from typing import Dict, Tuple, NamedTuple, Optional
import chex
from flax import linen as nn
from flax import struct
from flax.core import freeze, unfreeze
import numpy as np

# Add project root to path
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Import core components
from configs.default_config import get_minimal_config
from core.physics import (
    DroneState, PhysicsParams, dynamics_step_jit, 
    create_initial_drone_state, temporal_gradient_decay
)

# =============================================================================
# ç®€åŒ–çš„ç­–ç•¥ç½‘ç»œ
# =============================================================================

class SimplePolicyMLP(nn.Module):
    """
    æœ€ç®€åŒ–çš„MLPç­–ç•¥ç½‘ç»œ - ç”¨äºé˜¶æ®µ2æµ‹è¯•
    
    è¾“å…¥: æ— äººæœºçŠ¶æ€ [position(3) + velocity(3) = 6]
    è¾“å‡º: æ§åˆ¶è¾“å…¥ [thrust_x, thrust_y, thrust_z = 3]
    """
    
    hidden_dims: Tuple[int, ...] = (64, 64)
    output_dim: int = 3
    
    def setup(self):
        # Flaxæ¨¡å—ä¸­åº”ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æˆ–ç›´æ¥å®šä¹‰ï¼Œä¸èƒ½åœ¨setupä¸­ä½¿ç”¨append
        self.hidden_layers = [nn.Dense(dim) for dim in self.hidden_dims]
        self.output_layer = nn.Dense(self.output_dim)
        
    def __call__(self, state_vector: chex.Array) -> chex.Array:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            state_vector: [6] - [pos_x, pos_y, pos_z, vel_x, vel_y, vel_z]
        
        Returns:
            control: [3] - [thrust_x, thrust_y, thrust_z] èŒƒå›´ [-1, 1]
        """
        x = state_vector
        
        # éšè—å±‚
        for layer in self.hidden_layers:
            x = layer(x)
            x = nn.relu(x)
        
        # è¾“å‡ºå±‚ (ä½¿ç”¨tanhç¡®ä¿æ§åˆ¶è¾“å…¥åœ¨[-1, 1]èŒƒå›´å†…)
        control = self.output_layer(x)
        control = nn.tanh(control)  # çº¦æŸåˆ°[-1, 1]
        
        return control


def create_policy_network():
    """åˆ›å»ºå¹¶åˆå§‹åŒ–ç­–ç•¥ç½‘ç»œ"""
    policy_net = SimplePolicyMLP()
    
    # è™šæ‹Ÿè¾“å…¥è¿›è¡Œåˆå§‹åŒ–
    key = random.PRNGKey(42)
    dummy_state = jnp.zeros(6)  # [pos(3), vel(3)]
    
    params = policy_net.init(key, dummy_state)
    return policy_net, params


def drone_state_to_vector(state: DroneState) -> chex.Array:
    """å°†DroneStateè½¬æ¢ä¸ºç­–ç•¥ç½‘ç»œè¾“å…¥å‘é‡"""
    return jnp.concatenate([
        state.position,  # [3]
        state.velocity,  # [3]
    ])  # æ€»å…± [6]


# =============================================================================
# ç®€åŒ–çš„BPTTå¾ªç¯
# =============================================================================

@struct.dataclass
class ScanCarry:
    """scanå¾ªç¯çš„æºå¸¦çŠ¶æ€"""
    drone_state: DroneState
    step_count: int


@struct.dataclass  
class ScanOutput:
    """scanå¾ªç¯çš„è¾“å‡º"""
    position: chex.Array  # [3]
    velocity: chex.Array  # [3] 
    control: chex.Array   # [3]
    step_loss: float


def create_simple_scan_function(policy_net, policy_params, physics_params, target_position):
    """
    åˆ›å»ºç®€åŒ–çš„scanå‡½æ•° - é˜¶æ®µ2æ ¸å¿ƒ
    
    å®ç°: state -> policy -> physics -> loss
    """
    
    def scan_function(carry: ScanCarry, external_input) -> Tuple[ScanCarry, ScanOutput]:
        """
        å•æ­¥scanå‡½æ•°
        
        Flow:
        1. è·å–å½“å‰çŠ¶æ€
        2. ç­–ç•¥ç½‘ç»œäº§ç”Ÿæ§åˆ¶è¾“å…¥ 
        3. ç‰©ç†å¼•æ“æ›´æ–°çŠ¶æ€
        4. è®¡ç®—æ­¥éª¤æŸå¤±
        5. è¿”å›æ–°çŠ¶æ€å’Œè¾“å‡º
        """
        # 1. æå–å½“å‰çŠ¶æ€
        current_state = carry.drone_state
        step = carry.step_count
        
        # 2. ç­–ç•¥ç½‘ç»œï¼šstate -> control
        state_vector = drone_state_to_vector(current_state)
        control_input = policy_net.apply(policy_params, state_vector)
        
        # 3. ç‰©ç†å¼•æ“ï¼š(state, control) -> next_state
        next_state = dynamics_step_jit(current_state, control_input, physics_params)
        
        # 4. è®¡ç®—æ­¥éª¤æŸå¤±ï¼ˆç›®æ ‡ä½ç½®è·Ÿè¸ªï¼‰
        position_error = next_state.position - target_position
        step_loss = 0.5 * jnp.sum(position_error**2)
        
        # 5. æ›´æ–°æºå¸¦çŠ¶æ€
        new_carry = ScanCarry(
            drone_state=next_state,
            step_count=step + 1
        )
        
        # 6. è¾“å‡ºè®°å½•
        output = ScanOutput(
            position=next_state.position,
            velocity=next_state.velocity,
            control=control_input,
            step_loss=step_loss
        )
        
        return new_carry, output
    
    return scan_function


def create_simple_train_step(policy_net, physics_params, sequence_length=10):
    """
    åˆ›å»ºç®€åŒ–çš„è®­ç»ƒæ­¥éª¤å‡½æ•°
    
    å®ç°å®Œæ•´çš„BPTTè®­ç»ƒå¾ªç¯ï¼š
    1. è¿è¡Œscanè·å¾—è½¨è¿¹
    2. è®¡ç®—æ€»æŸå¤±
    3. è®¡ç®—æ¢¯åº¦
    4. æ›´æ–°å‚æ•°
    """
    
    def train_step(policy_params, optimizer_state, initial_state, target_position):
        """
        å•æ­¥è®­ç»ƒ
        
        Args:
            policy_params: ç­–ç•¥ç½‘ç»œå‚æ•°
            optimizer_state: ä¼˜åŒ–å™¨çŠ¶æ€
            initial_state: åˆå§‹æ— äººæœºçŠ¶æ€
            target_position: ç›®æ ‡ä½ç½® [3]
            
        Returns:
            new_params: æ›´æ–°åçš„å‚æ•°
            new_optimizer_state: æ›´æ–°åçš„ä¼˜åŒ–å™¨çŠ¶æ€  
            metrics: è®­ç»ƒæŒ‡æ ‡
        """
        
        def loss_function(params):
            """æŸå¤±å‡½æ•°ï¼šè¿è¡Œå®Œæ•´è½¨è¿¹å¹¶è®¡ç®—æŸå¤±"""
            # åˆ›å»ºscanå‡½æ•°
            scan_fn = create_simple_scan_function(
                policy_net, params, physics_params, target_position
            )
            
            # åˆå§‹æºå¸¦çŠ¶æ€
            initial_carry = ScanCarry(
                drone_state=initial_state,
                step_count=0
            )
            
            # è¿è¡Œscanå¾ªç¯
            final_carry, trajectory_outputs = lax.scan(
                scan_fn,
                initial_carry,
                jnp.arange(sequence_length),  # å¤–éƒ¨è¾“å…¥ï¼ˆæ—¶é—´æ­¥ç´¢å¼•ï¼‰
                length=sequence_length
            )
            
            # è®¡ç®—æ€»æŸå¤±
            step_losses = trajectory_outputs.step_loss  # [sequence_length]
            
            # æ—¶é—´åŠ æƒæŸå¤±ï¼ˆè·ç¦»ç›®æ ‡è¶Šè¿‘çš„æ—¶é—´æ­¥æƒé‡è¶Šé«˜ï¼‰
            time_weights = jnp.linspace(0.1, 1.0, sequence_length)
            weighted_loss = jnp.sum(step_losses * time_weights)
            
            return weighted_loss, (trajectory_outputs, final_carry)
        
        # è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
        (loss_value, (trajectory, final_state)), gradients = jax.value_and_grad(
            loss_function, has_aux=True
        )(policy_params)
        
        # åº”ç”¨æ¢¯åº¦æ›´æ–°
        optimizer = optax.adam(learning_rate=1e-3)
        updates, new_optimizer_state = optimizer.update(
            gradients, optimizer_state, policy_params
        )
        new_params = optax.apply_updates(policy_params, updates)
        
        # æ”¶é›†æŒ‡æ ‡
        metrics = {
            'loss': loss_value,
            'final_position_error': jnp.linalg.norm(
                final_state.drone_state.position - target_position
            ),
            'gradient_norm': optax.global_norm(gradients),
            'trajectory_length': jnp.linalg.norm(
                trajectory.position[-1] - trajectory.position[0]
            )
        }
        
        return new_params, new_optimizer_state, metrics
    
    return jax.jit(train_step)  # JITç¼–è¯‘è®­ç»ƒæ­¥éª¤


# =============================================================================
# é˜¶æ®µ2æµ‹è¯•å¥—ä»¶
# =============================================================================

def test_policy_network_creation():
    """æµ‹è¯•ç­–ç•¥ç½‘ç»œåˆ›å»ºå’Œåˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•1: ç­–ç•¥ç½‘ç»œåˆ›å»º")
    
    try:
        # åˆ›å»ºç½‘ç»œ
        policy_net, params = create_policy_network()
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_state = jnp.array([0.5, 1.0, 1.5, 0.1, 0.2, -0.1])  # [pos(3), vel(3)]
        control_output = policy_net.apply(params, test_state)
        
        # éªŒè¯è¾“å‡º
        assert control_output.shape == (3,), f"æœŸæœ›è¾“å‡ºå½¢çŠ¶(3,)ï¼Œå¾—åˆ°{control_output.shape}"
        assert jnp.all(jnp.abs(control_output) <= 1.0), "æ§åˆ¶è¾“å‡ºåº”åœ¨[-1,1]èŒƒå›´å†…"
        
        print(f"   âœ… ç­–ç•¥ç½‘ç»œåˆ›å»ºæˆåŠŸ")
        print(f"   ğŸ“Š å‚æ•°æ•°é‡: {sum(x.size for x in jax.tree.leaves(params))}")
        print(f"   ğŸ“Š æµ‹è¯•è¾“å‡º: {control_output}")
        print(f"   âœ”ï¸  è¾“å‡ºèŒƒå›´æ£€æŸ¥: {jnp.min(control_output):.3f} åˆ° {jnp.max(control_output):.3f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ç­–ç•¥ç½‘ç»œåˆ›å»ºé”™è¯¯: {e}")
        return False


def test_scan_function_creation():
    """æµ‹è¯•scanå‡½æ•°åˆ›å»ºå’Œå•æ­¥è¿è¡Œ"""  
    print("ğŸ”§ æµ‹è¯•2: Scanå‡½æ•°åˆ›å»º")
    
    try:
        # åˆ›å»ºç»„ä»¶
        policy_net, policy_params = create_policy_network()
        physics_params = PhysicsParams()
        target_position = jnp.array([2.0, 2.0, 2.0])
        
        # åˆ›å»ºscanå‡½æ•°
        scan_fn = create_simple_scan_function(
            policy_net, policy_params, physics_params, target_position
        )
        
        # æµ‹è¯•å•æ­¥è¿è¡Œ
        initial_state = create_initial_drone_state(jnp.array([0., 0., 1.]))
        initial_carry = ScanCarry(drone_state=initial_state, step_count=0)
        
        # è¿è¡Œå•æ­¥
        new_carry, output = scan_fn(initial_carry, 0)
        
        # éªŒè¯è¾“å‡º
        assert hasattr(output, 'position'), "è¾“å‡ºåº”åŒ…å«ä½ç½®"
        assert hasattr(output, 'control'), "è¾“å‡ºåº”åŒ…å«æ§åˆ¶è¾“å…¥"
        assert output.position.shape == (3,), "ä½ç½®åº”ä¸º3ç»´"
        assert output.control.shape == (3,), "æ§åˆ¶åº”ä¸º3ç»´"
        
        print(f"   âœ… Scanå‡½æ•°åˆ›å»ºæˆåŠŸ")
        print(f"   ğŸ“Š åˆå§‹ä½ç½®: {initial_state.position}")
        print(f"   ğŸ“Š æ›´æ–°ä½ç½®: {new_carry.drone_state.position}")
        print(f"   ğŸ“Š æ§åˆ¶è¾“å…¥: {output.control}")
        print(f"   ğŸ“Š æ­¥éª¤æŸå¤±: {output.step_loss:.6f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Scanå‡½æ•°åˆ›å»ºé”™è¯¯: {e}")
        return False


def test_multi_step_scan():
    """æµ‹è¯•å¤šæ­¥scanå¾ªç¯"""
    print("ğŸ”§ æµ‹è¯•3: å¤šæ­¥Scanå¾ªç¯")
    
    try:
        # åˆ›å»ºç»„ä»¶
        policy_net, policy_params = create_policy_network()
        physics_params = PhysicsParams()
        target_position = jnp.array([1.0, 0.0, 1.5])
        
        # åˆ›å»ºscanå‡½æ•°
        scan_fn = create_simple_scan_function(
            policy_net, policy_params, physics_params, target_position
        )
        
        # åˆå§‹çŠ¶æ€
        initial_state = create_initial_drone_state(jnp.array([0., 0., 1.]))
        initial_carry = ScanCarry(drone_state=initial_state, step_count=0)
        
        # è¿è¡Œå¤šæ­¥scan
        sequence_length = 15
        final_carry, trajectory = lax.scan(
            scan_fn,
            initial_carry,
            jnp.arange(sequence_length),
            length=sequence_length
        )
        
        # åˆ†æè½¨è¿¹
        positions = trajectory.position  # [sequence_length, 3]
        controls = trajectory.control    # [sequence_length, 3]
        losses = trajectory.step_loss    # [sequence_length]
        
        # è®¡ç®—æŒ‡æ ‡
        final_position_error = jnp.linalg.norm(
            final_carry.drone_state.position - target_position
        )
        total_distance_traveled = jnp.sum(jnp.linalg.norm(
            jnp.diff(positions, axis=0), axis=1
        ))
        
        print(f"   âœ… å¤šæ­¥ScanæˆåŠŸ")
        print(f"   ğŸ“Š è½¨è¿¹é•¿åº¦: {sequence_length} æ­¥")
        print(f"   ğŸ“Š åˆå§‹ä½ç½®: {positions[0]}")
        print(f"   ğŸ“Š æœ€ç»ˆä½ç½®: {positions[-1]}")
        print(f"   ğŸ“Š ç›®æ ‡ä½ç½®: {target_position}")
        print(f"   ğŸ“Š æœ€ç»ˆä½ç½®è¯¯å·®: {final_position_error:.4f}")
        print(f"   ğŸ“Š æ€»è¡Œé©¶è·ç¦»: {total_distance_traveled:.4f}")
        print(f"   ğŸ“Š å¹³å‡æ§åˆ¶å¼ºåº¦: {jnp.mean(jnp.linalg.norm(controls, axis=1)):.4f}")
        print(f"   ğŸ“Š æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ å¤šæ­¥Scanå¾ªç¯é”™è¯¯: {e}")
        return False


def test_jit_compilation():
    """æµ‹è¯•JITç¼–è¯‘èƒ½åŠ›"""
    print("ğŸ”§ æµ‹è¯•4: JITç¼–è¯‘éªŒè¯")
    
    try:
        # åˆ›å»ºç»„ä»¶
        policy_net, policy_params = create_policy_network()
        physics_params = PhysicsParams()
        
        # åˆ›å»ºJITç¼–è¯‘çš„è®­ç»ƒæ­¥éª¤
        train_step = create_simple_train_step(policy_net, physics_params, sequence_length=5)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        initial_state = create_initial_drone_state(jnp.array([0., 0., 1.]))
        target_position = jnp.array([0.5, 0.5, 1.5])
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        optimizer = optax.adam(learning_rate=1e-3)
        optimizer_state = optimizer.init(policy_params)
        
        # æµ‹è¯•JITç¼–è¯‘ï¼ˆç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šè§¦å‘ç¼–è¯‘ï¼‰
        print("   ğŸ”„ é¦–æ¬¡JITç¼–è¯‘...")
        start_time = time.time()
        new_params, new_opt_state, metrics = train_step(
            policy_params, optimizer_state, initial_state, target_position
        )
        first_call_time = time.time() - start_time
        
        # æµ‹è¯•åç»­è°ƒç”¨ï¼ˆå·²ç¼–è¯‘ï¼‰
        print("   ğŸš€ åç»­ç¼–è¯‘ç‰ˆæœ¬è°ƒç”¨...")
        start_time = time.time()
        new_params2, new_opt_state2, metrics2 = train_step(
            new_params, new_opt_state, initial_state, target_position
        )
        subsequent_call_time = time.time() - start_time
        
        speedup = first_call_time / subsequent_call_time if subsequent_call_time > 0 else float('inf')
        
        print(f"   âœ… JITç¼–è¯‘æˆåŠŸ")
        print(f"   â±ï¸  é¦–æ¬¡è°ƒç”¨æ—¶é—´: {first_call_time:.4f}s (åŒ…å«ç¼–è¯‘)")
        print(f"   â±ï¸  åç»­è°ƒç”¨æ—¶é—´: {subsequent_call_time:.4f}s")
        print(f"   ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"   ğŸ“Š åˆå§‹æŸå¤±: {metrics['loss']:.6f}")
        print(f"   ğŸ“Š ç¬¬äºŒæ¬¡æŸå¤±: {metrics2['loss']:.6f}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ JITç¼–è¯‘é”™è¯¯: {e}")
        return False


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµå’Œå‚æ•°æ›´æ–°"""
    print("ğŸ”§ æµ‹è¯•5: æ¢¯åº¦æµå’Œå‚æ•°æ›´æ–°")
    
    try:
        # åˆ›å»ºç»„ä»¶
        policy_net, initial_params = create_policy_network()
        physics_params = PhysicsParams()
        
        # åˆ›å»ºè®­ç»ƒæ­¥éª¤
        train_step = create_simple_train_step(policy_net, physics_params, sequence_length=8)
        
        # åˆå§‹åŒ–
        initial_state = create_initial_drone_state(jnp.array([0., 0., 1.]))
        target_position = jnp.array([1.0, 1.0, 2.0])
        
        optimizer = optax.adam(learning_rate=5e-3)
        optimizer_state = optimizer.init(initial_params)
        
        # è®°å½•å‚æ•°
        initial_param_norm = optax.global_norm(initial_params)
        
        # æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
        new_params, new_opt_state, metrics = train_step(
            initial_params, optimizer_state, initial_state, target_position
        )
        
        # åˆ†æå‚æ•°å˜åŒ–
        param_change = jax.tree.map(
            lambda new, old: new - old, 
            new_params, initial_params
        )
        param_change_norm = optax.global_norm(param_change)
        new_param_norm = optax.global_norm(new_params)
        
        # éªŒè¯æ¢¯åº¦æµ
        gradient_norm = metrics['gradient_norm']
        
        print(f"   âœ… æ¢¯åº¦æµæµ‹è¯•æˆåŠŸ")
        print(f"   ğŸ“Š åˆå§‹å‚æ•°èŒƒæ•°: {initial_param_norm:.6f}")
        print(f"   ğŸ“Š æ›´æ–°åå‚æ•°èŒƒæ•°: {new_param_norm:.6f}")
        print(f"   ğŸ“Š å‚æ•°å˜åŒ–èŒƒæ•°: {param_change_norm:.6f}")
        print(f"   ğŸ“Š æ¢¯åº¦èŒƒæ•°: {gradient_norm:.6f}")
        print(f"   ğŸ“Š è®­ç»ƒæŸå¤±: {metrics['loss']:.6f}")
        print(f"   ğŸ“Š ä½ç½®è¯¯å·®: {metrics['final_position_error']:.6f}")
        
        # éªŒè¯æœ‰æ„ä¹‰çš„æ›´æ–°
        assert gradient_norm > 1e-8, f"æ¢¯åº¦èŒƒæ•°è¿‡å°: {gradient_norm}"
        assert param_change_norm > 1e-8, f"å‚æ•°å˜åŒ–è¿‡å°: {param_change_norm}"
        
        print("   âœ”ï¸  æ¢¯åº¦èŒƒæ•°æ£€æŸ¥é€šè¿‡")
        print("   âœ”ï¸  å‚æ•°æ›´æ–°æ£€æŸ¥é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ¢¯åº¦æµæµ‹è¯•é”™è¯¯: {e}")
        return False


def test_loss_convergence():
    """æµ‹è¯•æŸå¤±æ”¶æ•› - å¤šæ­¥è®­ç»ƒ"""
    print("ğŸ”§ æµ‹è¯•6: æŸå¤±æ”¶æ•›éªŒè¯") 
    
    try:
        # åˆ›å»ºç»„ä»¶
        policy_net, params = create_policy_network()
        physics_params = PhysicsParams()
        
        # åˆ›å»ºè®­ç»ƒæ­¥éª¤
        train_step = create_simple_train_step(policy_net, physics_params, sequence_length=10)
        
        # è®­ç»ƒè®¾ç½®
        initial_state = create_initial_drone_state(jnp.array([0., 0., 1.]))
        target_position = jnp.array([0.3, 0.3, 1.2])  # ç›¸å¯¹è¾ƒè¿‘çš„ç›®æ ‡
        
        optimizer = optax.adam(learning_rate=1e-2)  # æ›´é«˜çš„å­¦ä¹ ç‡ä»¥ä¾¿å¿«é€Ÿæ”¶æ•›
        optimizer_state = optimizer.init(params)
        
        # è®­ç»ƒå¾ªç¯
        num_steps = 50
        loss_history = []
        current_params = params
        current_opt_state = optimizer_state
        
        print(f"   ğŸ‹ï¸ å¼€å§‹{num_steps}æ­¥è®­ç»ƒ...")
        
        for step in range(num_steps):
            current_params, current_opt_state, metrics = train_step(
                current_params, current_opt_state, initial_state, target_position
            )
            
            loss_history.append(float(metrics['loss']))
            
            if step % 10 == 0:
                print(f"   ğŸ“ˆ Step {step:2d}: loss={metrics['loss']:.6f}, "
                      f"pos_err={metrics['final_position_error']:.4f}")
        
        # åˆ†ææ”¶æ•›æ€§
        initial_loss = loss_history[0]
        final_loss = loss_history[-1]
        loss_reduction = (initial_loss - final_loss) / initial_loss
        
        # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸‹é™  
        loss_trend = jnp.polyfit(jnp.arange(len(loss_history), dtype=jnp.float32), 
                                jnp.array(loss_history), 1)[0]
        
        print(f"   âœ… è®­ç»ƒå®Œæˆ")
        print(f"   ğŸ“Š åˆå§‹æŸå¤±: {initial_loss:.6f}")
        print(f"   ğŸ“Š æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
        print(f"   ğŸ“Š æŸå¤±é™ä½: {loss_reduction:.2%}")
        print(f"   ğŸ“Š æŸå¤±è¶‹åŠ¿(æ–œç‡): {loss_trend:.8f}")
        print(f"   ğŸ“Š æœ€ç»ˆä½ç½®è¯¯å·®: {metrics['final_position_error']:.6f}")
        
        # æˆåŠŸæ ‡å‡†
        convergence_success = (loss_reduction > 0.1) or (loss_trend < 0)
        
        if convergence_success:
            print("   âœ”ï¸  æŸå¤±æ”¶æ•›æ£€æŸ¥é€šè¿‡")
            return True
        else:
            print("   âš ï¸  æŸå¤±æ”¶æ•›æœ‰é™ï¼Œä½†æ¢¯åº¦æµæ­£å¸¸")
            return True  # å¯¹äºç®€åŒ–æµ‹è¯•ï¼Œæ¢¯åº¦æµæ­£å¸¸å°±è¶³å¤Ÿäº†
        
    except Exception as e:
        print(f"   âŒ æŸå¤±æ”¶æ•›æµ‹è¯•é”™è¯¯: {e}")
        return False


def run_stage2_test_suite():
    """è¿è¡Œå®Œæ•´çš„é˜¶æ®µ2æµ‹è¯•å¥—ä»¶"""
    print("ğŸš€ å¼€å§‹MVPé˜¶æ®µ2æµ‹è¯•")
    print("="*80)
    
    tests = [
        ("ç­–ç•¥ç½‘ç»œåˆ›å»º", test_policy_network_creation),
        ("Scanå‡½æ•°åˆ›å»º", test_scan_function_creation),
        ("å¤šæ­¥Scanå¾ªç¯", test_multi_step_scan),
        ("JITç¼–è¯‘éªŒè¯", test_jit_compilation),
        ("æ¢¯åº¦æµæµ‹è¯•", test_gradient_flow),
        ("æŸå¤±æ”¶æ•›éªŒè¯", test_loss_convergence),
    ]
    
    results = {}
    total_time = time.time()
    
    for test_name, test_function in tests:
        start_time = time.time()
        try:
            success = test_function()
            results[test_name] = success
            duration = time.time() - start_time
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"   â±ï¸  è€—æ—¶: {duration:.3f}s")
            print(f"   {status}")
        except Exception as e:
            results[test_name] = False
            print(f"   âŒ å¼‚å¸¸: {e}")
        
        print("-" * 60)
    
    total_duration = time.time() - total_time
    
    # æ±‡æ€»ç»“æœ
    print("ğŸ“Š é˜¶æ®µ2æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("="*80)
    
    passed_tests = sum(results.values())
    total_tests = len(results)
    
    for test_name, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {test_name}")
    
    print(f"\nğŸ† æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.2f}s")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ­å–œï¼é˜¶æ®µ2æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… ç­–ç•¥ç½‘ç»œå®ç°æˆåŠŸ")
        print("âœ… BPTTå¾ªç¯å»ºç«‹å®Œæˆ")
        print("âœ… æ¢¯åº¦ä»æœªæ¥çŠ¶æ€æˆåŠŸåå‘ä¼ æ’­è‡³ç­–ç•¥ç½‘ç»œ")
        print("âœ… JITç¼–è¯‘å’Œè®­ç»ƒæ­¥éª¤åŠŸèƒ½æ­£å¸¸")
        print("âœ… å·²å‡†å¤‡å¥½è¿›å…¥é˜¶æ®µ3å¼€å‘ï¼ˆå®‰å…¨æœºåˆ¶é›†æˆï¼‰")
        return True
    else:
        failed_tests = [name for name, success in results.items() if not success]
        print(f"\nâš ï¸  {len(failed_tests)} ä¸ªæµ‹è¯•éœ€è¦å…³æ³¨:")
        for test_name in failed_tests:
            print(f"   - {test_name}")
        return False


if __name__ == "__main__":
    success = run_stage2_test_suite()
    sys.exit(0 if success else 1)